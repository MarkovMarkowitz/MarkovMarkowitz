{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarkovMarkowitz/MarkovMarkowitz/blob/main/ON2_Markowitz_Efficient_Frontier_v12A_MARKET_HEALTH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "8YziFkLOd_lj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "aQ9pqBcIeXM_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "FT-48_DXCxJR"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# @title Markov Markowitz Company / Efficient Portfolio Generator\n",
        "# @markdown ---\n",
        "# @markdown Input parameters for portfolio\n",
        "\n",
        "OFFSET = 0 # @param {type:\"number\"}\n",
        "LOOKBACK = 84 # @param {type:\"number\"}\n",
        "BACKTEST = 0 # @param {type:\"number\"}\n",
        "P_BOUND = 1 # @param {type:\"number\"}\n",
        "PURSE = 129000  # @param {type: \"number\"}\n",
        "EXCHANGE = \"bist30\"  # @param ['bist30', 'bist100', 'dow30', 'sp500']\n",
        "COMISSION_PERCENT = 0.0006 # @param {type: \"number\"}\n",
        "# @markdown ---\n",
        "# @markdown İstatistik ölçümlerde OPEN_CLOSE_SHARPE = False olacak\n",
        "OPEN_CLOSE_SHARPE = False # @param {type: \"boolean\"}\n",
        "NEGATIVE_SHARPE = False # @param {type: \"boolean\"}\n",
        "SEND_MAIL = True # @param {type: \"boolean\"}\n",
        "SAVE_PF = True # @param {type: \"boolean\"}\n",
        "\n",
        "# @markdown ---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "YMwfXes_vbjc"
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "today = date.today()\n",
        "\n",
        "def GenerateNewPortfolioFilename():\n",
        "  new = f\"ON2_D{today}_P{PURSE/1000}K_{EXCHANGE}_LB{LOOKBACK}_OFF{OFFSET}_PB{P_BOUND}_LONG={not OPEN_CLOSE_SHARPE}.xlsx\"\n",
        "  return new\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1HsqEBXZIQz",
        "outputId": "7ad5b898-e65b-4865-8672-7f9373d7901e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected =  0 84 129000 bist30\n"
          ]
        }
      ],
      "source": [
        "offset = OFFSET\n",
        "look_back = LOOKBACK\n",
        "CURRENT_T2 = PURSE\n",
        "exchange = EXCHANGE\n",
        "\n",
        "print(\"Selected = \", offset, look_back, CURRENT_T2, exchange)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwUEqtslcMZL",
        "outputId": "ca7b4df6-0c81-485d-8694-646d7a00872a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Date:  2023-12-20\n",
            "84 days before current date:  2023-09-27\n",
            "0 days before current date:  2023-12-21\n",
            "Backtest start date:  2023-12-21\n",
            "Backtest end date:  2023-12-20\n"
          ]
        }
      ],
      "source": [
        "from datetime import date, timedelta, datetime\n",
        "\n",
        "current_date = date.today().isoformat()\n",
        "days_before = (date.today() - timedelta(days=look_back+offset)).isoformat()\n",
        "days_after =  (date.today() + timedelta(days=1-offset)).isoformat()\n",
        "\n",
        "backtest_start = (date.today() - timedelta(days=offset-1)).isoformat()\n",
        "backtest_end =   (date.today() - timedelta(days=offset-BACKTEST)).isoformat()\n",
        "\n",
        "\n",
        "print(\"\\nCurrent Date: \",current_date)\n",
        "print(f\"{look_back+offset} days before current date: \",days_before)\n",
        "print(f\"{offset} days before current date: \",days_after)\n",
        "\n",
        "STEP = 0\n",
        "CHART = 0\n",
        "dateStart = days_before\n",
        "START_DATE = dateStart\n",
        "END_DATE   = days_after\n",
        "BACKTEST_START_DATE = backtest_start\n",
        "BACKTEST_END_DATE = backtest_end\n",
        "\n",
        "START_DATE, END_DATE\n",
        "start_time = datetime.now()\n",
        "\n",
        "\n",
        "print(f\"Backtest start date: \",BACKTEST_START_DATE)\n",
        "print(f\"Backtest end date: \",BACKTEST_END_DATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bVIczQ4fzJC"
      },
      "source": [
        "\n",
        "## Special Eyes-Only Report on\n",
        "# **Individual Portfolio Analysis and Further Suggestions**\n",
        "#### Report written by **Markov Markowitz Company**\n",
        "#### Report issued on **27.08.2023**\n",
        "\n",
        "Any comments should be sent to: info@markovmarkowitz.com\n",
        "\n",
        "\n",
        "\n",
        "--------------------------------------------------\n",
        "\n",
        "# Portfolio Construction with Maximum Win Probability and Maximum Sharpe Ratio Portfolio upon **BIST**100 Assets(\"**Borsa ISTanbul\", Turkey**) using:\n",
        "\n",
        "## 1. **Markov Chain Probabilistic Model**\n",
        "## 2. **Markowitz's Modern Portfolio Theory**\n",
        "\n",
        "Modern Portfolio Theory (MPT) is a Nobel Prize-winning economic theory.\n",
        "It explains how risk-averse investors can construct portfolios to optimize or maximize expected return based on a given level of market risk. <a href = \"https://en.wikipedia.org/wiki/Harry_Markowitz\">Harry Markowitz</a> pioneered this theory in his paper <a href = \"https://onlinelibrary.wiley.com/doi/full/10.1111/j.1540-6261.1952.tb01525.x\">Portfolio Selection</a> , which was published in the Journal of Finance in 1952. He was later awarded a Nobel Prize for his work on modern portfolio theory. Modern Portfolio Theory suggests diversification of all your securities and asset classes and not putting all your eggs in one basket. It emphasises the importance of portfolios, diversification, risk and the connections among different kinds of securities.\n",
        "\n",
        "\n",
        "## Table of contents\n",
        "1. [Volatility](#volat)\n",
        "2. [Variance and Standard Deviation](#type_vol)\n",
        "3. [Managing Portfolio Variance and Portfolio Variance Formula](#manpor)\n",
        "4. [Asset Selection](#asset_sel)\n",
        "5. [Select Backtesting Testing Dates](#select_dates)\n",
        "6. [Download the adjusted close prices of stocks](#downloads)\n",
        "7. [Plotting daily prices of all the stocks](#plot_daily)\n",
        "8. [Finding Daily returns](#daily_rets)\n",
        "9. [Standard deviations volatility and covariance matrix](#stddevs)\n",
        "10. [Correlation and heatmaps of correlation and effects on volatility](#heatmaps)\n",
        "11. [Markovitz Model Explanation](#markovitz)\n",
        "12. [Model portfolio with minimum risk amd its performance evaluation](#model)\n",
        "\n",
        "## Volatility <a name=\"volat\"></a>\n",
        "\n",
        "Volatility is a statistical measure of the dispersion of returns for a given security or market index. In most cases, the higher the volatility, the riskier the security. Volatility is often measured as either the standard deviation or variance between returns from that same security or market index.\n",
        "\n",
        "## Variance and Standard Deviation <a name=\"type_vol\"></a>\n",
        "\n",
        "Investors have to keep volatility in mind as well when choosing an investment. For example, a pension fund may need to be extra careful with its money and will want to ensure they aren’t getting into any extremely volatile investments. There are also hedge funds, which short stocks and even trade volatility with options. As you can see, whether you’re risk-seeking or risk-averse, the volatility (risk) of an investment is something you should care about.\n",
        "\n",
        "A simple measure of volatility is the variance. Variance is used to see how far away each data point in a set is away from the mean. Variance is calculated with the following steps:\n",
        "\n",
        "Take the difference between each data point and the mean Square each difference so that they're all positive values Sum up the squared results Divide this by the count of data points minus one $\\sigma^2 = \\frac{\\sum(x_i - \\overline{x}^2)}{n-1}$\n",
        "\n",
        "where\n",
        "\n",
        "$\\sigma^2 = \\textrm{Sample Variance}$\n",
        "\n",
        "$x_i = \\textrm{value of one observation}$\n",
        "\n",
        "$\\overline{x} = \\textrm{mean of all observations}$\n",
        "\n",
        "$n = \\textrm{number of observations}$\n",
        "\n",
        "The larger the variance, the further spread out it is from the mean. Variance treats all deviations from the mean the same way, regardless of whether they are less than or greater than the mean. A variance of zero would indicate that each data point is the same.\n",
        "\n",
        "Standard deviation is easy to calculate once you have the variance. All you have to do is take the square root of the variance:\n",
        "\n",
        "$\\sigma = \\sqrt{\\sigma^2}$\n",
        "\n",
        "where\n",
        "\n",
        "$\\sigma = \\textrm{standard deviation}$\n",
        "\n",
        "Standard deviation is another commonly used statistical measure to quantify market volatility. You would expect newer growth stocks to have higher standard deviations and more established blue-chip stocks to have lower standard deviations of returns. We will illustrate this by comparing daily returns from the last five years of the S&P 500 and NASDAQ, as well as Bitcoin prices. While Bitcoin isn't necessarily a growth stock, it's still very new compared to the S&P 500 and NASDAQ, so you would expect to see bigger swings in the price when compared to those two stock indices.\n",
        "\n",
        "This is illustrated below by taking the standard deviations of returns over the last five years. These results are as expected: Both the S&P 500 and NASDAQ have very similar daily standard deviations. Bitcoin, on the other hand, has almost five times the standard deviation of the two stock indices.\n",
        "\n",
        "## Managing Portfolio Variance and Portfolio Variance Formula <a name=\"manpor\"></a>\n",
        "\n",
        "In order to try to minimize portfolio variance, a good starting point is the formula itself to calculate variance with a two-asset portfolio.\n",
        "\n",
        "$\\textrm{Portfolio Variance} = w_x^2 \\sigma_x^2 + w_y^2 \\sigma_y^2 + 2w_x w_y Cov_{x,y}$\n",
        "\n",
        "where\n",
        "\n",
        "* $w_x$ = portfolio weight of asset x\n",
        "* $w_y$ = portfolio weight of asset y\n",
        "* $\\sigma_x$ = standard deviation of asset x\n",
        "* $\\sigma_y$ = standard deviation of asset y\n",
        "* $Cov_{x,y}$ = Covariance of the two assets\n",
        "\n",
        "Also, building off the previous lesson this means that\n",
        "$\\textrm{Portfolio Standard Deviation} = \\sqrt{\\textrm{Portfolio Variance}}$\n",
        "\n",
        "\n",
        "\n",
        "With this information in mind, there are 3 things we can do to minimize variance.\n",
        "\n",
        "1. We can pick assets with lower standard deviations of returns. This may seem obvious, but if we really want to reduce the variance of our portfolio, the simplest thing to do is just pick assets that have relatively low volatilities.\n",
        "2. Invest a higher percentage of your portfolio into your less risky asset(s). For our previous example with JPM and Bitcoin, we could further reduce our portfolio variance by investing a bigger portion of our funds into JPM since it had a lower standard deviation than Bitcoin.\n",
        "\n",
        "Sometimes, it's the case that an investor may still want to invest in a riskier asset like Bitcoin. This brings us to the third thing we can do to reduce variance.\n",
        "\n",
        "3. Check for assets with a low covariance. If you look at the right side of our portfolio variance function, you'll notice we have the covariance of two assets as a function parameter. If we can reduce that, we can reduce the overall variance of our portfolio.\n",
        "\n",
        "This is an important point and should be expanded upon further.\n",
        "\n",
        "\n",
        "## Covariance-Correlation Relationship\n",
        "If you recall from a previous lesson, the formula for correlation is:\n",
        "\n",
        "$\\rho_{x,y} = \\frac{Cov_{x,y}}{\\sigma_x*\\sigma_y}$\n",
        "\n",
        "We can rearrange this to get the covariance formula:\n",
        "\n",
        "$Cov_{x,y} = \\rho_{x,y}\\sigma_x\\sigma_y$\n",
        "\n",
        "Then, we can plug this back into our portfolio variance formula:\n",
        "\n",
        "$\\textrm{Portfolio Variance} = w_x^2 \\sigma_x^2 + w_y^2 \\sigma_y^2 + 2w_x w_y \\rho_{x,y}\\sigma_x\\sigma_y$\n",
        "\n",
        "\n",
        "These formulas are basically to show that we need to minimize correlations in order to minimize portfolio variance. Owning uncorrelated assets illustrates the efficient benefits of diversification. Let's write some reusable functions to sum up the work we did above and really display how this works with a few examples.\n",
        "\n",
        "\n",
        "As seen in the formula, in order to minimize portfolio variance we need to minimize the covariance term. And this can be done by minimization coefficents of this covariance term\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kD9NAwxYvjFe",
        "outputId": "c2096c23-9ca6-4f91-e5c4-7cccb5c26bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n",
            "Requirement already satisfied: nsepy in /usr/local/lib/python3.10/dist-packages (0.8)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nsepy) (4.11.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nsepy) (2.31.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nsepy) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nsepy) (1.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nsepy) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nsepy) (8.1.7)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nsepy) (4.9.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nsepy) (2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nsepy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nsepy) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nsepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->nsepy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nsepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nsepy) (2023.11.17)\n",
            "Requirement already satisfied: pyfolio in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (7.34.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (1.5.3)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (2023.3.post1)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (1.2.2)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (0.12.2)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (0.5.5)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.10/dist-packages (from empyrical>=0.5.0->pyfolio) (0.10.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio) (2.8.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.16.1->pyfolio) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.16.1->pyfolio) (3.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio) (0.8.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (4.9.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2.31.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=3.2.3->pyfolio) (0.2.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->pyfolio) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2023.11.17)\n"
          ]
        }
      ],
      "source": [
        "# Installing and Importing the libraries\n",
        "\n",
        "!pip3 install pandas\n",
        "!pip3 install numpy\n",
        "!pip3 install matplotlib\n",
        "!pip3 install seaborn\n",
        "!pip3 install scipy\n",
        "!pip3 install nsepy\n",
        "!pip3 install pyfolio\n",
        "\n",
        "\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "from datetime import date\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.optimize import minimize\n",
        "from nsepy import *\n",
        "\n",
        "import os\n",
        "\n",
        "from datetime import datetime\n",
        "import time\n",
        "import yfinance as yf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEBs17R2wC5D",
        "outputId": "a7321fd4-8237-4d49-a5c3-646e34845bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     PGSUS.IS\n",
            "1     YKBNK.IS\n",
            "2     ENKAI.IS\n",
            "3     BIMAS.IS\n",
            "4     ISCTR.IS\n",
            "5     TAVHL.IS\n",
            "6     AKBNK.IS\n",
            "7     GARAN.IS\n",
            "8     TUPRS.IS\n",
            "9     TOASO.IS\n",
            "10    ALARK.IS\n",
            "11    PETKM.IS\n",
            "12    ARCLK.IS\n",
            "13    KOZAA.IS\n",
            "14    TCELL.IS\n",
            "15    SAHOL.IS\n",
            "16    THYAO.IS\n",
            "17    ASELS.IS\n",
            "18    KOZAL.IS\n",
            "19    EKGYO.IS\n",
            "20    GUBRF.IS\n",
            "21    FROTO.IS\n",
            "22    KRDMD.IS\n",
            "23     SISE.IS\n",
            "24    EREGL.IS\n",
            "Name: Ticker, dtype: object\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "\n",
        "def GetSelectedStockList(exchange):\n",
        "\n",
        "    from google.colab import files\n",
        "\n",
        "    filename = f\"{exchange}_selected.csv\"\n",
        "    my_file = Path(f\"/content/{filename}\")\n",
        "\n",
        "    if my_file.is_file():\n",
        "        stock_list = pd.read_csv(filename).Ticker\n",
        "    else:\n",
        "        files.upload_file(filename)\n",
        "        stock_list = pd.read_csv(filename).Ticker\n",
        "\n",
        "    print(stock_list)\n",
        "    return(stock_list)\n",
        "\n",
        "stock_list = GetSelectedStockList(exchange)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "nqjURFWrP7OS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "8otzoN_HDIUI"
      },
      "outputs": [],
      "source": [
        "def NextStep():\n",
        "    global STEP\n",
        "    STEP+=1\n",
        "    print(70*'_')\n",
        "    print(f\"\\nPerforming STEP-{STEP}:\")\n",
        "\n",
        "def NextChart():\n",
        "    global CHART\n",
        "    CHART+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "naH4ZMZ5vue_"
      },
      "outputs": [],
      "source": [
        "# from datetime import date, timedelta\n",
        "\n",
        "\n",
        "\n",
        "# current_date = date.today().isoformat()\n",
        "# days_before = (date.today() - timedelta(days=look_back+offset)).isoformat()\n",
        "# days_after =  (date.today() + timedelta(days=1-offset)).isoformat()\n",
        "\n",
        "# print(\"\\nCurrent Date: \",current_date)\n",
        "# print(f\"{look_back+offset} days before current date: \",days_before)\n",
        "# print(f\"{offset} days before current date: \",days_after)\n",
        "\n",
        "# STEP = 0\n",
        "# CHART = 0\n",
        "# dateStart = days_before\n",
        "# START_DATE = dateStart\n",
        "# END_DATE   = days_after\n",
        "# START_DATE, END_DATE\n",
        "# start_time = datetime.now()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UniH-BqWm_j_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7425c23-6ade-404f-f408-085d6b26510a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************************************\n",
            "Starting Download ...\n",
            "****************************************************************\n",
            "Downloading PGSUS.IS\n",
            "Downloading YKBNK.IS\n",
            "Downloading ENKAI.IS\n",
            "Downloading BIMAS.IS\n",
            "Downloading ISCTR.IS\n",
            "Downloading TAVHL.IS\n",
            "Downloading AKBNK.IS\n",
            "Downloading GARAN.IS\n",
            "Downloading TUPRS.IS\n",
            "Downloading TOASO.IS\n",
            "Downloading ALARK.IS\n",
            "Downloading PETKM.IS\n",
            "Downloading ARCLK.IS\n",
            "Downloading KOZAA.IS\n",
            "Downloading TCELL.IS\n",
            "Downloading SAHOL.IS\n",
            "Downloading THYAO.IS\n",
            "Downloading ASELS.IS\n",
            "Downloading KOZAL.IS\n",
            "Downloading EKGYO.IS\n",
            "Downloading GUBRF.IS\n",
            "Downloading FROTO.IS\n",
            "Downloading KRDMD.IS\n",
            "Downloading SISE.IS\n",
            "Downloading EREGL.IS\n",
            "****************************************************************\n",
            "****************************************************************\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# ### Download the adjusted close prices of stocks <a name=\"downloads\"></a>\n",
        "\n",
        "# In[4]:\n",
        "\n",
        "LENGTH = 64\n",
        "\n",
        "\n",
        "\n",
        "price_list = []\n",
        "\n",
        "print(LENGTH*\"*\")\n",
        "print(\"Starting Download ...\")\n",
        "print(LENGTH*\"*\")\n",
        "for tick in stock_list:\n",
        "        print(f\"Downloading {tick}\")\n",
        "        yf_tick = yf.Ticker(tick)\n",
        "        df = yf_tick.history(interval='1d', auto_adjust=True, start=START_DATE, end=END_DATE, back_adjust = True, rounding=True)\n",
        "        df.dropna(how='all', inplace=True)\n",
        "        price_list.append(df)\n",
        "print(LENGTH*\"*\")\n",
        "\n",
        "print(LENGTH*\"*\")\n",
        "\n",
        "## Save datafiles to disk\n",
        "\n",
        "for i,df in enumerate(price_list):\n",
        "        df.to_csv(f\"{stock_list[i]}.csv\")\n",
        "\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "Stocks = stock_list\n",
        "pf_data = pd.DataFrame()\n",
        "li = pd.DataFrame() # my real portfolio dataframe for close\n",
        "lu = pd.DataFrame() # my real portfolio dataframe for open\n",
        "rets = pd.DataFrame()\n",
        "names = []\n",
        "count = len(Stocks)\n",
        "\n",
        "# os.chdir(wd)\n",
        "#for file in sorted2.Stock:\n",
        "for file in Stocks:\n",
        "    pf_data = pd.read_csv(f\"{file}.csv\", index_col='Date', parse_dates=True, keep_date_col = True, infer_datetime_format=True, dayfirst=True, decimal=\".\" )\n",
        "\n",
        "    li = pd.concat( [li,pf_data['Close']],axis=1) #, ignore_index=True)\n",
        "    lu = pd.concat( [lu,pf_data['Open']],axis=1) #, ignore_index=True)\n",
        "    # st_name = file.split('.',maxsplit = 1)\n",
        "    # names.append(st_name[0])\n",
        "    names.append(file)\n",
        "\n",
        "li.columns = names\n",
        "lu.columns = names\n",
        "\n",
        "li = li.rename_axis(index=\"Date\")\n",
        "lu = lu.rename_axis(index=\"Date\")\n",
        "\n",
        "pf_data = li.sort_values(by=['Date'], ascending=[True])\n",
        "pf_data_open = lu.sort_values(by=['Date'], ascending=[True])\n",
        "\n",
        "pf_data.to_csv(f'{exchange}.csv')\n",
        "pf_data_open.to_csv(f'{exchange}_open.csv')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "pf_data.plot(subplots = True,figsize = (10,10))\n",
        "plt.title(\"Close prices of all stocks\")\n",
        "plt.savefig(\"Fig1_ClosePrices.jpg\", format='jpg', dpi=300)\n",
        "plt.show()\n",
        "if  OPEN_CLOSE_SHARPE:\n",
        "  log_returns = np.log(pf_data_open / pf_data.shift(1)) - COMISSION_PERCENT*2\n",
        "else:\n",
        "  log_returns = np.log(pf_data/pf_data.shift(1)) - COMISSION_PERCENT*2\n",
        "\n",
        "\n",
        "#log_returns = (data['Adj Open'] - data['Adj Close'].shift(1)) / data['Adj Close'].shift(1) - COMISSION_PERCENT*2)\n",
        "\n",
        "\n",
        "log_returns\n",
        "\n",
        "log_returns.describe()\n",
        "np.round(log_returns.mean(),4)\n",
        "yearly_rets = np.round(log_returns.mean() * 252,2) # Mean returns annualized for year\n",
        "yearly_rets\n",
        "\n",
        "vol = np.round(log_returns.std()*np.sqrt(252),3) # annualized version of std deviation\n",
        "vol\n",
        "\n",
        "risk_free_rate = 0.23\n",
        "\n",
        "sharpe = (yearly_rets - risk_free_rate)/vol\n",
        "sharpe\n",
        "\n",
        "max_sr_vol = vol[sharpe.argmax()] # risk corresponding to maximum sharpe ratio\n",
        "max_sr_ret = yearly_rets[sharpe.argmax()] # return corresponding to maximum sharpe ratio\n",
        "\n",
        "def PrintSharpePerformance():\n",
        "    yearly_rets = np.round(log_returns.mean() * 252,2) # Mean returns annualized for year\n",
        "    yearly_rets\n",
        "    vol = np.round(log_returns.std()*np.sqrt(252),3) # annualized version of std deviation\n",
        "    vol\n",
        "    sharpe = (yearly_rets - risk_free_rate)/vol\n",
        "    sharpe\n",
        "    max_sr_vol = vol[sharpe.argmax()] # risk corresponding to maximum sharpe ratio\n",
        "    max_sr_ret = yearly_rets[sharpe.argmax()] # return corresponding to maximum sharpe ratio\n",
        "\n",
        "    ASSETS = log_returns.mean().index\n",
        "\n",
        "    print(f\"Sharpe Ratio = {sharpe[1]}\")\n",
        "    print(f\"Max Sharpe Ratio = {sharpe.max()}\")\n",
        "    print(f\"Max Sharpe Ratio Return = {max_sr_ret}\")\n",
        "    print(f\"Max Sharpe Ratio Volatility = {max_sr_vol}\")\n",
        "    return vol, ASSETS,sharpe\n",
        "\n",
        "\n",
        "def plot_with_labels(coord, labels, sharpe):\n",
        "    assert len(coord) == len(labels), 'coord len is not equal to labels len'\n",
        "    plt.figure(figsize=(10, 10))  # in inches\n",
        "    for i, label in enumerate(labels): #get (0, label)\n",
        "        x, y = coord[i] #2 dim\n",
        "        #plt.scatter(x, y)\n",
        "        # yearly_rets = np.round(log_returns.mean() * 252,2) # Mean returns annualized for year\n",
        "        # vol = np.round(log_returns.std()*np.sqrt(252),3) # annualized version of std deviation\n",
        "\n",
        "        #sharpe = (y - risk_free_rate)/x\n",
        "        plt.scatter(x, y, c=sharpe[i], cmap='viridis')\n",
        "        plt.annotate(label,\n",
        "                xy=(x, y), #show point\n",
        "                xytext=(5, 2), #show annotate\n",
        "                textcoords='offset points',\n",
        "                ha='left',\n",
        "                va='bottom')\n",
        "\n",
        "    plt.colorbar(label='Sharpe Ratio')\n",
        "    plt.xlabel('Volatility')\n",
        "    plt.ylabel('Returns')\n",
        "    plt.grid(True)\n",
        "    plt.title(f'Best {len(log_returns.mean())} of {exchange} R-R Map')\n",
        "    plt.savefig(\"Fig2_R-R_Map.jpg\", format='jpg', dpi=300)\n",
        "    plt.show()\n",
        "    return \"Fig2_R-R_Map.jpg\"\n",
        "\n",
        "def PlotRRMap():\n",
        "    coord = list(zip(vol, log_returns.mean()*100))\n",
        "    labels = ASSETS\n",
        "    aa = plot_with_labels(coord, labels, sharpe)\n",
        "\n",
        "    from IPython.display import Image\n",
        "    Image(url=aa)\n",
        "\n",
        "vol, ASSETS,sharpe = PrintSharpePerformance()\n",
        "\n",
        "PlotRRMap()\n",
        "\n",
        "print(f\"Max Sharpe Ratio = {sharpe.max()}\")\n",
        "print(f\"Max Sharpe Ratio Return = {max_sr_ret}\")\n",
        "print(f\"Max Sharpe Ratio Volatility = {max_sr_vol}\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(18,10))\n",
        "sns.heatmap(log_returns.corr(),linecolor='white',linewidths=1,annot=True)\n",
        "plt.title(\"correlation heatmap of stocks\")\n",
        "plt.savefig(\"Fig3_Correlation_Heatmap.jpg\", format='jpg', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#sns.pairplot(log_returns,palette='coolwarm')\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "# - The pair plots also signify the same result that there is no pair of stocks with high negative correlation. We don't find any pair-plot with upper-left to lower-right pattern.\n",
        "# - The pairs with high positive correlation have scatter plot with lower-left to upper-right pattern .\n",
        "# - Other pairs don't form any pattern.\n",
        "\n",
        "# # Markowitz Model\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "\n",
        "#\n",
        "# - We model our assets by their expected return, $E[R]$ and their risk, which is expressed as their standard deviation, $\\sigma$\n",
        "\n",
        "# - Our investment decisions are expressed by investing 100% of our wealth in assets( here, stocks), where each particular investment represents a proportion of our total wealth.\n",
        "\n",
        "#\n",
        "# - We will now implement Markowitz Model. This model assists in the selection of the most efficient portfolios by analyzing various possible portfolios of the selected stocks.\n",
        "\n",
        "# - We invest $w_i$ in $stock_i$ for every i, such that\n",
        "\n",
        "#  <h3>$$\\Sigma^{n}_{i=1} w_i = 1$$</h3>\n",
        "\n",
        "# - The expected return of the portfolio constructed would be\n",
        "\n",
        "# <h3>\n",
        "# $$E[R_p] = \\Sigma^{n}_{i=1} w_i E[R_i]$$</h3>\n",
        "\n",
        "# and the risk associated with the portfolio would be\n",
        "#\n",
        "\n",
        "# <h3>$$\\sigma^2(R_p) = \\Sigma^{n}_{i=1} w_i^2 \\sigma^2(R_i) + \\Sigma^{}_{i=1}\\Sigma^{}_{j {\\neq} i} w_i w_j \\sigma(R_i) \\sigma(R_j) \\rho_{ij}$$</h3>\n",
        "\n",
        "# $E[R_i]$ is the annual expected return of $i$th stock, $\\sigma(R_i)$ corrsponds to annual standard deviation of $i$th stock and $\\rho_{ij}$ is the correlation between the logarithmic returns $i$th and the $j$th stock.\n",
        "\n",
        "# - $E[R_p]$ is the annual expected return of the portfolio and $\\sigma(R_p)$ is the risk associated with the portfolio (Also the standard deviation of the portfolio)\n",
        "\n",
        "# - An efficient portfolio is one that maximizes return for a given level of risk. Our task is to select adequate weights $w_i$ to get the efficient portfolio\n",
        "\n",
        "# #### Implementation\n",
        "\n",
        "# -  Let $W_{1 \\times n}$ be a array containing the weights $w_i$ such that $\\Sigma^{n}_{i=1} w_i = 1$ and $E[R]_{ n\\times 1}$ be another array containing annual expected returns of n stocks present in the portfolio and $C$ be the covariance matrix of annual returns of  stocks, then\n",
        "\n",
        "# <h3>$$E[R_p] = WE[R]$$</h3>\n",
        "\n",
        "#\n",
        "# $$ \\sigma^2(R_p) = W^TCW $$\n",
        "\n",
        "# ### Sharpe Ratio\n",
        "#\n",
        "# - It is a statistical measure used in Modern Portfolio Theory.\n",
        "# - The Sharpe ratio measures the performance of an investment compared to a risk-free asset, after adjusting for its risk. It is defined as the difference between the returns of the investment and the risk-free return, divided by the standard deviation of the investment.\n",
        "# - A portfolio with a higher Sharpe ratio is considered to have best risk-adjusted returns.\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "\n",
        "# $$ S = \\frac{E[R_p] - R_f}{\\sigma(R_p)} $$\n",
        "\n",
        "# Here, $R_f$ is the risk free rate of return. We have taken risk free rate as 10 year government bond rate in Turkey.\n",
        "\n",
        "# In[22]:\n",
        "\n",
        "\n",
        "# A function for generating a numpy array containing random weights that add upto 1\n",
        "def RandWeights(size):\n",
        "    weight = np.random.dirichlet(np.ones(size))\n",
        "    return weight\n",
        "\n",
        "\n",
        "# In[23]:\n",
        "\n",
        "\n",
        "\n",
        "risk_free_rate = 0.235 # quite high in Turkey !\n",
        "\n",
        "# A function to generate the avg return, risk and the sharpe ratio of the portfolio\n",
        "# correponding to the weight array passed\n",
        "def portfolio_stats(weight):\n",
        "\n",
        "    # Convert to array in case list was passed instead.\n",
        "    weight = np.array(weight)\n",
        "    port_return = np.sum(log_returns.mean() * weight) * 250\n",
        "    port_risk = np.sqrt(np.dot(weight.T, np.dot(log_returns.cov() * 250, weight)))\n",
        "    sharpe = (port_return - risk_free_rate)/port_risk\n",
        "\n",
        "    return {'return': port_return, 'risk': port_risk, 'sharpe': sharpe}\n",
        "\n",
        "\n",
        "# In[24]:\n",
        "\n",
        "\n",
        "# Trying to generate random weights\n",
        "\n",
        "length = len(log_returns.columns)\n",
        "weight = RandWeights(length)\n",
        "\n",
        "# Generating Portfolio Statistics\n",
        "pf_stats = portfolio_stats(weight)\n",
        "\n",
        "pf_return = pf_stats['return']\n",
        "pf_risk = pf_stats['risk']\n",
        "sharpe_ratio = pf_stats['sharpe']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# #### We will now run a monte carlo simulation to generate random portfolios. We will use the results of simulation to draw an efficient frontier\n",
        "\n",
        "# In[30]:\n",
        "\n",
        "\n",
        "def Monte_Carlo(iterations):\n",
        "    portfolio_returns = []\n",
        "    portfolio_risks = []\n",
        "    for x in range (iterations):\n",
        "        weight = RandWeights(length)\n",
        "        pf_stats = portfolio_stats(weight)\n",
        "        portfolio_returns.append(pf_stats['return'])\n",
        "        portfolio_risks.append(pf_stats['risk'])\n",
        "\n",
        "    portfolio_returns = np.array(portfolio_returns)\n",
        "    portfolio_risks = np.array(portfolio_risks)\n",
        "    return portfolio_returns, portfolio_risks\n",
        "\n",
        "\n",
        "# In[31]:\n",
        "\n",
        "\n",
        "portfolio_returns, portfolio_risks = Monte_Carlo(10000)\n",
        "sharpe = portfolio_returns / portfolio_risks\n",
        "max_sr_ret = portfolio_returns[sharpe.argmax()] # return corresponding to maximum sharpe ratio\n",
        "max_sr_vol = portfolio_risks[sharpe.argmax()] # risk corresponding to maximum sharpe ratio\n",
        "max_sr_ret\n",
        "\n",
        "\n",
        "# In[32]:\n",
        "\n",
        "\n",
        "plt.figure(figsize=(18,10))\n",
        "plt.scatter(portfolio_risks, portfolio_returns, c=sharpe, cmap='viridis')\n",
        "plt.colorbar(label='Sharpe Ratio')\n",
        "plt.xlabel('Risk')\n",
        "plt.ylabel('Return')\n",
        "plt.title('R/R Locus of portfolios: The Efficient Frontier')\n",
        "plt.scatter(max_sr_vol, max_sr_ret,c='red', s=50) # red dot\n",
        "plt.savefig(\"Fig4_RR_Locus.jpg\", format='jpg', dpi=300)\n",
        "plt.show()\n",
        "print(f\"Max Sharpe Ratio = {sharpe.max()}\")\n",
        "print(f\"Max Sharpe Ratio Return = {max_sr_ret}\")\n",
        "print(f\"Max Sharpe Ratio Volatility = {max_sr_vol}\")\n",
        "\n",
        "\n",
        "# - The above plot shows comparison of all portfolio combinations generated in Mone Carlo Simulation in terms of their risk and return. The red dot corresponds to the portfolio having the highest sharpe ratio amoung the generated portfolios. ( This portfolio may not be the one with highest sharpe ratio as we are plotting random portfolios. It is just the portfolio with highest sharpe ratio amoung all the randomly generated portfolios)\n",
        "\n",
        "# - We will now try to generate optimized portffolios subject to various conditions\n",
        "\n",
        "# - This hyperbolic plot is called 'Markowitz's Bullet'\n",
        "\n",
        "# #### Using Optimization to find portfolio with max sharpe ratio\n",
        "# - The below function returns the weights array cooresponding to the portfolio with the highest Sharpe Ratio\n",
        "# - We are using Scipy.optimize.minimize. We are trying to minimize negative Sharpe Ratio (which is same as maximising the sharpe ratio)\n",
        "# - The constraint for optimization is -> Sum of all the weights has to be 1, and all the weights are bounded between 0 and 1\n",
        "\n",
        "# - The optimization is successful.\n",
        "#\n",
        "\n",
        "# - The required weights are in the key x\n",
        "\n",
        "# #### Using Optimisation to find portfolio that has minimum risk for a given expected return\n",
        "#\n",
        "# - Sometimes, the investors want to have a portfolio with a fixed targert return.\n",
        "# - They want to find portfolio that would provide that return with minimum risk involved\n",
        "\n",
        "#\n",
        "\n",
        "# #### Finding portfolio that provide the minimum risk\n",
        "\n",
        "# In[33]:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def OptimizationWithSharpeRatio():\n",
        "\n",
        "    def FindNegSharpe(weight):\n",
        "      if NEGATIVE_SHARPE:\n",
        "        return portfolio_stats(weight)['sharpe']\n",
        "      else:\n",
        "        return -portfolio_stats(weight)['sharpe']\n",
        "\n",
        "\n",
        "\n",
        "    res = minimize(\n",
        "          FindNegSharpe,\n",
        "          RandWeights(length),\n",
        "          method = 'SLSQP',\n",
        "          constraints=[\n",
        "            {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
        "          ],\n",
        "          bounds=[(0, P_BOUND) for i in range(length)]\n",
        "        )\n",
        "\n",
        "    return res\n",
        "\n",
        "def OptimizingWithMinRisk():\n",
        "\n",
        "    def fun(weight):\n",
        "        pf_stats = portfolio_stats(weight)\n",
        "        _risk = pf_stats['risk']\n",
        "        return _risk\n",
        "\n",
        "\n",
        "    res = minimize(\n",
        "      fun,\n",
        "      RandWeights(length),\n",
        "      method = 'SLSQP',\n",
        "      constraints=[\n",
        "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
        "      ],\n",
        "      bounds=[(0., P_BOUND) for i in range(length)]\n",
        "    )\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "# In[34]:\n",
        "\n",
        "\n",
        "#OptimizingWithMinRisk()\n",
        "\n",
        "\n",
        "# ### Plotting the efficient Frontier\n",
        "\n",
        "# - The efficient frontier is the set of optimal portfolios that offer the highest expected return for a defined level of risk or the lowest risk for a given level of expected return. Portfolios that lie below the efficient frontier are sub-optimal because they do not provide enough return for the level of risk.\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "\n",
        "# - We will plot the efficient frontier by taking the optimal portfolios for all possible returns\n",
        "\n",
        "# In[35]:\n",
        "\n",
        "\n",
        "target_returns = np.linspace(portfolio_returns.min(), portfolio_returns.max(),20)\n",
        "\n",
        "minimal_risks = []\n",
        "for target_return in target_returns:\n",
        "    optimal = OptimizingWithMinRisk()\n",
        "    minimal_risks.append(optimal['fun'])\n",
        "\n",
        "minimal_risks = np.array(minimal_risks)\n",
        "print(minimal_risks)\n",
        "\n",
        "\n",
        "# In[36]:\n",
        "\n",
        "\n",
        "plt.figure(figsize=(18,10))\n",
        "\n",
        "plt.scatter(portfolio_risks, portfolio_returns,\n",
        "            c = ( portfolio_returns / portfolio_risks),\n",
        "            marker = 'o')\n",
        "\n",
        "# Plotting the efficient frontier\n",
        "# plt.scatter(minimal_risks,\n",
        "#             target_returns,\n",
        "#             c = (target_returns / minimal_risks),\n",
        "#             marker = 'x')\n",
        "\n",
        "\n",
        "#Plotting the optimal portfolio that has lowest risk\n",
        "#Optimal_weights_For_Lowest_Risk = OptimizingWithMinRisk().x\n",
        "Optimal_weights_For_Highest_Sharpe = OptimizationWithSharpeRatio().x\n",
        "\n",
        "\n",
        "plt.plot(portfolio_stats(Optimal_weights_For_Highest_Sharpe)['risk'],\n",
        "         portfolio_stats(Optimal_weights_For_Highest_Sharpe)['return'],\n",
        "         'r*',\n",
        "         markersize = 25.0, label = \"Portfolio corresponding highest sharpe ratio\")\n",
        "\n",
        "\n",
        "plt.xlabel('Portfolio Risk',fontsize = 20)\n",
        "plt.ylabel('Portfolio Return', fontsize = 20)\n",
        "plt.legend(prop={'size': 10})\n",
        "plt.colorbar(label='Sharpe ratio')\n",
        "\n",
        "\n",
        "# - The efficient frontier is different for different investors, depending upon the assets they are holding\n",
        "#\n",
        "#\n",
        "\n",
        "# - There is nothing like a single optimal portfolio. The efficient frontier is the collection of optimal portfolios.\n",
        "\n",
        "# - The investors can choose any optimal portfolio depending upon the risk they can take\n",
        "\n",
        "# In[37]:\n",
        "\n",
        "\n",
        "w = np.round(Optimal_weights_For_Highest_Sharpe,4)\n",
        "w\n",
        "len(w)\n",
        "\n",
        "\n",
        "# In[38]:\n",
        "\n",
        "\n",
        "BEST_PF = pd.Series(w*100, log_returns.columns)\n",
        "print(\"% weights of minimum volatility PF\")\n",
        "print (60*\"-\")\n",
        "\n",
        "index = w>=0.000\n",
        "BEST_PF[index].round(3)\n",
        "\n",
        "\n",
        "# In[39]:\n",
        "\n",
        "\n",
        "w = np.round(Optimal_weights_For_Highest_Sharpe,4)\n",
        "BEST_PF = pd.Series(w*100, stock_list)\n",
        "print(\"% weights of Best Sharpe PF\")\n",
        "index = w>=0.000\n",
        "Final_TEFAS_PF = pd.DataFrame(BEST_PF[index].round(4),  columns=['%'] )\n",
        "Portfolio_Weights = np.round(w[index],4)\n",
        "Portfolio_Assets = BEST_PF[index]\n",
        "Portfolio_Amounts = Portfolio_Weights*100000\n",
        "Final_TEFAS_PF['Amounts for Capital of 100000 TL'] = Portfolio_Amounts\n",
        "print(portfolio_stats(Optimal_weights_For_Highest_Sharpe))\n",
        "Final_TEFAS_PF.sort_values(by=['%'], ascending=[False])\n",
        "\n",
        "\n",
        "# In[40]:\n",
        "\n",
        "\n",
        "import datetime\n",
        "\n",
        "import pandas as pd\n",
        "import pandas_datareader.data as web\n",
        "import seaborn as sns\n",
        "from IPython.display import VimeoVideo\n",
        "\n",
        "\n",
        "# In[41]:\n",
        "\n",
        "\n",
        "def getReturns(startTime, endTime, tickers):\n",
        "\n",
        "    # pull price data from yahoo -- (list(tickers.keys())) = ['^GSPC','^RUT']\n",
        "    prices = web.DataReader(stock_list, \"yahoo\", START_DATE, END_DATE)[\"Adj Close\"]\n",
        "    prices = prices.dropna()\n",
        "    returns = prices.pct_change()\n",
        "    return prices.pct_change()\n",
        "\n",
        "\n",
        "# In[42]:\n",
        "\n",
        "\n",
        "def compareVariance(startTime, endTime, tickers, weights):\n",
        "    returns = getReturns(startTime, endTime, tickers)\n",
        "    tmp = weights * returns\n",
        "    returns[f\"Portfolio w/ weights {Portfolio_Weights}\"] = tmp[tmp.columns[0]] + tmp[tmp.columns[1]]\n",
        "    standardDev = returns.std()\n",
        "    avgReturns = returns.mean()\n",
        "    res = pd.concat([avgReturns * 100, standardDev*100], axis=1)\n",
        "    res.columns = [\"Daily Average Return %\", \"Standard Deviation of Returns %\"]\n",
        "    return res.round(3)\n",
        "\n",
        "\n",
        "import pyfolio\n",
        "\n",
        "print(Final_TEFAS_PF)\n",
        "\n",
        "Portfolio_Amounts = np.multiply(100000, Portfolio_Weights )\n",
        "InitialPrices = pf_data.iloc[0,0:]\n",
        "\n",
        "Portfolio_Shares = np.trunc((Portfolio_Amounts / InitialPrices)) # determine shares\n",
        "\n",
        "np.shape(Portfolio_Shares)\n",
        "\n",
        "Prices = pf_data.iloc[:,0:]\n",
        "Prices\n",
        "\n",
        "\n",
        "pf_data['Portfolio'] = np.dot(Portfolio_Shares, Prices.T)  # PF_VALUE = dot product of shares and their prices !!!!\n",
        "pf_data['PF_Rets'] = pf_data['Portfolio'].pct_change()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUTvMi_0p-4n"
      },
      "outputs": [],
      "source": [
        "pyfolio.create_simple_tear_sheet(pf_data['PF_Rets'].dropna())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuyRk1Akndsk"
      },
      "outputs": [],
      "source": [
        "Portfolio_Amounts = np.round(CURRENT_T2*Portfolio_Weights,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8cDJT2ks-r_"
      },
      "outputs": [],
      "source": [
        "InitialPrices = pf_data.iloc[0,0:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dwE9-B_txcK"
      },
      "outputs": [],
      "source": [
        "show_df = pd.DataFrame({\"assets\":Portfolio_Assets.index.T, \"%\": np.round(100*Portfolio_Weights,4), \"Amount\": Portfolio_Amounts})\n",
        "show_df = show_df.loc[(show_df[\"%\"]>0)]\n",
        "show_df = show_df.sort_values(by=['%'],ascending=False)\n",
        "show_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUG0PlKWLGdw"
      },
      "outputs": [],
      "source": [
        "last_prices = pf_data.iloc[-1,0:]\n",
        "last_prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAvyYc4gLPSS"
      },
      "outputs": [],
      "source": [
        "portfolio_assets_last_prices = last_prices.loc[show_df['assets']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXs3UPJ8t0V8"
      },
      "outputs": [],
      "source": [
        "print(\"Last prices are:\")\n",
        "print(\"-----------------\")\n",
        "print(portfolio_assets_last_prices)\n",
        "\n",
        "show_df['buy_price'] = portfolio_assets_last_prices.values\n",
        "show_df['shares_to_buy'] = np.trunc(show_df['Amount'] / portfolio_assets_last_prices.values)\n",
        "show_df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vgwjOueElaw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR224IQK2w01"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng0_Nkwvbvcg"
      },
      "outputs": [],
      "source": [
        "\n",
        "def ConstructPortfolioTimeSeries(portfolio):\n",
        "    NextStep()\n",
        "    print(f\"Construct Time series...\")\n",
        "    # print(f\"portfolio = {portfolio} is input\")\n",
        "    print(70*'=')\n",
        "\n",
        "    Residue_Cash = CURRENT_T2\n",
        "    #os.chdir(wd)\n",
        "\n",
        "    OrderedTable = pd.DataFrame()\n",
        "    df = pd.DataFrame()\n",
        "    names = show_df.assets\n",
        "    #print(names)\n",
        "    filename = f\"{names.iloc[0]}.csv\"\n",
        "    #print(filename)\n",
        "\n",
        "    df = pd.read_csv(filename) #change 1\n",
        "    #df = pd.read_csv(filename, index_col='Date', parse_dates=True, keep_date_col = True, infer_datetime_format=True, dayfirst=True, decimal=\",\")\n",
        "\n",
        "    OrderedTable[\"Date\"] = df.iloc[:,0] #change 3\n",
        "\n",
        "    # init_weight = np.round(1/len(names),5)\n",
        "    # Portfolio_Weights = [ init_weight for i in range(len(names))]\n",
        "\n",
        "    portfolio['Portfolio_Weights'] = portfolio['%']/100\n",
        "\n",
        "    for tick in names:\n",
        "        #print(f\"Fetching {tick}\")\n",
        "        filename = f\"{tick}.csv\"\n",
        "        #filename = f\"{names[0]+'.IS'}.csv\"\n",
        "\n",
        "        df = pd.read_csv(filename)\n",
        "        #df = pd.read_csv(filename, index_col='Date', parse_dates=True, keep_date_col = True, infer_datetime_format=True, dayfirst=True, decimal=\",\") #change 2\n",
        "        OrderedTable[f\"{tick}\"] = df['Close']  # get each ETFs column write inside OrderedTable\n",
        "\n",
        "\n",
        "    portfolio['InitialPrices'] = OrderedTable.iloc[0,1:].values\n",
        "    #print(f\"\\n Initial prices: \\n{InitialPrices} \\n\")\n",
        "\n",
        "    portfolio['FinalPrices'] = OrderedTable.iloc[-1,1:].values\n",
        "    #print(f\"\\n Final prices: {FinalPrices}\")\n",
        "\n",
        "    Update_Capital = Residue_Cash # add the cash not used for stocks\n",
        "\n",
        "    portfolio['Portfolio_Amounts'] = np.multiply(Update_Capital, portfolio['Portfolio_Weights'] )\n",
        "    #print(f\" Portfolio amounts: \\n{Portfolio_Amounts} \\n\")\n",
        "\n",
        "    portfolio['Portfolio_Shares'] = np.trunc(portfolio['Portfolio_Amounts'] / portfolio['InitialPrices'] )  # determine shares\n",
        "\n",
        "    #print(f\" Portfolio shares: \\n{portfolio['Portfolio_Shares']} \")\n",
        "\n",
        "    portfolio['Purchased Value'] = portfolio['InitialPrices'] * portfolio['Portfolio_Shares']\n",
        "\n",
        "    portfolio['Market Value'] = portfolio['FinalPrices'] * portfolio['Portfolio_Shares']\n",
        "    portfolio['PnL %'] = (portfolio['Market Value'] - portfolio['Purchased Value']) / portfolio['Purchased Value'] *100\n",
        "    portfolio['Start PF %'] = portfolio['Purchased Value'] / portfolio['Purchased Value'].sum() *100\n",
        "    portfolio['End PF %'] = portfolio['Market Value'] / portfolio['Market Value'].sum() *100\n",
        "\n",
        "    portfolio['Market Value'] = pd.to_numeric(portfolio['Market Value']).round(2)\n",
        "    portfolio['PnL %'] = pd.to_numeric(portfolio['PnL %']).round(2)\n",
        "    portfolio['Start PF %'] = pd.to_numeric(portfolio['Start PF %']).round(2)\n",
        "    portfolio['End PF %'] = pd.to_numeric(portfolio['End PF %']).round(2)\n",
        "\n",
        "    portfolio['Final_Cost'] = np.multiply(Update_Capital, portfolio['End PF %']/100 )\n",
        "\n",
        "    Prices = OrderedTable.iloc[:,1:].values\n",
        "\n",
        "    FirstPrices = OrderedTable.iloc[0,0:len(names)].values\n",
        "    FirstPrices\n",
        "\n",
        "    OrderedTable['PF_Value'] = np.dot(portfolio['Portfolio_Shares'], Prices.T)  # PF_VALUE = dot product of shares and their prices !!!!\n",
        "    #print(OrderedTable['PF_Value'])\n",
        "\n",
        "    Residue_Cash = Update_Capital - OrderedTable.PF_Value.iloc[0] # !!!\n",
        "    print(f\" Residue cash: {Residue_Cash} \\n\")\n",
        "\n",
        "    OrderedTable['PF_Value'] += Residue_Cash\n",
        "\n",
        "    Update_Capital = OrderedTable.PF_Value.iloc[-1] # Update_Captial =  value of the PF at the end of every quarter\n",
        "\n",
        "    #print(f\" Portfolio capital at the end of period: {Update_Capital} \\n\")\n",
        "    #print(\" Ordered Table: \\n\")\n",
        "\n",
        "    OrderedTable['pct_change'] = OrderedTable['PF_Value'].pct_change()\n",
        "    OrderedTable.set_index(\"Date\", inplace = True)\n",
        "    OrderedTable.index= pd.to_datetime(OrderedTable.index)  # PYFOLIO nun düzgün çalışması icin bu gerekli\n",
        "    return OrderedTable, portfolio, Residue_Cash\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liipNzId2FUY"
      },
      "outputs": [],
      "source": [
        "show_df['assets']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnbZxrf7cPqn"
      },
      "outputs": [],
      "source": [
        "def ShowTearSheet(OrderedPctChange):\n",
        "    NextStep()\n",
        "    NextChart()\n",
        "    print(f\"Showing Tearsheet of Portfolio...\")\n",
        "    print(70*'=')\n",
        "    import pyfolio\n",
        "    print(f\"********* PORTFOLIO TEARSHEET *************** \")\n",
        "\n",
        "    try:\n",
        "        simple_tear_sheet = pyfolio.create_simple_tear_sheet(OrderedPctChange)\n",
        "        print(\"********* end of TEARSHEET **************\\n\")\n",
        "        #simple_tear_sheet.savefig(f\"Chart_{CHART}_Ret_Tear_sheet.jpg\", format='jpg', dpi=300)\n",
        "        #from IPython.display import Image\n",
        "        #Image(url=f\"Chart_{CHART}_Simple_Tear_sheet.jpg\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error generating returns tear sheet:\", e)\n",
        "        returns_tear_sheet = None\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvmRLZIW8oBn"
      },
      "outputs": [],
      "source": [
        "OrderedTable, IDEAL_PF, Residue_Cash = ConstructPortfolioTimeSeries(show_df)\n",
        "display(OrderedTable['PF_Value'])\n",
        "ShowTearSheet(OrderedTable['pct_change'].dropna())\n",
        "OrderedTable.to_csv(f\"Best_PF_TimeSeries_{exchange}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyfolio.plot_rolling_sharpe(OrderedTable['pct_change'].dropna(),rolling_window=84, grid=True, figsize=(16, 10))\n",
        "# pyfolio.plot_monthly_returns_heatmap(OrderedTable['pct_change'].dropna())\n",
        "# pyfolio.plot_drawdown_underwater(OrderedTable['pct_change'].dropna(), grid=True)"
      ],
      "metadata": {
        "id": "4x6eA7ggbJSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8Mzzw7i86U6"
      },
      "outputs": [],
      "source": [
        "import pyfolio as pf\n",
        "pystats_df = pf.timeseries.perf_stats(OrderedTable['pct_change'].dropna())\n",
        "max_drawdown = np.abs(100*pf.timeseries.max_drawdown(OrderedTable['pct_change'].dropna()))\n",
        "annual_return = pf.timeseries.annual_return(OrderedTable['pct_change'].dropna())\n",
        "sharpe_ratio = pf.timeseries.sharpe_ratio(OrderedTable['pct_change'].dropna())\n",
        "print(\"NEW PORTFOLIO PERFORMANCE\")\n",
        "pystats_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mNsKyuqzw22"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "py-MezeyuUdP"
      },
      "outputs": [],
      "source": [
        "print(f\"daily mean return for new portfolio = %{np.round(pf_data['PF_Rets'].mean()*100,3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7O3JY5Zz9Cak"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOcz7FvSCYqF"
      },
      "outputs": [],
      "source": [
        "# BEST_PF = pd.Series(np.array(IDEAL_PF['End PF %']), np.array(IDEAL_PF['assets']))\n",
        "# a = pd.DataFrame(BEST_PF,  columns=['%'] )\n",
        "# a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD1whso-7-bA"
      },
      "outputs": [],
      "source": [
        "IDEAL_PF['Rebalance Buy Price'] = show_df['buy_price']\n",
        "IDEAL_PF['Rebalance Shares'] = show_df['shares_to_buy']\n",
        "IDEAL_PF = np.round(IDEAL_PF,4)\n",
        "IDEAL_PF.to_csv(f\"Best_PF_For_{exchange}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y4qlN8GVWf9"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download(f\"Best_PF_For_{exchange}.csv\")\n",
        "# print(\"........................................files downloaded ........................................\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AbO8rMl-BGH"
      },
      "outputs": [],
      "source": [
        "from datetime import date, timedelta, datetime\n",
        "start_time = datetime.now()\n",
        "start_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VHF0xFcwTM6"
      },
      "outputs": [],
      "source": [
        "display(IDEAL_PF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QwD57lvpDpc"
      },
      "outputs": [],
      "source": [
        "sum(IDEAL_PF['Final_Cost'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfgLxaVSNOj_"
      },
      "outputs": [],
      "source": [
        "sum(IDEAL_PF['Market Value'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "geg_eja4xplR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CDVIzHWR4DT"
      },
      "outputs": [],
      "source": [
        "TOTAL_REBALANCE_PURCHASE = IDEAL_PF['Final_Cost'].sum()\n",
        "print(f\"This portfolio started with : {np.round(IDEAL_PF['Purchased Value'].sum(),2)} TL\", )\n",
        "print(f\"This portfolio ended up with : {np.round(IDEAL_PF['Market Value'].sum(),2)} TL in {look_back} days\", )\n",
        "\n",
        "print(f\"TOTAL REBALANCE PURCHASE will be: {np.round(TOTAL_REBALANCE_PURCHASE,2)} \", )\n",
        "print(f\"RESIDUE CASH will be: {np.round(Residue_Cash)} \", )\n",
        "print('----------------------------------------------------------------------------------------')\n",
        "print(\"Make sure that you buy the exact amount of shares (Rebalance Shares) shown on the table IDEAL_PF.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CUSTOMER_VIEW = IDEAL_PF[['assets','Rebalance Buy Price', 'Rebalance Shares', 'Market Value']]\n",
        "CUSTOMER_VIEW"
      ],
      "metadata": {
        "id": "kVnC6c0_FFs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK-P-pjNzx7T"
      },
      "source": [
        "**Sharpe ratio**: The Sharpe ratio measures the excess return (the return above the risk-free rate) per unit of volatility or standard deviation. Like the Omega ratio, it measures the risk-adjusted return of a portfolio or investment but does not consider the likelihood of incurring large losses. Instead, it looks at the overall volatility, which exhibits poor efficiency as a risk denominator.\n",
        "\n",
        "\n",
        "**Treynor ratio**: Both the Omega and the Treynor ratios take into account the risk of an investment. However, the Treynor ratio uses systematic risk, also known as beta, in its denominator. That means the Omega ratio captures the total risk of an investment, while the Treynor ratio only captures the risk that is not diversifiable.\n",
        "\n",
        "\n",
        "**Calmar ratio**: Like the Omega, the Calmar ratio measures the risk-adjusted performance of an investment. However, it uses the maximum drawdown as the risk measure. The maximum drawdown is the maximum percentage loss from a peak to a trough, representing the worst-case scenario. That means that the Omega ratio captures the total risk of an investment, while the Calmar ratio captures the worst-case scenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITaDg6bB0GgM"
      },
      "outputs": [],
      "source": [
        "if SAVE_PF:\n",
        "  NEW_PORTFOLIO_FILENAME = GenerateNewPortfolioFilename()\n",
        "  print(\"New Portfolio will be saved as: \", NEW_PORTFOLIO_FILENAME )\n",
        "  with pd.ExcelWriter(NEW_PORTFOLIO_FILENAME) as writer:  # doctest: +SKIP\n",
        "      pystats_df.to_excel(writer, sheet_name = 'PF STATS')\n",
        "      show_df.to_excel(writer, sheet_name = 'PF ASSETS')\n",
        "      #worksheet = writer.sheets['PF STATS']\n",
        "      #worksheet.insert_image(5, 5, \"Fig1_ClosePrices.jpg\")\n",
        "      writer.save()\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QUgYg46IAW9"
      },
      "outputs": [],
      "source": [
        "# from openpyxl import load_workbook\n",
        "# import pandas as pd\n",
        "# df_new = pd.DataFrame({'Col_C': [9, 10, 11, 12]})\n",
        "# wb = load_workbook('test.xlsx')\n",
        "\n",
        "# ws = wb['Sheet1']\n",
        "\n",
        "# for index, row in df_new.iterrows():\n",
        "#     cell = 'C%d'  % (index + 2)\n",
        "#     ws[cell] = row[0]\n",
        "\n",
        "# wb.save('test.xlsx')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1s_LOrQIqTA"
      },
      "outputs": [],
      "source": [
        "# from openpyxl import load_workbook\n",
        "# import pandas as pd\n",
        "\n",
        "# wb = load_workbook(filename)\n",
        "\n",
        "# ws = wb['PF STATS']\n",
        "\n",
        "# for index\n",
        "#     cell = 'C%d'  % (index + 2)\n",
        "#     ws[cell] =\n",
        "\n",
        "# wb.save('test.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kdS8A8UM6a9"
      },
      "outputs": [],
      "source": [
        "def SendEmailThroughGmail(filename):\n",
        "    '''\n",
        "\n",
        "    UTILITY U=019 : SEND_EMAIL_THRU_GMAIL\n",
        "    --------------------------------------------\n",
        "    - SETS variables for mail server\n",
        "    - SETS database to be emailed\n",
        "    - SETS filename to be attached\n",
        "    - CHANGES directory for writing the excel file\n",
        "    - FORMS the excel file\n",
        "    - SETS params for mail and its content with smtp lib\n",
        "    - ATTACHES file with mimetypes\n",
        "    - SENDS mail to my own gmail address with ssl library\n",
        "\n",
        "    '''\n",
        "\n",
        "    gmail_pass = \"owypdnplmjxuofwg\" #\"tinvqeuucaczivic\"  #uwyuympejcjvaikg\n",
        "    user = \"alperulku1970@gmail.com\"\n",
        "    subscribers = \"alperulku1970@gmail.com\"\n",
        "    SERVER_ADDRESS = \"smtp.gmail.com\"\n",
        "    SERVER_PORT = 587\n",
        "\n",
        "    #now = datetime.now()\n",
        "    # Final_TEFAS_PF['Max Drawdown %'] = np.round(MaxDrawdown, 4)\n",
        "    # IDEALPF['Max Drawdown'] = np.round(MaxDrawdown, 4)\n",
        "    # Final_TEFAS_PF.to_csv(filename_statement + \".csv\")\n",
        "\n",
        "    shopping_list_file = 'ShoppingList.csv'\n",
        "    #os.chdir(out)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # with pd.ExcelWriter(filename) as writer:  # doctest: +SKIP\n",
        "    #     #Final_TEFAS_PF.to_excel(writer, sheet_name = 'Yeni Portföy')\n",
        "    #     #df = pd.DataFrame(Kurallar)\n",
        "    #     #df.to_excel(writer, sheet_name='Kurallar')\n",
        "    #     df = pd.DataFrame(Performance)\n",
        "    #     df.to_excel(writer, sheet_name='İdeal PF Performans')\n",
        "    #     df = pd.DataFrame(Current_PF)\n",
        "    #     df.to_excel(writer, sheet_name='Mevcut PF')\n",
        "    #     IDEALPF.to_excel(writer, sheet_name = 'Ideal PF')\n",
        "    #     if FW_TEST_PERIOD !=0:\n",
        "    #         ShoppingList.to_excel(writer, sheet_name='Fark Alış-Satış Listesi')\n",
        "\n",
        "    global exchange\n",
        "    import smtplib\n",
        "    from email.message import EmailMessage\n",
        "\n",
        "    msg = EmailMessage()\n",
        "\n",
        "    msg['Subject'] = filename\n",
        "    msg['From'] = user\n",
        "    msg['To'] = subscribers\n",
        "\n",
        "    text = f\"Merhaba, bugünün {exchange} piyasası için en iyi Sharpe Oranı'na sahip Portföyü ektedir: {filename} \\r\\n\"\n",
        "\n",
        "    text+= \"Markov Markowitz, Çankaya, Ankara, Türkiye.\\r\\n\"\n",
        "    text+= \"Her hakkı saklıdır. @ Markov Markowitz 2022-2023.\"\n",
        "\n",
        "\n",
        "    msg.set_content(text)\n",
        "\n",
        "    import mimetypes\n",
        "\n",
        "    #path = f\"/Users/alperulku/Desktop/Masaüstü - Alper’s Mac mini/MY BEST PORTFOLIOS/{filename}\"\n",
        "    path =  filename\n",
        "\n",
        "    # Guess the content type based on the file's extension.\n",
        "    ctype, encoding = mimetypes.guess_type(path)\n",
        "    if ctype is None or encoding is not None:\n",
        "        ctype = 'application/octet-stream'\n",
        "    maintype, subtype = ctype.split('/', 1)\n",
        "\n",
        "    with open(path, 'rb') as fp:\n",
        "        msg.add_attachment(fp.read(), maintype=maintype, subtype=subtype,\n",
        "                           filename=filename)\n",
        "\n",
        "    path =  filename\n",
        "    with open(path, 'rb') as fp:\n",
        "        msg.add_attachment(fp.read(), maintype=maintype, subtype=subtype,\n",
        "                           filename=filename)\n",
        "\n",
        "\n",
        "    # path = root + \"/\" + f\"MPT_v{version}_TEST.pdf\"\n",
        "    # with open(path, 'rb') as fp:\n",
        "    #     msg.add_attachment(fp.read(), maintype=maintype, subtype=subtype,\n",
        "    #                        filename=f\"MPT_v{version}_TEST.pdf\")\n",
        "\n",
        "\n",
        "\n",
        "    import ssl\n",
        "\n",
        "    # Create a SSLContext object with default settings.\n",
        "    context = ssl.create_default_context()\n",
        "\n",
        "    with smtplib.SMTP(SERVER_ADDRESS, SERVER_PORT) as smtp:\n",
        "        smtp.ehlo()  # Say EHLO to server\n",
        "        smtp.starttls(context=context)  # Puts the connection in TLS mode.\n",
        "        smtp.ehlo()\n",
        "        smtp.login(user, gmail_pass)\n",
        "        smtp.send_message(msg)  # Auto detects the sender and recipient from header\n",
        "\n",
        "    print(\"mail sent with success with attachment\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9BrtykoGnRJ"
      },
      "outputs": [],
      "source": [
        "if SEND_MAIL:\n",
        "  filename = GenerateNewPortfolioFilename()\n",
        "  SendEmailThroughGmail(filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1uE5g20Fawd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTcSKfGL-NTh"
      },
      "source": [
        "BURADAN İTİBAREN BACKTEST SÜRESİ KADAR ANALİZ YAPILACAK\n",
        "-------------------------------------------------------\n",
        "-------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmNKfUHB6GMz"
      },
      "outputs": [],
      "source": [
        "price_list = []\n",
        "\n",
        "print(LENGTH*\"*\")\n",
        "print(\"Starting Download ...\")\n",
        "print(LENGTH*\"*\")\n",
        "for tick in stock_list:\n",
        "        print(f\"Downloading {tick}\")\n",
        "        yf_tick = yf.Ticker(tick)\n",
        "        df = yf_tick.history(interval='1d', auto_adjust=True, start=BACKTEST_START_DATE, end=BACKTEST_END_DATE, back_adjust = True, rounding=True)\n",
        "        df.dropna(how='all', inplace=True)\n",
        "        price_list.append(df)\n",
        "print(LENGTH*\"*\")\n",
        "\n",
        "print(LENGTH*\"*\")\n",
        "\n",
        "## Save datafiles to disk\n",
        "\n",
        "for i,df in enumerate(price_list):\n",
        "        df.to_csv(f\"{stock_list[i]}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if BACKTEST == 0:\n",
        "  print(\"BACKTEST period is 0, so, analysis is completed\")\n",
        "  exit(0)"
      ],
      "metadata": {
        "id": "mQdv-GU27eKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdiTiopNKSvL"
      },
      "outputs": [],
      "source": [
        "Stocks = stock_list\n",
        "pf_data = pd.DataFrame()\n",
        "li = pd.DataFrame() # my real portfolio dataframe for close\n",
        "lu = pd.DataFrame() # my real portfolio dataframe for open\n",
        "rets = pd.DataFrame()\n",
        "names = []\n",
        "count = len(Stocks)\n",
        "\n",
        "# os.chdir(wd)\n",
        "#for file in sorted2.Stock:\n",
        "for file in Stocks:\n",
        "    pf_data = pd.read_csv(f\"{file}.csv\", index_col='Date', parse_dates=True, keep_date_col = True, infer_datetime_format=True, dayfirst=True, decimal=\".\" )\n",
        "\n",
        "    li = pd.concat( [li,pf_data['Close']],axis=1) #, ignore_index=True)\n",
        "    lu = pd.concat( [lu,pf_data['Open']],axis=1) #, ignore_index=True)\n",
        "    # st_name = file.split('.',maxsplit = 1)\n",
        "    # names.append(st_name[0])\n",
        "    names.append(file)\n",
        "\n",
        "li.columns = names\n",
        "lu.columns = names\n",
        "\n",
        "li = li.rename_axis(index=\"Date\")\n",
        "lu = lu.rename_axis(index=\"Date\")\n",
        "\n",
        "pf_data = li.sort_values(by=['Date'], ascending=[True])\n",
        "pf_data_open = lu.sort_values(by=['Date'], ascending=[True])\n",
        "\n",
        "pf_data.to_csv(f'{exchange}.csv')\n",
        "pf_data_open.to_csv(f'{exchange}_open.csv')\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "pf_data.plot(subplots = True,figsize = (10,10))\n",
        "plt.title(\"Close prices of all stocks\")\n",
        "plt.savefig(\"Fig1_ClosePrices.jpg\", format='jpg', dpi=300)\n",
        "plt.show()\n",
        "if  OPEN_CLOSE_SHARPE:\n",
        "  log_returns = np.log(pf_data_open / pf_data.shift(1)) - COMISSION_PERCENT*2\n",
        "else:\n",
        "  log_returns = np.log(pf_data/pf_data.shift(1)) - COMISSION_PERCENT*2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hut9-ATENT1p"
      },
      "outputs": [],
      "source": [
        "log_returns\n",
        "\n",
        "log_returns.describe()\n",
        "np.round(log_returns.mean(),4)\n",
        "yearly_rets = np.round(log_returns.mean() * 252,2) # Mean returns annualized for year\n",
        "yearly_rets\n",
        "\n",
        "vol = np.round(log_returns.std()*np.sqrt(252),3) # annualized version of std deviation\n",
        "vol\n",
        "\n",
        "risk_free_rate = 0.23\n",
        "\n",
        "sharpe = (yearly_rets - risk_free_rate)/vol\n",
        "sharpe\n",
        "\n",
        "max_sr_vol = vol[sharpe.argmax()] # risk corresponding to maximum sharpe ratio\n",
        "max_sr_ret = yearly_rets[sharpe.argmax()] # return corresponding to maximum sharpe ratio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEIcgM2uNrur"
      },
      "outputs": [],
      "source": [
        "log_returns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0kYOwzrNt1s"
      },
      "outputs": [],
      "source": [
        "log_returns.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiA5-zNeN91f"
      },
      "outputs": [],
      "source": [
        "yearly_rets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTSR0PdPOBrO"
      },
      "outputs": [],
      "source": [
        "vol, ASSETS,sharpe = PrintSharpePerformance()\n",
        "\n",
        "PlotRRMap()\n",
        "\n",
        "print(f\"Max Sharpe Ratio = {sharpe.max()}\")\n",
        "print(f\"Max Sharpe Ratio Return = {max_sr_ret}\")\n",
        "print(f\"Max Sharpe Ratio Volatility = {max_sr_vol}\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(18,10))\n",
        "sns.heatmap(log_returns.corr(),linecolor='white',linewidths=1,annot=True)\n",
        "plt.title(\"correlation heatmap of stocks\")\n",
        "plt.savefig(\"Fig3_Correlation_Heatmap.jpg\", format='jpg', dpi=300)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGhdbzQ0OSkj"
      },
      "outputs": [],
      "source": [
        "pf_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRtpE86aP0X0"
      },
      "outputs": [],
      "source": [
        "Portfolio_Amounts = np.multiply(100000, Portfolio_Weights )\n",
        "InitialPrices = pf_data.iloc[0,0:]\n",
        "\n",
        "Portfolio_Shares = np.trunc((Portfolio_Amounts / InitialPrices)) # determine shares\n",
        "\n",
        "np.shape(Portfolio_Shares)\n",
        "\n",
        "Prices = pf_data.iloc[:,0:]\n",
        "Prices\n",
        "\n",
        "\n",
        "pf_data['Portfolio'] = np.dot(Portfolio_Shares, Prices.T)  # PF_VALUE = dot product of shares and their prices !!!!\n",
        "pf_data['PF_Rets'] = pf_data['Portfolio'].pct_change()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NG2C6B6WQUYu"
      },
      "outputs": [],
      "source": [
        "Portfolio_Shares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2m8rwHwQafr"
      },
      "outputs": [],
      "source": [
        "pf_data['Portfolio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCUvSbymQoGd"
      },
      "outputs": [],
      "source": [
        "InitialPrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDnN55TiRYB3"
      },
      "outputs": [],
      "source": [
        "#pyfolio.create_simple_tear_sheet(pf_data['PF_Rets'].dropna())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6A_wB37TTtPB"
      },
      "outputs": [],
      "source": [
        "OrderedTable, IDEAL_PF, Residue_Cash = ConstructPortfolioTimeSeries(show_df)\n",
        "display(OrderedTable['PF_Value'])\n",
        "ShowTearSheet(OrderedTable['pct_change'].dropna())\n",
        "OrderedTable.to_csv(f\"Best_PF_TimeSeries_{exchange}.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-sPv37mIrNV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-qqiS5EIsDK"
      },
      "source": [
        "PIYASANIN SAĞLIĞI GÖSTERGESİ\n",
        "\n",
        "MS105 nin üzerinde olacak\n",
        "Depremde ve seçimde 0 ın altına düşmüş.\n",
        "Depremde -1\n",
        "Seçimde -0.5\n",
        "maksimuma geldiğinde 3.5\n",
        "\n",
        "MMS 84 göstergesi gayet pürüzsüz veriyor.\n",
        "Negatif sharpe ile LB = 84 iyi olabilir.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyfolio.plot_rolling_sharpe(OrderedTable['pct_change'].dropna(),rolling_window=84, grid=True, figsize=(14, 8))"
      ],
      "metadata": {
        "id": "WbbKh2U42VWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY1fe82RHbZZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "pyfolio.plot_monthly_returns_heatmap(OrderedTable['pct_change'].dropna())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_cSA_onIpa-"
      },
      "outputs": [],
      "source": [
        "\n",
        "pyfolio.plot_drawdown_underwater(OrderedTable['pct_change'].dropna(), grid=True, figsize=(14, 8))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8_d7hL-jurR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zY0Ow_wBS_z5"
      },
      "outputs": [],
      "source": [
        "pystats_df = pf.timeseries.perf_stats(OrderedTable['pct_change'].dropna())\n",
        "max_drawdown = np.abs(100*pf.timeseries.max_drawdown(OrderedTable['pct_change'].dropna()))\n",
        "annual_return = pf.timeseries.annual_return(OrderedTable['pct_change'].dropna())\n",
        "sharpe_ratio = pf.timeseries.sharpe_ratio(OrderedTable['pct_change'].dropna())\n",
        "print(\"NEW PORTFOLIO PERFORMANCE\")\n",
        "pystats_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VQ-L-bsTMGt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMKvQL3PUV2KTqI4IH34CTE",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}