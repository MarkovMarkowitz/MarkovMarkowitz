{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarkovMarkowitz/MarkovMarkowitz/blob/main/MPT_v554_MARKOV_REGIME.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "482b5823-33e2-4457-ae12-57c5795c8344",
      "metadata": {
        "id": "482b5823-33e2-4457-ae12-57c5795c8344"
      },
      "source": [
        "### PROGRAM START AND INSTRUCTIONS <a name=\"start_and_instruct\"></a>"
      ]
    },
    {
      "cell_type": "raw",
      "id": "2a31a180-847d-471d-b76b-632889148159",
      "metadata": {
        "id": "2a31a180-847d-471d-b76b-632889148159"
      },
      "source": [
        "Çalıştırma talimatı:\n",
        "\n",
        "* Interneti aç\n",
        "- Önce elindeki hisse sayısını ve toplam yekunu aşağı gir\n",
        "- Çalıştırdıktan sonra YF_MYPF.csv dosyasını Yahoo Fınance den çağır\n",
        "- Bu dosyayı tekrar MYPF.csv olarak export edip tekrar çalıştır.\n",
        "- Eğer emailine BIST dosyası gelmişse tamam demektir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9c5e0244-0f61-4040-8fba-493857e35724",
      "metadata": {
        "id": "9c5e0244-0f61-4040-8fba-493857e35724",
        "outputId": "dfe7a5f3-9633-4aa2-ec26-b21d8d390bd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1668     ODAS.IS\n",
            "458     KOZAA.IS\n",
            "539     ENKAI.IS\n",
            "171     ALARK.IS\n",
            "326     TCELL.IS\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "CURRENT_T2      = 102901             # FOR BIST 636945\n",
        "\n",
        "MyAssets = [          \"ODAS.IS\",\n",
        "                      \"KOZAA.IS\",\n",
        "                      \"ENKAI.IS\",\n",
        "                      \"ALARK.IS\",\n",
        "                      \"TCELL.IS\"\n",
        "           ]\n",
        "MyShares = [            1668,\n",
        "                        458,\n",
        "                        539,\n",
        "                        171,\n",
        "                        326\n",
        "\n",
        "           ]\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "GecerliPF = pd.Series(MyAssets, MyShares)\n",
        "\n",
        "\n",
        "print(GecerliPF)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "595a3f8d-c9e3-4af6-9266-662e56c1000b",
      "metadata": {
        "id": "595a3f8d-c9e3-4af6-9266-662e56c1000b"
      },
      "source": [
        "### LINE NUMBER COUNT <a name=\"line_number\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "13763fc7-1282-4fcf-97af-44b71efac9e3",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "13763fc7-1282-4fcf-97af-44b71efac9e3"
      },
      "outputs": [],
      "source": [
        "#pandas.set_option('display.max_rows', None)\n",
        "\n",
        "import os\n",
        "root = \"/Users/alperulku/EPAT-99-FINAL PROJECT/EPAT PROJECT WORK\"\n",
        "#os.chdir(root)\n",
        "\n",
        "# with open(f\"MPT_v553_MARKOV_PROCESS.ipynb\", 'r') as fp:\n",
        "#     lines = len(fp.readlines())\n",
        "#     print('Toplam Satır sayısı:', lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "20ec0649-1477-4b69-853d-f3b8d4f482e0",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "20ec0649-1477-4b69-853d-f3b8d4f482e0",
        "outputId": "3b88f781-7da2-486e-cd0d-9b4dc9b6516c",
        "colab": {
          "resources": {
            "http://localhost:8080/MARKOVMAR5.1.png": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bulunulan dizin : /content\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"MARKOVMAR5.1.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# -------------------------\n",
        "#     CONFIGURATION PARAMS\n",
        "# -------------------------\n",
        "\n",
        "version = \"553\"\n",
        "\n",
        "\n",
        "\n",
        "directory_path = os.getcwd()\n",
        "print(\"Bulunulan dizin : \" + directory_path)\n",
        "from IPython.display import Image\n",
        "\n",
        "# get the image\n",
        "Image(url=\"MARKOVMAR5.1.png\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "031e10b9-2a31-43d3-83ba-a25e9c101ffb",
      "metadata": {
        "id": "031e10b9-2a31-43d3-83ba-a25e9c101ffb",
        "outputId": "6e29889d-d3dd-407e-f78a-feb6668f4c92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " BinPortföy V1.553 Portföy Yönetim Sistemi  "
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from IPython.display import Markdown as md\n",
        "\n",
        "string = \" BinPortföy V1.{} Portföy Yönetim Sistemi  \".format(version)\n",
        "\n",
        "md(string)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5c3e137",
      "metadata": {
        "id": "f5c3e137"
      },
      "source": [
        "<h1>BinPortföy &reg; AI Tabanlı Portföy Yönetim Sistemi </h1>\n",
        "<h2>Yapay Zeka Tabanlı Portföy Tasarımı & Performans Raporlama Yazılımı </h2>\n",
        "<h2>Markov Markowitz&reg; Şirketi 2022 - 2023 </h2>\n",
        "<h4>Python ve Markdown kodlama : Alper Ülkü</h4>\n",
        "<h4>Raporlama tarihi: Sys.Date() </h4>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9fcc6495-4ab0-420f-bdb7-90389c61cae2",
      "metadata": {
        "id": "9fcc6495-4ab0-420f-bdb7-90389c61cae2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# -------------------------\n",
        "#     EXCHANGE PARAMETERS\n",
        "# -------------------------\n",
        "\n",
        "risk_free_rate  = 0.25                  # FOR BIST\n",
        "#risk_free_rate = 0.05                  # FOR S&P\n",
        "#risk_free_rate = 0.065                 # FOR NSE\n",
        "\n",
        "#CURRENT_T2     = 35970              00         # FOR S&P\n",
        "#currency       = \"INR\"              0        # FOR NSE\n",
        "currency        = \"TL\"                         # FOR BIST\n",
        "#currency       = \"USD\"                       # FOR S&P\n",
        "\n",
        "# ------------------------------\n",
        "#     FILTER PARAMETERS\n",
        "# ------------------------------\n",
        "\n",
        "Tedbirli_Filtering   = True\n",
        "Sharpe_Std_Filtering = True\n",
        "Corr_Filtering       = True\n",
        "\n",
        "SHARPE_LIMIT   = -2                     # FOR BIST 153\n",
        "STD_LIMIT      = 4                     # FOR BIST  3.5\n",
        "CORR_FILTER    = 0.75\n",
        "\n",
        "# ------------------------------\n",
        "#     FLOATING POINT CONVENTION\n",
        "# ------------------------------\n",
        "\n",
        "pd.options.display.float_format = \"{:,.3f}\".format  # << INPUT\n",
        "\n",
        "# ------------------------------\n",
        "#     SIMULATION PARAMETERS\n",
        "# ------------------------------\n",
        "P_BOUND_HI = 1   # 0.19416                           # << 1 disinda bir degere sinirlayinca getiri azaliyor\n",
        "P_BOUND_LO = 0   # 0.19416                           # << SIFIR KALMASI GEREKIYOR OPTIMIZASYON CONVERGE EDEMIYOR\n",
        "LENGTH     = 100                                         # << INPUT for seperator length\n",
        "CASES      = 50000                                       # << INPUT for $ of cases in the Montecarlo simulation\n",
        "START_DAYS_AGO  = 140    # calibrated for 28.04.2022 on 7.09.22                           # << INPUT for forward testing period\n",
        "BACKTEST_PERIOD = 140    # calibrated for 28.04.2022 on 7.09.22                          # << INPUT for backward testing period\n",
        "FW_TEST_PERIOD  = 0  # calibrated for 28.04.2022 on 7.09.22\n",
        "FW_TEST_LIMIT = 0\n",
        "\n",
        "# ------------------------------\n",
        "#     LIBRARY SETTINGS\n",
        "# ------------------------------\n",
        "# Installing and Importing the libraries\n",
        "\n",
        "#!pip3 install pandas\n",
        "#!pip3 install numpy\n",
        "#!pip3 install matplotlib\n",
        "#!pip3 install seaborn\n",
        "#!pip3 install scipy\n",
        "#!pip3 install nsepy\n",
        "#!pip3 install yfinance\n",
        "\n",
        "\n",
        "# Convert every TL entry to USD in dataframe\n",
        "# pf_data[pf_data.columns].apply(lambda x: x/pf_data['TRY=X'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "73d27fde-fbdd-4a1c-8101-ba2404370385",
      "metadata": {
        "id": "73d27fde-fbdd-4a1c-8101-ba2404370385"
      },
      "outputs": [],
      "source": [
        "# from IPython.display import IFrame, display, HTML\n",
        "# your_variable = 100\n",
        "# html_skin = f\"  <h2 style='color:blue'>Customer Name : {name}</h2>\"\n",
        "# html_skin = f\"  <h2>Customer Name : {name}</h2>\"\n",
        "# display(HTML(html_skin))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0b9fa94-6d7f-4a01-9160-d551719c872a",
      "metadata": {
        "tags": [],
        "id": "f0b9fa94-6d7f-4a01-9160-d551719c872a"
      },
      "source": [
        "### İçindekiler\n",
        "1. [Import Libraries](#import_lib)\n",
        "2. [Compare Assets for Best Sharpe Ratio](#Select_dataset)\n",
        "3. [Set Working Directories ***CHANGE***](#Set_working_dir)\n",
        "4. [Read Raw data file for assets ***CHANGE***](#Read_Raw_Datafile)\n",
        "4. [Read TEDBIRLI HISSELER LISTESI from GEDIK](#Read_Banned)\n",
        "5. [Set Ready-To-Go and Exclusion Lists](#Ready_Asset_List)\n",
        "6. [Clean the Raw Asset List](#Clean_Asset_List)\n",
        "7. [Initialize Global Inputs ***CHANGE***](#Initialize_Globals)\n",
        "8. [Select Backtesting and Forward Testing Dates](#select_dates)\n",
        "9. [Download Data for Backtesting and Prefilter Assets for SR > 3](#Download_BackTest)\n",
        "10. [Filter Correlated Assets with Correlation more than 0.6](#filter_corr)\n",
        "11. [STOCK_LIST BYPASS HERE](#STOCK_LIST_BY_PASS)\n",
        "12. [DOWNLOAD_ASSETS FOR GIVEN DATES](#Download_Assets_For_Dates)\n",
        "13. [Merge All CSV Files to form DF:li](#Merge_All_CSV_Files)\n",
        "14. [Analyzing Data for Backtesting](#Analyze_BackTest)\n",
        "15. [Generate random Markowitz portfolios via Montecarlo for Sharpe Analysis](#Generate_Markowitz)\n",
        "15. [Find Optimal weights For Highest Sharpe Ratio and Least Drawdown](#Least_MDD)\n",
        "16. [Find Optimal weights For Highest Sharpe Ratio](#Optimal_Sharpe)\n",
        "17. [Present Optimal Portfolio For Highest Sharpe Ratio](#Optimal_Portfolio)\n",
        "18. [Present Backtesting Performance](#Backtest_perf)\n",
        "19. [Download Data for Forward Testing Performance](#download_fwtest)\n",
        "20. [Present Forward Testing Performance](#present_fwtest)\n",
        "21. [My Own Manual Portfolio Performance](#my_own)\n",
        "22. [Present My Own Manual Portfolio Performance](#present_own)\n",
        "23. [Create Shopping List for migration to Ideal PF](#shop_list)\n",
        "24. [Send Ideal PF by Gmail](#send_gmail)\n",
        "25. [IDEAL.csv PORTFOLIO PERFORMANCE](#ideal_csv)\n",
        "25. [MYPF.csv PORTFOLIO PERFORMANCE](#mypf.csv_perf)\n",
        "25. [Plot Sector Graph for Ideal PF](#sector_graph)\n",
        "26. [Write Ideal PF to Yahoo Portfolio Compatible CSV file](#yahoo_pf)\n",
        "27. ========= PROGRAM PAUSES HERE for you to export imported yahoo PF into EXPORT.csv ===\n",
        "28. [Read PF From yahoo Portfolio again to calculate Last-Day-Weights of Selected PF](#Update_weights)\n",
        "29. [Portföy Alpha ve Beta Parametrelerinin Hesabı](#alpha_beta)\n",
        "30. [Index ve Portföyümüzün Risk ve Maksimum Çöküş Değerlerinin Hesaplanması](#vol_mdd)\n",
        "31. [Send Ideal PF by Gmail](#send_gmail)\n",
        "31. [IDEAL PORTFÖY PERFORMANSI GÖSTERİMİ](#ideal_pf_perf)\n",
        "32. [My Own Portfolio (EXPORT.CSV) Performance](#my_pf_perf)\n",
        "33. [MYPF.csv PORTFOLIO PERFORMANCE](#mypf.csv_perf)\n",
        "34. [ALPHA BETA CALCULATIONS FOR MYPF](#alphabeta)\n",
        "35. [SHAPIRO-WILK test for NORMALITY](#shapiro)\n",
        "36. [ACF and PACF tests for Stationarity](#acf_pacf)\n",
        "37. [TREND DETECTION AND BUY-SELL SIGNAL GENERATION FOR MYPF](#trend_detect)\n",
        "38. [TIME SERIES STATISTICAL MODELS](#time_series)\n",
        "39. [AUTOREGRESSIVE MODEL OPS](#autoregressive)\n",
        "40. [MICROALPHAS TRAINING](#microalphas)\n",
        "41. [TA-LIB OPERATIONS](#talib_ops)\n",
        "42. [SQL OPERATIONS](#sql_ops)\n",
        "43. [LINE NUMBER COUNT](#line_number)\n",
        "44. [READ ALL PORTFOLIOS FROM YF PAGE](#read_portfolios)\n",
        "45. [READ CUSTOMER INFOS FROM EXCEL FILE](#read_customers)\n",
        "46. [CREATE REPORT FOR PROFORMA INVOICE (BORA)](#bora_invoice)\n",
        "47. [CREATE REPORT FOR PROFORMA INVOICE (COŞKUN)](#coskun_invoice)\n",
        "48. [CREATE REPORT FOR PROFORMA INVOICE (MURAT)](#murat_invoice)\n",
        "49. [CREATE REPORT FOR PROFORMA INVOICE (ALPER)](#alper_invoice)\n",
        "50. [CHECK IF BANNED ASSETS ARE INSIDE CURRENT PF](#BAN_CHECK)\n",
        "60. [SEND_EMAIL_THRU_GMAIL](#SEND_GMAIL)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7821891f-40f0-4d57-bdec-fc1a555fea69",
      "metadata": {
        "tags": [],
        "id": "7821891f-40f0-4d57-bdec-fc1a555fea69"
      },
      "source": [
        "### BİTİRİLEN İŞLER LİSTESİ:\n",
        "1. BinPortföy: En yüksek Sharpe Oranlı portföyün bulunması (12-13)\n",
        "2. BinPortföy: Exchange'deki asset isimlerinin CSV dosyasından okunması ve filtrelenmesi (5-9)\n",
        "3. BinPortföy: Önerilen Portföyün Yahoo Portfolio CSV'e dönüşümü (23'e eklendi)\n",
        "4. BinPortföy: XU100 indexi ile hem grafik hen de beta hesabı yaparak karşılaştır (24)\n",
        "5. BinPortföy: Hindistan borsası NSE eklendi.(4)\n",
        "6. MM: BES'leri bozdur. (8.08.2022)\n",
        "7. MM: Quantinsti Toplantı (10.08.2022)\n",
        "8. MM ile konuş ve şirket kuruluş başvurusunu tamamla (Eylül 2022)\n",
        "9. BinPortföy: XU100 ile portföy performans karşılaştırma tablosu (IDEAL.csv yi XU100 olarak sec)\n",
        "10. BinPortföy: Alış Tarihi, Bugün Tarihi ve grafik dosyalarını eklenmesi, aslında tümü PDF rapor olarak daha iyi görünecek.\n",
        "12. YAHOO PF'den tüm portföy listesinin indirilmesi ve liste halinde incelenmesi (temizleme islemleri halledilecek)\n",
        "13. Baştan sona Markdown Raporunun Word ya da PDF olarak hazırlanması (HTML olarak tamam) şu komut ile halledildi. (7.01.2023) https://wkhtmltopdf.org/downloads.html den macos için yüklemek gerekti. Sonra bunları command line a yazıcaz:\n",
        "\n",
        "!pip install jupyter_contrib_nbextensions\n",
        "!os.chdir(root)\n",
        "!jupyter nbconvert --no-input --to html MPT_v547_PROFORMA_OK.ipynb\n",
        "!wkhtmltopdf MPT_v547_PROFORMA_OK.html MPT_v547_PROFORMA_OK.pdf\n",
        "\n",
        "\n",
        "14. gmail i otomatik gondermede sorun olmamasi icin asagidaki adimlari zaman zaman yapmak gerekir?:\n",
        "\n",
        "Create & use app passwords\n",
        "Important: To create an app password, you need 2-Step Verification on your Google Account.\n",
        "\n",
        "If you use 2-Step-Verification and get a \"password incorrect\" error when you sign in, you can try to use an app password.\n",
        "\n",
        "Go to your Google Account.\n",
        "Select Security\n",
        "Under \"Signing in to Google,\" select 2-Step Verification.\n",
        "At the bottom of the page, select App passwords.\n",
        "Enter a name that helps you remember where you’ll use the app password.\n",
        "Select Generate.\n",
        "To enter the app password, follow the instructions on your screen. The app password is the 16-character code that generates on your device.\n",
        "Select Done.\n",
        "If you’ve set up 2-Step Verification but can’t find the option to add an app password, it might be because:\n",
        "\n",
        "https://myaccount.google.com/apppasswords?utm_source=google-account&utm_medium=myaccountsecurity&utm_campaign=tsv-settings&rapt=AEjHL4NP9qzMEQu5QY6i5d07rZ75hTfoYLvMJSjbsv7MbgBKgC7t866q25VxcHMWZXxxwmdp03CuHqoxMsBEkkpnGzaGqbcBpA\n",
        "\n",
        "Your Google Account has 2-Step Verification set up only for security keys.\n",
        "You’re logged into a work, school, or another organization account.\n",
        "Your Google Account has Advanced Protection.\n",
        "Tip: Usually, you’ll need to enter an app password once per app or device.\n",
        "\n",
        "\n",
        "15. Quantinsti ile anlaşma imzası (associate member)\n",
        "16. Marka başvurusu parasının yatır 1020 TL (15.01.2023)\n",
        "17. BinPortföy: TL Dolara tum pf_data'nın bölünmesi\n",
        "18. Iki python dosyasinin karşılaştırılması için\n",
        "\n",
        "pip install nbdime\n",
        "\n",
        "!nbdiff-web MPT_v550_REPORTLAB_WITH_FUNCTIONS.ipynb MPT_v550A_RELOCATED_MYPF.ipynb\n",
        "\n",
        "### ÖNEMLİ HINDISTAN ELEŞTIRISI:\n",
        "Temel eleştiri reel getirinin hesaplanması gerektiğine yönelik oldu. Onun için ilk olarak\n",
        "tüm pf_data kolonlarının dolar fiyatına bölünmesini sağlamak gerek. 16 maddede halledildi (16.01.2023)\n",
        "\n",
        "### ÖNEMLİ NOT:\n",
        "S&P de BIST te olduğu gibi bir edge yakalanması mümkü değil gibi görünüyor. 100D-140D-183D-365D BK değeri için FW test sonuçları hiç iyi değil => bu durumda pasif olarak sadece %20 civarında spot dolar alıp bekletmek yeterli olacaktır.\n",
        "\n",
        "### TO-DO LIST:\n",
        "01. BinPortföy: CORRELATION FILTER sirasinda en iyi return getirenin seçilmesi\n",
        "02. BinPortföy: RAPOR: Markdown Raporlama metninin hazırlanması (tipik bir raporu indir)\n",
        "03. BinPortföy: RAPOR: Tedbirli hisselerin mevcut MYPF'den ayiklanmasi ve RAPORA eklenmesi\n",
        "04. BinPortföy: RAPOR: Tüm Markdown'un renklendirilmesi\n",
        "05. BinPortföy: RAPOR: Yahoo PF nın scrape edilmesi\n",
        "06. BinPortföy: Tüm programın baştan fonksiyonlara dönüşümü OOP ye uygun olarak\n",
        "07. BinPortföy: Django entegrasyonu\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd0984fe-f913-4e30-becc-c35632709030",
      "metadata": {
        "tags": [],
        "id": "dd0984fe-f913-4e30-becc-c35632709030"
      },
      "source": [
        "### Import Libraries <a name=\"import_lib\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2c6d7054-9d5e-461b-8660-3a349f04c1d9",
      "metadata": {
        "id": "2c6d7054-9d5e-461b-8660-3a349f04c1d9",
        "outputId": "abc9c814-d8c8-4716-fc2f-24edcfd2e8da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nsepy\n",
            "  Downloading nsepy-0.8.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nsepy) (4.11.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nsepy) (2.31.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nsepy) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nsepy) (1.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nsepy) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nsepy) (8.1.7)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nsepy) (4.9.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nsepy) (2.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nsepy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nsepy) (2023.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nsepy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->nsepy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nsepy) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nsepy) (2023.7.22)\n",
            "Building wheels for collected packages: nsepy\n",
            "  Building wheel for nsepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nsepy: filename=nsepy-0.8-py3-none-any.whl size=36057 sha256=08f4dc963805071082b14ba3df9443f1631deb4ab89d0c3ffbd05412d71b8704\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/87/cb/acaf83f625e5fc73e1fe6e2a8e97680c74cd72391850ef5a86\n",
            "Successfully built nsepy\n",
            "Installing collected packages: nsepy\n",
            "Successfully installed nsepy-0.8\n",
            "Bulunulan dizin : /content\n",
            "Dosya ismi: content\n"
          ]
        }
      ],
      "source": [
        "!pip install nsepy\n",
        "\n",
        "# to measure exec time\n",
        "from timeit import default_timer as timer\n",
        "from datetime import date\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.optimize import minimize\n",
        "from nsepy import *\n",
        "\n",
        "#pd.set_option('display.max_rows', None)\n",
        "\n",
        "import os\n",
        "directory_path = os.getcwd()\n",
        "print(\"Bulunulan dizin : \" + directory_path)\n",
        "folder_name = os.path.basename(directory_path)\n",
        "print(\"Dosya ismi: \" + folder_name)\n",
        "\n",
        "from datetime import datetime\n",
        "import time\n",
        "import yfinance as yf\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "860e7095-fcee-4b75-884c-dec3638a7a7d",
      "metadata": {
        "id": "860e7095-fcee-4b75-884c-dec3638a7a7d"
      },
      "outputs": [],
      "source": [
        "def AddToStockList(alist,item):\n",
        "    a = []\n",
        "    for i in alist:\n",
        "        a.append(i)\n",
        "    a.append(item)\n",
        "    return (a)\n",
        "\n",
        "def ConvertOunceToGram( a, b):\n",
        "    multiply = []\n",
        "    for number1, number2 in zip(a,b):\n",
        "        multiply.append(number1 * number2 / 31.103477)\n",
        "    return(multiply)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8690a9eb-1beb-4fd5-8f5f-21f22837ce18",
      "metadata": {
        "tags": [],
        "id": "8690a9eb-1beb-4fd5-8f5f-21f22837ce18"
      },
      "source": [
        "### Compare BIST500 Assets for Best Sharpe Ratio <a name=\"Select_dataset\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "410b7a23-2cfa-46ca-93ed-9be0f363ad7c",
      "metadata": {
        "id": "410b7a23-2cfa-46ca-93ed-9be0f363ad7c"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#start = datetime.date.today() - datetime.timedelta(DELTA)\n",
        "#end   = datetime.date.today()\n",
        "\n",
        "def InvestCompare(startTime, endTime, tickers, STD_LIMIT, SHARPE_LIMIT, START_DAYS_AGO, FW_TEST_PERIOD):\n",
        "    # pull price data from yahoo -- (list(tickers.keys())) = ['^GSPC','^RUT']\n",
        "    import datetime\n",
        "\n",
        "    prices = pd.DataFrame()\n",
        "    #prices = web.DataReader(tickers, \"yahoo\", startTime, endTime)[\"Adj Close\"]\n",
        "    # prices = web.DataReader(SELECTED_EXCHANGE, \"yahoo\", startTime, endTime)[\"Close\"]\n",
        "    print(f\"======================================\")\n",
        "    print(f\"Comparing assets for Sharpe and Std Dev\")\n",
        "    # prices = pdr.get_data_yahoo(SELECTED_EXCHANGE, startTime, endTime)\n",
        "    # cols = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']\n",
        "    # prices.reindex(columns=cols)\n",
        "\n",
        "    names = []\n",
        "\n",
        "    for tick in SELECTED_EXCHANGE:\n",
        "        print(f\"Downloading {tick}\")\n",
        "        yf_tick = yf.Ticker(tick)\n",
        "        df = yf_tick.history(interval='1d', auto_adjust=True, start=T0_START, end=T0_END, back_adjust = True, rounding=True)\n",
        "        df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "        df.dropna(how='all', inplace=True)\n",
        "        prices = pd.concat([prices,df['Close']],axis=1, ignore_index=False)\n",
        "        #st_name = tick.split('.',maxsplit = 1)\n",
        "        names.append(tick)\n",
        "\n",
        "    prices.columns = names\n",
        "    prices= prices.dropna()\n",
        "\n",
        "    # USDTRY CONVERSION\n",
        "    if 'TRY=X' in prices.columns:\n",
        "        for i in prices.columns :\n",
        "            if i != 'GC=F' and i != 'CL=F':\n",
        "                prices[i] = pd.Series(prices[i] / prices['TRY=X'])\n",
        "\n",
        "    returns = np.log(prices) - np.log(prices.shift(1))\n",
        "    returns = returns.iloc[1:, 0:]\n",
        "\n",
        "    investments = pd.DataFrame(returns.std()*100, columns=[\"Standart Sapma %\"])\n",
        "    investments[\"Ortalama Günlük Getiri %\"] = pd.DataFrame(100 * returns.mean())\n",
        "    investments[\"Sharpe Oranı\"] = pd.DataFrame( 100 * (returns.mean() - Rfr_g ) / returns.std())\n",
        "    investments[\"Net Dönem Getirisi %\"] = pd.DataFrame(100 * (returns.sum() - Rfr))\n",
        "    print(investments)\n",
        "    filtered_inv = investments[ (investments['Standart Sapma %'] <= STD_LIMIT   ) &\n",
        "                                (investments['Sharpe Oranı']     >= SHARPE_LIMIT)\n",
        "                              ].sort_values(by=[\"Sharpe Oranı\"], ascending=[False])\n",
        "\n",
        "    return prices, filtered_inv\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1aee4284-8b6d-4caa-820e-70154f223c18",
      "metadata": {
        "id": "1aee4284-8b6d-4caa-820e-70154f223c18"
      },
      "outputs": [],
      "source": [
        "def plot_sector_counts(sector_counts):\n",
        "\n",
        "    bar = plt.subplot2grid((15,24), (0,0), rowspan=12, colspan=12)\n",
        "    pie = plt.subplot2grid((15,24), (0,12), rowspan=12, colspan=12)\n",
        "\n",
        "    # Bar chart\n",
        "    sector_counts.plot(\n",
        "        kind='bar',\n",
        "        color='b',\n",
        "        rot=45,\n",
        "        ax=bar,\n",
        "    )\n",
        "\n",
        "    bar.set_title('Markov Markovitz PF %')\n",
        "\n",
        "    # Pie chart\n",
        "    sector_counts.plot(\n",
        "        kind='pie',\n",
        "        colormap='Set3',\n",
        "        autopct='%.1f %%',\n",
        "        fontsize=8,\n",
        "        ax=pie,\n",
        "    )\n",
        "    pie.set_ylabel('')  # This overwrites default ylabel, which is None :(\n",
        "    pie.set_title('Markov Markowitz PF %')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20676bae-8c31-4639-abd1-d5987bdd1ef6",
      "metadata": {
        "tags": [],
        "id": "20676bae-8c31-4639-abd1-d5987bdd1ef6"
      },
      "source": [
        "### Set Working Directories <a name=\"Set_working_dir\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "890bd9c6-6f8f-43a7-91f8-acd4f0cc6ee1",
      "metadata": {
        "id": "890bd9c6-6f8f-43a7-91f8-acd4f0cc6ee1",
        "outputId": "f5ec5603-3ae0-4c88-eea1-d1538de89a66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filename = /Users/alperulku/EPAT-99-FINAL PROJECT/EPAT PROJECT WORK/BIST30.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/Users/alperulku/EPAT-99-FINAL PROJECT/EPAT PROJECT WORK'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#exchange = \"BIST500\"                   # << INPUT for exchange\n",
        "#exchange = \"SP500\"                      # << INPUT\n",
        "#exchange = \"NSE\"                      # << INPUT\n",
        "#exchange = \"CRYPTOS\"                      # << INPUT\n",
        "exchange = \"BIST30\"\n",
        "\n",
        "dl = \"/Users/alper/Downloads\"           # << INPUT\n",
        "root = f\"E:\\\\ALL_FILES\\\\100_FINANCE\\\\EPAT\\\\ALL MODULES\\\\EPAT-99-FINAL PROJECT\\\\EPAT PROJECT WORK\" # << INPUT\n",
        "drv_path = f\"{root}/chromedriver\"       # << INPUT\n",
        "url = 'https://www.tefas.gov.tr/TarihselVeriler.aspx' # << INPUT\n",
        "\n",
        "dl = \"/Users/alperulku/Downloads\"\n",
        "root = \"/Users/alperulku/EPAT-99-FINAL PROJECT/EPAT PROJECT WORK\"\n",
        "drv_path = f\"{root}/chromedriver\"\n",
        "url = 'https://www.tefas.gov.tr/TarihselVeriler.aspx'\n",
        "wd = f\"{root}/{exchange}\"\n",
        "out = f\"{wd}\" # << INPUT\n",
        "\n",
        "\n",
        "#os.chdir(root)\n",
        "f1 = f\"{wd}.csv\" # << INPUT\n",
        "print(\"filename =\", f1)\n",
        "root\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ae0cf01-ca1b-4d32-b1d8-3c69a26162de",
      "metadata": {
        "tags": [],
        "id": "4ae0cf01-ca1b-4d32-b1d8-3c69a26162de"
      },
      "source": [
        "### Read TEDBIRLI HISSELER LISTESI from GEDIK <a name=\"Read_Banned\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfa6e33e-8cab-4253-bde1-e3f81cdf645d",
      "metadata": {
        "id": "dfa6e33e-8cab-4253-bde1-e3f81cdf645d"
      },
      "source": [
        "Write a new python program to read the table with selector = '#overlay-wrapper > div.row.subcontent > div.large-8.end.medium-6.small-12.columns > div > table' , on the web page \"https://www.gedik.com/bilgi-egitimler/tedbirli-hisseler\", display this table as a dataframe and save this dataframe as csv file. Show comments in your program, show me the most efficient code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "98a6d8d7-84b8-424d-a031-5880aff958c3",
      "metadata": {
        "id": "98a6d8d7-84b8-424d-a031-5880aff958c3"
      },
      "outputs": [],
      "source": [
        "# # Import the required libraries\n",
        "# import requests\n",
        "# import pandas as pd\n",
        "# from bs4 import BeautifulSoup\n",
        "\n",
        "# # Send an HTTP GET request to the web page\n",
        "# response = requests.get(\"https://www.gedik.com/bilgi-egitimler/tedbirli-hisseler\")\n",
        "\n",
        "# # Parse the HTML content\n",
        "# soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "# # Find the table element with the specified selector\n",
        "# table = soup.select_one(\"#overlay-wrapper > div.row.subcontent > div.large-8.end.medium-6.small-12.columns > div > table\")\n",
        "\n",
        "# # Extract the data from the table and store it in a list of rows\n",
        "# data = []\n",
        "# for row in table.find_all(\"tr\"):\n",
        "#     cells = row.find_all(\"td\")\n",
        "#     cells = [cell.text.strip() for cell in cells]\n",
        "#     data.append(cells)\n",
        "\n",
        "# # Create a Pandas DataFrame from the data\n",
        "# TEDBIRLI_DF = pd.DataFrame(data[1:], columns=data[0])\n",
        "\n",
        "# # Display the DataFrame\n",
        "# #print(df)\n",
        "\n",
        "# # Save the DataFrame as a CSV file\n",
        "# TEDBIRLI_HISSELER = TEDBIRLI_DF['TEDBİRLİ HİSSE']+\".IS\"\n",
        "# TEDBIRLI_DF['TEDBİRLİ HİSSE'] += \".IS\"\n",
        "# TEDBIRLI_DF.to_csv(\"tedbirli_hisseler.csv\", index=False)\n",
        "# TEDBIRLI_DF"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08135bb7-9483-4286-8648-ef02d372b3d3",
      "metadata": {
        "tags": [],
        "id": "08135bb7-9483-4286-8648-ef02d372b3d3"
      },
      "source": [
        "### Set Ready-To-Go and Exclusion Lists <a name=\"Ready_Asset_List\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "3c468863-2486-40ec-977e-72c87a8986d0",
      "metadata": {
        "id": "3c468863-2486-40ec-977e-72c87a8986d0"
      },
      "outputs": [],
      "source": [
        "# \"RYSAS.IS\" in TEDBIRLI_HISSELER.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "49fe6afe",
      "metadata": {
        "id": "49fe6afe"
      },
      "outputs": [],
      "source": [
        "\n",
        "stock_list = [ \"AKCNS.IS\",  \"AKSA.IS\" ,\"AKSEN.IS\", \"ALARK.IS\",\"ARDYZ.IS\", \"ARENA.IS\", \"ARSAN.IS\",\"ASELS.IS\",\n",
        "             \"BERA.IS\" ,\"BIMAS.IS\",\"BRYAT.IS\", \"CLEBI.IS\", \"DOHOL.IS\", \"EKGYO.IS\",\"FROTO.IS\",\n",
        "             \"GLYHO.IS\",\"GUBRF.IS\",\"GARAN.IS\", \"GSDHO.IS\", \"HDFGS.IS\", \"HALKB.IS\",\n",
        "             \"HEKTS.IS\",\"IPEKE.IS\",\"INDES.IS\", \"INFO.IS\" , \"ISMEN.IS\",\n",
        "             \"KAREL.IS\",\"KRDMD.IS\", \"KORDS.IS\", \"KARSN.IS\",\n",
        "             \"KOZAA.IS\",\"MGROS.IS\", \"ODAS.IS\" , \"OTKAR.IS\", \"PGSUS.IS\", \"PKART.IS\",\"PETKM.IS\",\n",
        "             \"SASA.IS\" ,\"SKTAS.IS\", \"SKBNK.IS\", \"SOKM.IS\" ,\n",
        "             \"TAVHL.IS\",\"TTRAK.IS\",\"TCELL.IS\", \"TOASO.IS\", \"TSKB.IS\" , \"TURSG.IS\", \"TKFEN.IS\",\n",
        "             \"TUPRS.IS\",\"VESBE.IS\", \"VAKBN.IS\", \"VESTL.IS\", \"YKBNK.IS\", \"YATAS.IS\", \"AEFES.IS\"]\n",
        "\n",
        "BIST100 = [\n",
        "\n",
        "           \"AEFES.IS\", \"AKSEN.IS\",\"ALARK.IS\", \"ARCLK.IS\", \"ARDYZ.IS\", \"ARSAN.IS\", \"BIMAS.IS\",\n",
        "           \"GARAN.IS\",\"GSDHO.IS\",\"HDFGS.IS\", \"INFO.IS\" , \"ISCTR.IS\", \"ISMEN.IS\", \"BRYAT.IS\", \"DOHOL.IS\",\n",
        "           \"KAREL.IS\",\"KCHOL.IS\",\"KRDMD.IS\", \"SISE.IS\" , \"SKTAS.IS\",  \"EKGYO.IS\", \"ENJSA.IS\",\n",
        "           \"THYAO.IS\",\"TUPRS.IS\",\"VESBE.IS\", \"BERA.IS\" , \"XU100.IS\", \"CLEBI.IS\", \"GLYHO.IS\", \"GUBRF.IS\",\n",
        "           \"HEKTS.IS\",\"INDES.IS\",\"SASA.IS\" , \"TTRAK.IS\", \"PKART.IS\", \"FROTO.IS\", \"HALKB.IS\", \"IPEKE.IS\",\n",
        "           \"KORDS.IS\",\"EREGL.IS\", \"KCHOL.IS\", \"ASELS.IS\", \"YKBNK.IS\", \"PETKM.IS\",\n",
        "           \"INDES.IS\",\"ARENA.IS\",\"KOZAA.IS\", \"KOZAL.IS\", \"MGROS.IS\", \"ODAS.IS\" , \"OTKAR.IS\", \"PGSUS.IS\",\n",
        "           \"SAHOL.IS\",\"SKBNK.IS\",\"SOKM.IS\" , \"TCELL.IS\", \"TOASO.IS\", \"TSKB.IS\" , \"TTKOM.IS\", \"TURSG.IS\",\n",
        "           \"VAKBN.IS\",\"VESTL.IS\",\"ADESE.IS\", \"AEFES.IS\", \"AKSA.IS\" , \"ALGYO.IS\", \"ALKIM.IS\",\n",
        "           \"AYDEM.IS\",\"BAGFS.IS\",\n",
        "           \"ALGYO.IS\", \"BRMEN.IS\", \"CANTE.IS\", \"CCOLA.IS\", \"CEMAS.IS\", \"CIMSA.IS\",\n",
        "           \"CMENT.IS\", \"DEVA.IS\",  \"DOAS.IS\",  \"DOHOL.IS\", \"ENKAI.IS\",\n",
        "           \"ERBOS.IS\", \"ETILR.IS\", \"GOZDE.IS\", \"ISBIR.IS\",\n",
        "           \"ISDMR.IS\", \"ISFIN.IS\", \"ISYAT.IS\", \"IZMDC.IS\", \"KARTN.IS\", \"KERVT.IS\", #GCM'de sorunlu - TBORG ve KENT\n",
        "           \"KLNMA.IS\", \"MAVI.IS\",  \"NTHOL.IS\",  \"OYAKC.IS\",\n",
        "           \"PARSN.IS\", \"PETKM.IS\", \"QNBFL.IS\", \"QUAGR.IS\", \"RTALB.IS\", \"SARKY.IS\",\n",
        "           \"SELEC.IS\", \"TKNSA.IS\", \"TRGYO.IS\", \"ULKER.IS\", #\"UTPYA.IS\",\n",
        "           \"VERUS.IS\", \"YATAS.IS\", \"ZOREN.IS\",\n",
        "           \"AKBNK.IS\", \"EGEEN.IS\", \"TAVHL.IS\", \"KARSN.IS\", \"ECILC.IS\", \"TKFEN.IS\",\n",
        "          # \"TRY=X\"   , \"GC=F\"\n",
        "            ]\n",
        "\n",
        "MINUS = [ \"ISGYO.IS\"  ]\n",
        "\n",
        "TI3 = [\n",
        "        # \"ANHYT.IS\",\n",
        "        \"ANSGR.IS\",\n",
        "        \"ISCTR.IS\",\n",
        "        \"ISFIN.IS\",\n",
        "        # \"ISGSY.IS\",\n",
        "        \"ISGYO.IS\",\n",
        "        \"ISMEN.IS\",\n",
        "        \"ISYAT.IS\",\n",
        "        \"SISE.IS\",\n",
        "        \"TSGYO.IS\",\n",
        "        \"TSKB.IS\",\n",
        "      ]\n",
        "\n",
        "DOW30 =[\n",
        "         \"AXP\",\"AMGN\",\"AAPL\",\"BA\",\"CAT\",\"CSCO\",\"CVX\",\"GS\",\"HD\",\"HON\",\"IBM\",\"INTC\",\n",
        "          \"JNJ\",\"KO\",\"JPM\",\"MCD\",\"MMM\",\"MRK\",\"MSFT\",\"NKE\",\"PG\",\"TRV\",\"UNH\",\"CRM\",\n",
        "          \"VZ\",\"V\",\"WBA\",\"WMT\",\"DIS\",\"DOW\"]\n",
        "\n",
        "NASDAQ30 = [\n",
        "                \"AMGN\",\n",
        "                \"MAR\",\n",
        "                \"ATVI\",\n",
        "                \"SBUX\",\n",
        "                \"DLTR\",\n",
        "                \"PCAR\",\n",
        "                \"MDLZ\",\n",
        "                \"SIRI\",\n",
        "                \"KDP\",\n",
        "                \"HON\",\n",
        "                \"FISV\",\n",
        "                \"VRSK\",\n",
        "                \"VRSN\",\n",
        "                \"AZN\",\n",
        "                \"BIDU\",\n",
        "                \"AMAT\",\n",
        "                \"MRNA\",\n",
        "                \"FTNT\",\n",
        "                \"CEG\",\n",
        "                \"ZS\",\n",
        "                \"ZM\",\n",
        "                \"JD\",\n",
        "                \"MCH\",\n",
        "                \"AAPL\",\n",
        "                \"MRVL\",\n",
        "                \"INTU\",\n",
        "                \"DOCU\",\n",
        "                \"MELI\",\n",
        "                \"ILMN\",\n",
        "                \"TSLA\"\n",
        "            ]\n",
        "\n",
        "CRYPTOS = [\n",
        "\n",
        "\"BTC-USD\",\n",
        "\"ETH-USD\",\n",
        "\"USDT-USD\",\n",
        "\"BNB-USD\",\n",
        "\"USDC-USD\",\n",
        "\"XRP-USD\",\n",
        "\"SOL-USD\",\n",
        "\"LUNA1-USD\",\n",
        "\"ADA-USD\",\n",
        "\"HEX-USD\",\n",
        "\"AVAX-USD\",\n",
        "\"UST-USD\",\n",
        "#\"DOT-USD\",\n",
        "\"DOGE-USD\",\n",
        "\"BUSD-USD\",\n",
        "\"SHIB-USD\",\n",
        "\"WBTC-USD\",\n",
        "\"MATIC-USD\",\n",
        "\"STETH-USD\",\n",
        "\"NEAR-USD\",\n",
        "\"CRO-USD\",\n",
        "\"DAI-USD\",\n",
        "\"LTC-USD\",\n",
        "\"TRX-USD\",\n",
        "#\"WTRX-USD\",\n",
        "\"ATOM-USD\",\n",
        "\"LINK-USD\",\n",
        "\"UNI1-USD\",\n",
        "\"BCH-USD\",\n",
        "\"LEO-USD\"\n",
        "\n",
        "          ]\n",
        "\n",
        "USD_EUR = [\"TRY=X\", \"EURTRY=X\"]\n",
        "USDTR_GOLD = [\"GC=F\", \"TRY=X\", \"EURTRY=X\"]\n",
        "Metals = [\"GC=F\", \"TRY=X\",  \"SI=F\"]\n",
        "Metals_Oil = [\"GC=F\",  \"SI=F\", \"CL=F\"]\n",
        "Gold_Oil_ETFS = [\"AAAU\",  \"GDX\", \"OIL\"]\n",
        "\n",
        "\n",
        "Exotics = [ \"BTC-USD\", \"ETH-USD\" ]\n",
        "'''\n",
        "UTILITY U=017 : SET_WORKING_AND DOWNLOADS_DIR_PATHS\n",
        "--------------------------------------------\n",
        "- SETS variables for working directory (as may change from compuet to computer)\n",
        "- SETS downloads directory (as may change from compuet to computer)\n",
        "- SETS download web site\n",
        "'''\n",
        "# stock_list = Filtered_Stocks\n",
        "\n",
        "BIST500_A = [ \"OYAYO.IS\", \"KLKIM.IS\", \"LINK.IS\", \"IDEAS.IS\", \"KRGYO.IS\", \"PINSU.IS\",\"MNDRS.IS\",\n",
        "              \"PEGYO.IS\", \"OLMK.IS\", \"ULUUN.IS\", \"MARTI.IS\", \"TIRE.IS\",\n",
        "              \"SANFM.IS\", \"BLCYT.IS\", \"IZFAS.IS\", \"FONET.IS\",\"KAPLM.IS\", \"YAYLA.IS\", \"KONYA.IS\"]\n",
        "\n",
        "Exclusion_SP500 = [ \"XLNX\", \"WYN\", \"WLTW\", \"HCN\",\"VIAB\", \"VAR\", \"UTX\", \"TSS\", \"TMK\", \"TWX\", \"TIF\",\n",
        "                    \"SYMC\", \"STI\", \"SNI\", \"SCG\", \"COL\", \"RHT\", \"RTN\", \"PCLN\", \"PBCT\", \"NBL\",\n",
        "                    \"NFX\", \"MYL\", \"KORS\", \"LUK\", \"LB\", \"KSU\", \"JEC\", \"INFO\", \"HRS\", \"GGP\",\n",
        "                    \"FLIR\", \"ESRX\", \"EVHC\", \"ETFC\", \"DPS\", \"DWDP\", \"DISCK\", \"DISCA\", \"CSRA\",\n",
        "                    \"CXO\", \"XEC\", \"CTL\", \"CELG\", \"CBS\", \"CBG\", \"COG\", \"CA\", \"BF.B\", \"BRK.B\",\n",
        "                    \"BBT\", \"BHGE\", \"ANDV\", \"ADS\", \"AGN\", \"ALXN\", \"AET\", \"APC\", \"CERN\", \"MON\",\n",
        "                    \"NWSA\", \"WBA\", \"ANTM\", \"BLL\", \"BRK.B\", \"BF.B\"\n",
        "                 ]\n",
        "\n",
        "EX = [\n",
        "                     \"ADANA.IS\", \"ADBGR.IS\", \"ADNAC.IS\", \"AFMAS.IS\",\"AKFEN.IS\", \"AKGUV.IS\", \"AKPAZ.IS\", \"ALNTF.IS\",\n",
        "                     \"ALTIN.IS\", \"ALYAG.IS\", \"ANACM.IS\", \"ANSA.IS\" ,\"ARFYO.IS\", \"ARTOG.IS\", \"ASLAN.IS\", \"ASYAB.IS\",\n",
        "                     \"ATAC.IS\",  \"ATPET.IS\", \"AVIVA.IS\", \"BAYRD.IS\", \"BISAS.IS\", \"BMEKS.IS\", \"BOLUC.IS\",\n",
        "                     \"BOYNR.IS\", \"BROVA.IS\", \"BSHEV.IS\", \"CARFA.IS\", \"CARFB.IS\", \"CBSBO.IS\",\n",
        "                     \"COMDO.IS\", \"DENCM.IS\", \"DENIZ.IS\", \"DENTA.IS\", \"DNZYO.IS\", \"DYHOL.IS\",\n",
        "                     \"ECBYO.IS\", \"ECYAP.IS\", \"EGLYO.IS\", \"EGYO.IS\", \"EMBYO.IS\", \"ESEMS.IS\",\n",
        "                     \"EUROM.IS\", \"FFKRL.IS\", \"FINBN.IS\", \"FNSYO.IS\", \"FONFK.IS\", \"FVORI.IS\",\n",
        "                     \"GDKGS.IS\", \"GDKYO.IS\", \"GUSGR.IS\", \"HITIT.IS\", \"HZNDR.IS\", \"ICGYH.IS\",\n",
        "                     \"IDAS.IS\",  \"IHMAD.IS\", \"ISGSY.IS\", \"ISKUR.IS\", \"ISYHO.IS\", \"KARKM.IS\",\n",
        "                     \"KILER.IS\", \"KLBMO.IS\", \"KOMHL.IS\", \"KPHOL.IS\", \"KRATL.IS\", \"KRSAN.IS\",\n",
        "                     \"KSTUR.IS\", \"LATEK.IS\", \"LTHOL.IS\", \"MANGO.IS\", \"MATAS.IS\", \"MCTAS.IS\",\n",
        "                     \"MRDIN.IS\", \"MRTGG.IS\", \"MUTLU.IS\", \"NTTUR.IS\", \"OLMIP.IS\", \"OZBAL.IS\",\n",
        "                     \"PIMAS.IS\", \"PRTAS.IS\", \"PTOFS.IS\", \"RANLO.IS\", \"SAFGY.IS\", \"SODA.IS\",\n",
        "                     \"TACTR.IS\", \"TARAF.IS\", \"TATKS.IS\", \"TCRYO.IS\", \"TEBNK.IS\", \"TEKST.IS\",\n",
        "                     \"TEPAS.IS\", \"TKURU.IS\", \"TRKCM.IS\", \"TRNSK.IS\", \"TUDDF.IS\", \"UCAK.IS\",\n",
        "                     \"UNYEC.IS\", \"UYUM.IS\", \"VKBYO.IS\",  \"YKGYO.IS\", \"YKSGR.IS\",\n",
        "                     \"DGZTE.IS\", \"SKPLC.IS\", \"YAZIC.IS\", \"YKBYO.IS\", \"ADEL.IS\",  \"ASCEL.IS\",\n",
        "     ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Exclusion_BIST500 = [\n",
        "                     \"ATSYH.IS\",\n",
        "                     \"ADANA.IS\", \"ADBGR.IS\", \"ADNAC.IS\", \"AFMAS.IS\",\"AKFEN.IS\", \"AKGUV.IS\", \"AKPAZ.IS\", \"ALNTF.IS\",\n",
        "                     \"ALTIN.IS\", \"ALYAG.IS\", \"ANACM.IS\", \"ANSA.IS\" ,\"ARFYO.IS\", \"ARTOG.IS\", \"ARTI.IS\",  \"ASLAN.IS\", \"ASYAB.IS\",\n",
        "                     \"ATAC.IS\",  \"ATPET.IS\", \"AVIVA.IS\", \"BAYRD.IS\", \"BISAS.IS\", \"BMEKS.IS\",\"BOLUC.IS\", \"BMELK.IS\",\n",
        "                     \"BOYNR.IS\", \"BROVA.IS\", \"BSHEV.IS\", \"CARFA.IS\", \"CARFB.IS\", \"CBSBO.IS\", \"CASA.IS\",\n",
        "                     \"COMDO.IS\", \"DENCM.IS\", \"DENIZ.IS\", \"DENTA.IS\", \"DNZYO.IS\", \"DYHOL.IS\", \"DARDL.IS\", \"DIRIT.IS\",\n",
        "                     \"ECBYO.IS\", \"ECYAP.IS\", \"EGLYO.IS\", \"EGYO.IS\",  \"EMBYO.IS\", \"ESEMS.IS\", \"EGCEY.IS\", \"EGCYO.IS\", \"EGCYH.IS\", \"EPLAS.IS\",\n",
        "                     \"EUROM.IS\", \"FFKRL.IS\", \"FINBN.IS\", \"FNSYO.IS\", \"FONFK.IS\", \"FVORI.IS\", \"EKIZ.IS\",\n",
        "                     \"GDKGS.IS\", \"GDKYO.IS\", \"GUSGR.IS\", \"HITIT.IS\", \"HZNDR.IS\", \"ICGYH.IS\",\n",
        "                     \"IDAS.IS\",  \"IHMAD.IS\", \"ISGSY.IS\", \"ISKUR.IS\", \"ISYHO.IS\", \"KARKM.IS\",\n",
        "                     \"KILER.IS\", \"KLBMO.IS\", \"KOMHL.IS\", \"KPHOL.IS\", \"KRATL.IS\", \"KRSAN.IS\",\n",
        "                     \"KSTUR.IS\", \"LATEK.IS\", \"LTHOL.IS\", \"MANGO.IS\", \"MATAS.IS\", \"MCTAS.IS\",\n",
        "                     \"MRDIN.IS\", \"MRTGG.IS\", \"MUTLU.IS\", \"NTTUR.IS\", \"OLMIP.IS\", \"OZBAL.IS\",\n",
        "                     \"PIMAS.IS\", \"PRTAS.IS\", \"PTOFS.IS\", \"RANLO.IS\", \"SAFGY.IS\", \"SODA.IS\",\n",
        "                     \"TACTR.IS\", \"TARAF.IS\", \"TATKS.IS\", \"TCRYO.IS\", \"TEBNK.IS\", \"TEKST.IS\",\n",
        "                     \"TEPAS.IS\", \"TKURU.IS\", \"TRKCM.IS\", \"TRNSK.IS\", \"TUDDF.IS\", \"UCAK.IS\",\n",
        "                     \"UNYEC.IS\", \"UYUM.IS\", \"VKBYO.IS\",  \"YKGYO.IS\", \"YKSGR.IS\", \"ISATR.IS\",\n",
        "                     \"DGZTE.IS\", \"SKPLC.IS\", \"YAZIC.IS\", \"YKBYO.IS\", \"ADEL.IS\",  \"ASCEL.IS\", \"ACSEL.IS\",\n",
        "                     \"FENER.IS\", \"GSRAY.IS\", \"TSPOR.IS\", \"COSMO.IS\", \"BRKO.IS\",  \"SELGD.IS\", #TAKIM HİSSELERİNE GÜVENMIYORUZ\n",
        "                     \"EUKYO.IS\", \"ORMA.IS\", \"DURDO.IS\", \"CMENT.IS\",  \"MERKO.IS\", \"BFREN.IS\", \"YBTAS.IS\", \"TIRE.IS\", \"BAKAB.IS\", \"MERIT.IS\"\n",
        "                    ]\n",
        "\n",
        "\n",
        "    # son 4 ü yine alımda risk formu istiyor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "YASAKLI_BIST500 = [   \"ADESE.IS\", \"KRTEK.IS\",\n",
        "                     \"ATSYH.IS\", \"AKSUE.IS\", \"ARASE.IS\", \"ASUZU.IS\", \"ATAGY.IS\", \"ATSYH.IS\", \"AVOD.IS\", \"BAKAB.IS\"\n",
        "                     \"BRMEN.IS\", \"BRYAT.IS\", \"CRDFA.IS\", \"DERHL.IS\", \"DESA.IS\", \"DOGUB.IS\", \"DYOBY.IS\", \"ELITE.IS\",\n",
        "                     \"FADE.IS\",  \"GLBMD.IS\",  \"GRNYO.IS\",  \"HEDEF.IS\", \"HKTM.IS\", \"HUNER.IS\", \"IEYHO.IS\", \"IHAAS.IS\",\n",
        "                     \"INVEO.IS\", \"ISFIN.IS\", \"KAPLM.IS\", \"KIMMR.IS\", \"KMPUR.IS\", \"KZBGY.IS\", \"MEGAP.IS\", \"MERKO.IS\",\n",
        "                     \"MTRKS.IS\", \"NTGAZ.IS\", \"NTHOL.IS\", \"PAGYO.IS\", \"PETUN.IS\", \"PINSU.IS\", \"RODRG.IS\", \"ROYAL.IS\",\n",
        "                     \"SUWEN.IS\", \"TEKTU.IS\", \"ULUFA.IS\", \"UNLU.IS\",  \"ZOREN.IS\", \"ZRGYO.IS\",\n",
        "                     \"TSKB.IS\",  \"SKBNK.IS\", \"ISGYO.IS\", \"SERVE.IS\", \"UTPYA.IS\", \"XU100.IS\",\n",
        "\n",
        "                    ]\n",
        "\n",
        "\n",
        "Exclusion_NSE = [ 'MOTHERSUMI.NS','RUCHI.NS', 'MINDAIND.NS', 'SUPPETRO.NS', 'COSMOFILMS.NS',\n",
        "                  'SHIL.NS', 'SHIL.NS', 'KPIGLOBAL.NS', 'EMAMIPAP.NS', 'EMAMIPAP.NS',\n",
        "                  'ARTEMISMED.NS', 'KOKUYOCMLN.NS', 'BETA.NS', 'ZUARIGLOB.NS', 'BBTCL.NS',\n",
        "                  'INNOVANA.NS', 'CEBBCO.NS','KNAGRI.NS','NRL.NS','ROHITFERRO.NS',\n",
        "                  'EMKAYTOOLS.NS', 'PENTAGOLD.NS', 'KOTYARK.NS', 'EUROBOND.NS','SIGMA.NS',\n",
        "                  'BEWLTD.NS','SHIGAN.NS','MADHAVBAUG.NS','OSIAHYPER.NS','PAVNAIND.NS',\n",
        "                  'JAINAM.NS',\n",
        "\n",
        "\n",
        "\n",
        "                ]\n",
        "\n",
        "BIST30YENI = [ 'AKBNK.IS', 'ASTOR.IS','ALARK.IS','ARCLK.IS','ASELS.IS', 'BIMAS.IS', 'BRMEN.IS', 'CMENT.IS','EKGYO.IS',\n",
        "           'ENKAI.IS', 'EREGL.IS', 'FROTO.IS', 'GARAN.IS', 'GUBRF.IS', 'HEKTS.IS','ISCTR.IS', 'ISBIR.IS', 'KENT.IS',\n",
        "           'KOZAA.IS', 'KOZAL.IS', 'KCHOL.IS', 'KLNMA.IS', 'KRDMD.IS', 'ODAS.IS', 'PETKM.IS', 'PGSUS.IS', 'QNBFB.IS','IZINV.IS',\n",
        "           'SAHOL.IS', 'SASA.IS', 'SISE.IS', 'SNKRN.IS','TAVHL.IS', 'TBORG.IS','TCELL.IS', 'THYAO.IS', 'TOASO.IS',\n",
        "           'TUPRS.IS', 'YKBNK.IS']\n",
        "\n",
        "\n",
        "BIST30 = [ 'AKBNK.IS', 'AKSEN.IS','ALARK.IS','ARCLK.IS','ASELS.IS','BIMAS.IS','EKGYO.IS',\n",
        "           'ENKAI.IS', 'EREGL.IS', 'FROTO.IS', 'GARAN.IS', 'GUBRF.IS', 'HEKTS.IS','ISCTR.IS',\n",
        "           'KOZAA.IS', 'KOZAL.IS', 'KCHOL.IS', 'KRDMD.IS', 'ODAS.IS', 'PETKM.IS', 'PGSUS.IS',\n",
        "           'SAHOL.IS', 'SISE.IS', 'TAVHL.IS', 'TCELL.IS', 'THYAO.IS', 'TOASO.IS',\n",
        "           'TUPRS.IS', 'YKBNK.IS']\n",
        "\n",
        "BIST30YENI = [ 'AKBNK.IS', 'ASTOR.IS','ALARK.IS','ARCLK.IS','ASELS.IS', 'BIMAS.IS', 'BRMEN.IS', 'CMENT.IS','EKGYO.IS',\n",
        "           'ENKAI.IS', 'EREGL.IS', 'FROTO.IS', 'GARAN.IS', 'GUBRF.IS', 'HEKTS.IS','ISCTR.IS', 'ISBIR.IS', 'KENT.IS',\n",
        "           'KOZAA.IS', 'KOZAL.IS', 'KCHOL.IS', 'KLNMA.IS', 'KRDMD.IS', 'ODAS.IS', 'PETKM.IS', 'PGSUS.IS', 'QNBFB.IS','IZINV.IS',\n",
        "           'SAHOL.IS', 'SASA.IS', 'SISE.IS', 'SNKRN.IS','TAVHL.IS', 'TBORG.IS','TCELL.IS', 'THYAO.IS', 'TOASO.IS',\n",
        "           'TUPRS.IS', 'YKBNK.IS']\n",
        "\n",
        "\n",
        "#ILAVE = [ 'PRZMA.IS',\t\"CANTE\", 'PEGYO.IS', 'ANSGR.IS',\t'VAKKO.IS',\t'QUAGR.IS','MGROS.IS',\t'AKCNS.IS' ] #,   'CANTE.IS' ]\n",
        "ILAVE = [ \t'QUAGR.IS' , \"TURSG.IS\"] # 'CANTE.IS', \"EUPWR.IS\",\"AEFES.IS\", \"TRGYO.IS\"  ]\n",
        "\n",
        "\n",
        "TR_ADDITIONS= [ \"EURTRY=X\", \"TRY=X\"]\n",
        "#TR_ADDITIONS= [\"QUAGR.IS\", \"CANTE.IS\"]\n",
        "US_ADDITIONS= [ \"CL=F\", \"GC=F\"]\n",
        "\n",
        "BIST30 = BIST30 + ILAVE\n",
        "\n",
        "\n",
        "# USDTRY CONVERSION\n",
        "\n",
        "def AddTRYXToStockList(sl):\n",
        "    if exchange == \"BIST500\" or exchange == \"BIST30\":\n",
        "        if 'TRY=X' not in sl:\n",
        "            sl = AddToStockList(sl, 'TRY=X')\n",
        "            return sl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "38256cd7-b702-40c7-876c-9fb0994ce7fb",
      "metadata": {
        "id": "38256cd7-b702-40c7-876c-9fb0994ce7fb"
      },
      "outputs": [],
      "source": [
        "def SelectExchange(exchange):\n",
        "\n",
        "    # \"CANTE.IS\",\n",
        "\n",
        "    if  \"BIST500\" in f1:\n",
        "        df = pd.read_csv(f1, delimiter = \";\")\n",
        "        df.Kod = df.Kod + \".IS\"\n",
        "        BIST500 = df.Kod      # << INPUT\n",
        "        #s_row = pd.Series([\"XU100.IS\", \"CANTE.IS\", \"QUAGR.IS\", \"TRY=X\", \"EURTRY=X\", \"GC=F\"])    # INPUT eğer dolar euro altın eklenecek ise\n",
        "        s_row = pd.Series(TR_ADDITIONS)\n",
        "        BIST500 = BIST500.append(s_row,ignore_index=True)\n",
        "        SELECTED_EXCHANGE = BIST500\n",
        "\n",
        "    elif  \"BIST30\" in f1:\n",
        "        SELECTED_EXCHANGE = BIST30\n",
        "\n",
        "    elif \"SP500\" in f1:\n",
        "        # df = pd.read_csv(f1)\n",
        "        # SP500 = df.Symbol      # << INPUT\n",
        "        url = r'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
        "        #url = r'https://www.wikiwand.com/en/List_of_companies_listed_on_the_National_Stock_Exchange_of_India'\n",
        "        tables = pd.read_html(url) # Returns list of all tables on page\n",
        "        sp500_table = tables[0] # Select table of interest\n",
        "        SELECTED_EXCHANGE = sp500_table.Symbol\n",
        "        s_row = pd.Series(US_ADDITIONS)\n",
        "        SELECTED_EXCHANGE = SELECTED_EXCHANGE.append(s_row,ignore_index=True)\n",
        "\n",
        "\n",
        "    elif \"NSE\" in f1:\n",
        "        df = pd.read_excel(\"MCAP31032022.xlsx\")\n",
        "        df.Symbol = df.Symbol + \".NS\"\n",
        "        NSE500 = df.Symbol      # << INPUT\n",
        "        SELECTED_EXCHANGE = NSE500.sample(500)\n",
        "\n",
        "\n",
        "    elif \"CRYPTOS\" in f1:\n",
        "        SELECTED_EXCHANGE = CRYPTOS\n",
        "\n",
        "    return(SELECTED_EXCHANGE)\n",
        "\n",
        "SELECTED_EXCHANGE = SelectExchange(exchange)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "849c8aff-22ed-4883-afbe-efbc21a84241",
      "metadata": {
        "tags": [],
        "id": "849c8aff-22ed-4883-afbe-efbc21a84241"
      },
      "source": [
        "### Clean the Raw Asset Lists using Exclusion Lists <a name=\"Clean_Asset_List\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "61ab0a4a-8500-410d-bed6-9c9fbdbd592c",
      "metadata": {
        "id": "61ab0a4a-8500-410d-bed6-9c9fbdbd592c",
        "outputId": "061e751b-3190-4b84-9ae6-8a3e5ba100e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "type(SELECTED_EXCHANGE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9aa43182-86c9-4122-9b48-d8e6a730edbe",
      "metadata": {
        "id": "9aa43182-86c9-4122-9b48-d8e6a730edbe",
        "outputId": "90b80b41-7f3c-4892-b2aa-d69bcffc92c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(SELECTED_EXCHANGE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "095aac00-4197-439c-a9a2-616eb6c71d3e",
      "metadata": {
        "id": "095aac00-4197-439c-a9a2-616eb6c71d3e"
      },
      "outputs": [],
      "source": [
        "def Clean_List(my_list, exclusion_list):\n",
        "    new_list = []\n",
        "    count = 0\n",
        "    for i in my_list:\n",
        "        if i in exclusion_list:\n",
        "            continue\n",
        "        else:\n",
        "            new_list.append(i)\n",
        "    return new_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "594648c2-eec5-4d5d-a118-eba781f5df38",
      "metadata": {
        "id": "594648c2-eec5-4d5d-a118-eba781f5df38"
      },
      "outputs": [],
      "source": [
        "def flatten(input):\n",
        "    new_list = []\n",
        "    for i in input:\n",
        "        for j in i:\n",
        "            new_list.append(j)\n",
        "    return new_list\n",
        "\n",
        "\n",
        "if  exchange == \"BIST500\":\n",
        "    if Tedbirli_Filtering:\n",
        "        temp = list(Clean_List( pd.DataFrame(SELECTED_EXCHANGE).values,   pd.DataFrame(Exclusion_BIST500).values ))\n",
        "        temp = list(Clean_List( pd.DataFrame(temp).values,                pd.DataFrame(YASAKLI_BIST500).values ))\n",
        "        # temp = list(Clean_List( pd.DataFrame(temp).values,                pd.DataFrame(TEDBIRLI_HISSELER).values ))\n",
        "        SELECTED_EXCHANGE = flatten(temp)\n",
        "\n",
        "#     SELECTED_EXCHANGE = Clean_List(   SELECTED_EXCHANGE, Exclusion_BIST500  )\n",
        "#     SELECTED_EXCHANGE = Clean_List(   SELECTED_EXCHANGE, YASAKLI_BIST500    )\n",
        "#     SELECTED_EXCHANGE = Clean_List(   SELECTED_EXCHANGE, TEDBIRLI_HISSELER  )\n",
        "\n",
        "elif exchange == \"SP500\":\n",
        "    temp = Clean_List( SELECTED_EXCHANGE,   Exclusion_SP500 )\n",
        "    SELECTED_EXCHANGE = temp\n",
        "elif exchange == \"NSE\":\n",
        "    temp = Clean_List( SELECTED_EXCHANGE,   Exclusion_NSE )\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "576ca896-0dcd-4cf2-bc6c-bc4e5df80feb",
      "metadata": {
        "id": "576ca896-0dcd-4cf2-bc6c-bc4e5df80feb",
        "outputId": "2d63af72-395f-42bc-ec41-8b33f4b5b8d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "\"GDKGS.IS\" in SELECTED_EXCHANGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "976b91c2-1b5b-43eb-81eb-1dd63361c6b8",
      "metadata": {
        "id": "976b91c2-1b5b-43eb-81eb-1dd63361c6b8",
        "outputId": "d2ea2264-9e9b-4933-d578-a9dabc95615b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31,)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "np.shape(SELECTED_EXCHANGE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "1e6fd19f-88bc-4231-8bb3-43f7b9ec645b",
      "metadata": {
        "id": "1e6fd19f-88bc-4231-8bb3-43f7b9ec645b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b4ae9d92-a0a5-4539-8547-cd704d1661fc",
      "metadata": {
        "id": "b4ae9d92-a0a5-4539-8547-cd704d1661fc",
        "outputId": "94774bf4-d244-4faf-da17-0711aa8a2059",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "len(SELECTED_EXCHANGE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "91c2ebcf-6974-4c00-a73d-9885ac4d573c",
      "metadata": {
        "id": "91c2ebcf-6974-4c00-a73d-9885ac4d573c"
      },
      "outputs": [],
      "source": [
        "# \"BAKAB.IS\" in pd.DataFrame(TEDBIRLI_HISSELER).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7ddc34a2-fc58-4c58-8d00-ee4b124ca893",
      "metadata": {
        "id": "7ddc34a2-fc58-4c58-8d00-ee4b124ca893"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "67f957ac-4dd2-4ab8-8710-972586042be9",
      "metadata": {
        "id": "67f957ac-4dd2-4ab8-8710-972586042be9"
      },
      "outputs": [],
      "source": [
        "# !pip install fix_yahoo_finance\n",
        "# !pip install yfinance --upgrade --no-cache-dir\n",
        "\n",
        "#import fix_yahoo_finance\n",
        "\n",
        "def FilterCorrelated(SELECTED_EXCHANGE, CORR_FILTER, startTime, endTime):\n",
        "\n",
        "    prices = pd.DataFrame()\n",
        "    print(f\"======================================\")\n",
        "    print(f\"Comparing assets for Cross Correlation\")\n",
        "    # prices = pdr.get_data_yahoo(SELECTED_EXCHANGE, startTime, endTime)\n",
        "    # cols = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']\n",
        "    # prices.reindex(columns=cols)\n",
        "\n",
        "    names = []\n",
        "\n",
        "    for tick in SELECTED_EXCHANGE:\n",
        "        print(f\"Downloading {tick}\")\n",
        "        yf_tick = yf.Ticker(tick)\n",
        "        df = yf_tick.history(interval='1d', auto_adjust=True, start=startTime, end=endTime, back_adjust = True, rounding=True)\n",
        "        df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "        df.dropna(how='all', inplace=True)\n",
        "        prices = pd.concat([prices,df['Close']],axis=1, ignore_index=False)\n",
        "        #st_name = tick.split('.',maxsplit = 1)\n",
        "        names.append(tick)\n",
        "\n",
        "    prices.columns = names\n",
        "    prices= prices.dropna()\n",
        "\n",
        "    returns = np.log(prices) - np.log(prices.shift(1))\n",
        "    returns = returns.iloc[1:, 0:]\n",
        "    p_return = prices.iloc[-1] / prices.iloc[0] - 1\n",
        "\n",
        "    LR = returns.dropna()\n",
        "    correlation = LR.corr()\n",
        "    numeric_columns = LR.columns\n",
        "\n",
        "    #plt.figure(figsize=(22,22))\n",
        "    #sns.heatmap(correlation>= CORR_FILTER,linecolor='white',linewidths=1,annot=True)\n",
        "\n",
        "    high_corr = [ ]\n",
        "\n",
        "    for c1 in LR.columns:\n",
        "        for c2 in LR.columns:\n",
        "            if c1 != c2 and c1 not in high_corr and correlation[c1][c2] > CORR_FILTER and p_return[c1] < p_return[c2]:\n",
        "                  high_corr.append(c1)\n",
        "\n",
        "    print(\"\\nHighly Correlated Assets = \", high_corr)\n",
        "    SELECTED_EXCHANGE = list(set(SELECTED_EXCHANGE) - set(high_corr))\n",
        "    print(\"\\nNew asset list = \", SELECTED_EXCHANGE)\n",
        "    SELECTED_EXCHANGE\n",
        "    print('\\nNew asset count =', len(SELECTED_EXCHANGE))\n",
        "    return SELECTED_EXCHANGE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "225099c3-f79b-43fe-ba55-f153bd9ed46a",
      "metadata": {
        "tags": [],
        "id": "225099c3-f79b-43fe-ba55-f153bd9ed46a"
      },
      "source": [
        "### Initialize Global Inputs <a name=\"Initialize_Globals\"></a>\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "5a1f3c22-18a9-4681-ad11-fa18084a9d0a",
      "metadata": {
        "id": "5a1f3c22-18a9-4681-ad11-fa18084a9d0a"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "look_back       = START_DAYS_AGO\n",
        "Rfr_g = risk_free_rate / 365 # << INPUT calculate daily rfr\n",
        "Rfr = Rfr_g * START_DAYS_AGO                        # << INPUT calculate rfr for the period\n",
        "#stock_list = pd.DataFrame(SELECTED_EXCHANGE)                      # << INPUT for asset list to be processed# << INPUT for asset list to be processed\n",
        "stock_list = SELECTED_EXCHANGE\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "277e5cc9-eef8-4b13-a8b4-80cf8bd46f7e",
      "metadata": {
        "id": "277e5cc9-eef8-4b13-a8b4-80cf8bd46f7e",
        "outputId": "d771cbc9-ec22-4730-f570-ab8e183d1a78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "type(stock_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bdd36bf",
      "metadata": {
        "tags": [],
        "id": "4bdd36bf"
      },
      "source": [
        "### Select Backtesting and Forward Testing Dates <a name=\"select_dates\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "8809e1ba-804a-4a4c-a715-109be52280ee",
      "metadata": {
        "id": "8809e1ba-804a-4a4c-a715-109be52280ee",
        "outputId": "e3523ac8-c55e-463f-80b0-22751e048c4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "len(stock_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "99293898-b7fd-4d26-8483-4ae7c51c4e69",
      "metadata": {
        "id": "99293898-b7fd-4d26-8483-4ae7c51c4e69",
        "outputId": "63589394-d8c5-43ad-8075-110461604d47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SIMULATION DATES\n",
            "======================================================================\n",
            "Current Date:   2023-08-21\n",
            "T0 Start date:  2023-04-03\n",
            "T0 End date:    2023-08-21\n",
            "T1 Start date:  2023-08-22\n",
            "T1 End date:    2023-08-22\n",
            "END_DATE_M1:    2023-08-21\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "UTILITY U=006 : RETRO_DAY_CALCULATOR WITH SELECTING WEEKDAY ONLY\n",
        "---------------------------------------------------------------\n",
        "- OUTPUTS n days later or before with argument inside the timedelta() function\n",
        "-\n",
        "\n",
        "4 Temmuz PAZARTESI GUNDUZ ISLETILEN PROGRAMIN PARAMETRELERI\n",
        "=================================================\n",
        "8/3/5 de 5 te 4 tane tavan kagidi yakaladi\n",
        "8/3/5 de 3 te 3 tavan kagidi yakaladi\n",
        "\n",
        "Current Date:   2022-07-04\n",
        "T0 Start date:  2022-06-26\n",
        "T0 End date:    2022-06-30\n",
        "T1 Start date:  2022-07-01\n",
        "T1 End date:    2022-07-03\n",
        "END_DATE_M1:    2022-07-01\n",
        "\n",
        "\n",
        "9/3/6 da 4 te 4 yakaladi\n",
        "7/3/4 da 2 te 2 yakaladi\n",
        "7/3/5 de 7 de 6 yakaladi\n",
        "9/4/5 hic olmadi\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "def CalculateStartEndTimes(look_back, BACKTEST_PERIOD, FW_TEST_PERIOD):\n",
        "    from datetime import date, timedelta\n",
        "\n",
        "    def prev_weekday(adate):\n",
        "        adate -= timedelta(days=1)\n",
        "        while adate.weekday() > 4: # Mon-Fri are 0-4\n",
        "            adate -= timedelta(days=1)\n",
        "        return adate\n",
        "\n",
        "    current_date = date.today().isoformat()\n",
        "\n",
        "\n",
        "    T0_START = ( date.today() - timedelta( days = look_back))\n",
        "    T0_END   = ( T0_START + timedelta( days = BACKTEST_PERIOD ))\n",
        "    T1_START = ( T0_END   + timedelta( days = 1 ))\n",
        "    T1_END   = ( T1_START + timedelta( days = FW_TEST_PERIOD ))\n",
        "\n",
        "    END_DATE_M1 =  prev_weekday(T1_END)\n",
        "\n",
        "    print(70*'=')\n",
        "    print(\"SIMULATION DATES\")\n",
        "    print(70*'=')\n",
        "    print(\"Current Date:  \",current_date)\n",
        "    print(\"T0 Start date: \", T0_START)\n",
        "    print(\"T0 End date:   \", T0_END)\n",
        "    print(\"T1 Start date: \", T1_START)\n",
        "    print(\"T1 End date:   \", T1_END)\n",
        "    print(\"END_DATE_M1:   \", END_DATE_M1)\n",
        "    print(70*'-')\n",
        "    return T0_START, T0_END, T1_START, T1_END, END_DATE_M1\n",
        "\n",
        "T0_START, T0_END, T1_START, T1_END, END_DATE_M1 = CalculateStartEndTimes(look_back, BACKTEST_PERIOD, FW_TEST_PERIOD)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82707fc9-2471-48b5-b20f-4e827c7b6639",
      "metadata": {
        "tags": [],
        "id": "82707fc9-2471-48b5-b20f-4e827c7b6639"
      },
      "source": [
        "### Download Data for Backtesting and Prefilter Assets for SR > SHARPE_LIMIT <a name=\"Download_BackTest\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "a087b852-13e4-4b6a-a148-411e630914fe",
      "metadata": {
        "id": "a087b852-13e4-4b6a-a148-411e630914fe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b4c10240-3162-448c-9cb5-0b3290b61ec8",
      "metadata": {
        "id": "b4c10240-3162-448c-9cb5-0b3290b61ec8",
        "outputId": "79e8f980-43d2-43c3-d08f-1bae046f8435",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "'GC=F' in SELECTED_EXCHANGE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "3b662389-c27c-4be4-bf0b-2338256c83ee",
      "metadata": {
        "id": "3b662389-c27c-4be4-bf0b-2338256c83ee",
        "outputId": "1dbba593-b37e-4e80-c9b3-3dd65c07ec88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AKBNK.IS',\n",
              " 'AKSEN.IS',\n",
              " 'ALARK.IS',\n",
              " 'ARCLK.IS',\n",
              " 'ASELS.IS',\n",
              " 'BIMAS.IS',\n",
              " 'EKGYO.IS',\n",
              " 'ENKAI.IS',\n",
              " 'EREGL.IS',\n",
              " 'FROTO.IS',\n",
              " 'GARAN.IS',\n",
              " 'GUBRF.IS',\n",
              " 'HEKTS.IS',\n",
              " 'ISCTR.IS',\n",
              " 'KOZAA.IS',\n",
              " 'KOZAL.IS',\n",
              " 'KCHOL.IS',\n",
              " 'KRDMD.IS',\n",
              " 'ODAS.IS',\n",
              " 'PETKM.IS',\n",
              " 'PGSUS.IS',\n",
              " 'SAHOL.IS',\n",
              " 'SISE.IS',\n",
              " 'TAVHL.IS',\n",
              " 'TCELL.IS',\n",
              " 'THYAO.IS',\n",
              " 'TOASO.IS',\n",
              " 'TUPRS.IS',\n",
              " 'YKBNK.IS',\n",
              " 'QUAGR.IS',\n",
              " 'TURSG.IS']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "\n",
        "def FilterAssetsForSharpe(SELECTED_EXCHANGE):\n",
        "    import pandas_datareader.data as web\n",
        "    if Sharpe_Std_Filtering:\n",
        "\n",
        "        print(LENGTH*\"*\")\n",
        "        print(f\"STAGE-1: {len(SELECTED_EXCHANGE)} {exchange} assets being filtered for Sharpe Ratio > {SHARPE_LIMIT} and Std Dev < %{STD_LIMIT} ...\")\n",
        "        print(LENGTH*\"*\")\n",
        "        PRICES, BEST = InvestCompare( T0_START, T0_END, SELECTED_EXCHANGE, STD_LIMIT, SHARPE_LIMIT, START_DAYS_AGO, FW_TEST_PERIOD )  # << INPUT T1_END idi T0_END olması gerekli\n",
        "        print(PRICES)\n",
        "\n",
        "    # applying filter function\n",
        "        list1 = BEST.filter([   \"Net Dönem Getirisi %\",\n",
        "                                \"Standart Sapma %\",\n",
        "                                \"Ortalama Günlük Getiri %\",\n",
        "                                \"Sharpe Oranı\"])\n",
        "        list1.to_csv(f\"BEST_{exchange}_{look_back}D.csv\")\n",
        "        stock_list = list1.index\n",
        "\n",
        "    #else:\n",
        "        # os.chdir(root)\n",
        "        # filename = f\"BEST_{exchange}_{look_back}D.csv\"\n",
        "        # list1 = pd.read_csv(filename)\n",
        "        # stock_list = list1['Unnamed: 0']\n",
        "    print(stock_list)\n",
        "    return(stock_list)\n",
        "\n",
        "#stock_list = FilterAssetsForSharpe(SELECTED_EXCHANGE)\n",
        "stock_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f6ed355-e060-4784-b751-3578d692f5fe",
      "metadata": {
        "id": "4f6ed355-e060-4784-b751-3578d692f5fe"
      },
      "source": [
        "### Filter Correlated Assets with Correlation more than 0.6 <a name=\"filter_corr\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba948dda-546d-4329-b607-47b2b9e817b5",
      "metadata": {
        "id": "ba948dda-546d-4329-b607-47b2b9e817b5"
      },
      "source": [
        "### TAM BURADA KALDIK DATAFRAME DOLARA CEVRILMIS DURUMDA TEKRAR CEVRIME GEREK KALMADAN ILERLE !!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "472a490c-351f-4c3e-8d4b-e48adaa5c4e4",
      "metadata": {
        "id": "472a490c-351f-4c3e-8d4b-e48adaa5c4e4",
        "outputId": "c074c631-e6fb-4a29-9984-ea0dfe4b89cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AKBNK.IS',\n",
              " 'AKSEN.IS',\n",
              " 'ALARK.IS',\n",
              " 'ARCLK.IS',\n",
              " 'ASELS.IS',\n",
              " 'BIMAS.IS',\n",
              " 'EKGYO.IS',\n",
              " 'ENKAI.IS',\n",
              " 'EREGL.IS',\n",
              " 'FROTO.IS',\n",
              " 'GARAN.IS',\n",
              " 'GUBRF.IS',\n",
              " 'HEKTS.IS',\n",
              " 'ISCTR.IS',\n",
              " 'KOZAA.IS',\n",
              " 'KOZAL.IS',\n",
              " 'KCHOL.IS',\n",
              " 'KRDMD.IS',\n",
              " 'ODAS.IS',\n",
              " 'PETKM.IS',\n",
              " 'PGSUS.IS',\n",
              " 'SAHOL.IS',\n",
              " 'SISE.IS',\n",
              " 'TAVHL.IS',\n",
              " 'TCELL.IS',\n",
              " 'THYAO.IS',\n",
              " 'TOASO.IS',\n",
              " 'TUPRS.IS',\n",
              " 'YKBNK.IS',\n",
              " 'QUAGR.IS',\n",
              " 'TURSG.IS']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "def FilterAssetsForCorrelation(stock_list):\n",
        "\n",
        "    print(LENGTH*\"*\")\n",
        "    print(f\"STAGE-2: {len(stock_list)} {exchange} assets being filtered for Correlation < {CORR_FILTER} ...\")\n",
        "    print(LENGTH*\"*\")\n",
        "    stock_list = FilterCorrelated(stock_list, CORR_FILTER, T0_START, T0_END)\n",
        "\n",
        "    print(70*'-')\n",
        "    print(f\"\\n{T0_START} ... {T0_END} arası {exchange}'in en iyi {len(stock_list)} hissesi\\n \")\n",
        "    print(f\"Dönem vadeli mevduat getirisi= %{np.round(Rfr*100,2)}\\n \")\n",
        "    #stock_list.append(\"CANTE.IS\")\n",
        "\n",
        "    print(\"\\nyeni hisse listesi\")\n",
        "    print(\"\\n==================\\n\")\n",
        "\n",
        "    print(stock_list)\n",
        "    return(stock_list)\n",
        "\n",
        "# stock_list = [ \"SNGYO.IS\", \"SILVR.IS\", \"BANVT.IS\", \"MNDRS.IS\", \"INFO.IS\", \"CANTE.IS\", \"PGSUS.IS\", \"DAGHL.IS\",\n",
        "#                \"MEPET.IS\", \"ODAS.IS\", \"ACSEL.IS\", \"HEKTS.IS\",  \"BLCYT.IS\", \"OYAYO.IS\", \"LKMNH.IS\", \"ARMDA.IS\" ]\n",
        "\n",
        "stock_list\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "b020e13a-892c-4790-9e3d-b6900cbf47bd",
      "metadata": {
        "id": "b020e13a-892c-4790-9e3d-b6900cbf47bd",
        "outputId": "1b3099e8-d111-404f-8629-e6c7f01c1c7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************************************************************************\n",
            "STAGE-2: 31 BIST30 assets being filtered for Correlation < 0.75 ...\n",
            "****************************************************************************************************\n",
            "======================================\n",
            "Comparing assets for Cross Correlation\n",
            "Downloading AKBNK.IS\n",
            "Downloading AKSEN.IS\n",
            "Downloading ALARK.IS\n",
            "Downloading ARCLK.IS\n",
            "Downloading ASELS.IS\n",
            "Downloading BIMAS.IS\n",
            "Downloading EKGYO.IS\n",
            "Downloading ENKAI.IS\n",
            "Downloading EREGL.IS\n",
            "Downloading FROTO.IS\n",
            "Downloading GARAN.IS\n",
            "Downloading GUBRF.IS\n",
            "Downloading HEKTS.IS\n",
            "Downloading ISCTR.IS\n",
            "Downloading KOZAA.IS\n",
            "Downloading KOZAL.IS\n",
            "Downloading KCHOL.IS\n",
            "Downloading KRDMD.IS\n",
            "Downloading ODAS.IS\n",
            "Downloading PETKM.IS\n",
            "Downloading PGSUS.IS\n",
            "Downloading SAHOL.IS\n",
            "Downloading SISE.IS\n",
            "Downloading TAVHL.IS\n",
            "Downloading TCELL.IS\n",
            "Downloading THYAO.IS\n",
            "Downloading TOASO.IS\n",
            "Downloading TUPRS.IS\n",
            "Downloading YKBNK.IS\n",
            "Downloading QUAGR.IS\n",
            "Downloading TURSG.IS\n",
            "\n",
            "Highly Correlated Assets =  ['AKBNK.IS', 'EREGL.IS', 'ISCTR.IS', 'KOZAL.IS', 'PGSUS.IS', 'SAHOL.IS', 'SISE.IS', 'YKBNK.IS']\n",
            "\n",
            "New asset list =  ['KOZAA.IS', 'AKSEN.IS', 'TOASO.IS', 'TAVHL.IS', 'TCELL.IS', 'PETKM.IS', 'EKGYO.IS', 'KCHOL.IS', 'ASELS.IS', 'BIMAS.IS', 'TUPRS.IS', 'ENKAI.IS', 'ARCLK.IS', 'ODAS.IS', 'KRDMD.IS', 'ALARK.IS', 'HEKTS.IS', 'QUAGR.IS', 'FROTO.IS', 'GUBRF.IS', 'GARAN.IS', 'TURSG.IS', 'THYAO.IS']\n",
            "\n",
            "New asset count = 23\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "2023-04-03 ... 2023-08-21 arası BIST30'in en iyi 23 hissesi\n",
            " \n",
            "Dönem vadeli mevduat getirisi= %9.59\n",
            " \n",
            "\n",
            "yeni hisse listesi\n",
            "\n",
            "==================\n",
            "\n",
            "['KOZAA.IS', 'AKSEN.IS', 'TOASO.IS', 'TAVHL.IS', 'TCELL.IS', 'PETKM.IS', 'EKGYO.IS', 'KCHOL.IS', 'ASELS.IS', 'BIMAS.IS', 'TUPRS.IS', 'ENKAI.IS', 'ARCLK.IS', 'ODAS.IS', 'KRDMD.IS', 'ALARK.IS', 'HEKTS.IS', 'QUAGR.IS', 'FROTO.IS', 'GUBRF.IS', 'GARAN.IS', 'TURSG.IS', 'THYAO.IS']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if Corr_Filtering:\n",
        "    stock_list = FilterAssetsForCorrelation(stock_list)\n",
        "else:\n",
        "    print(\"\\nCAUTION: NO CORRELATION FILTERING DONE !\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "596c0a02-b34a-46ce-8b0b-91ff2d318708",
      "metadata": {
        "id": "596c0a02-b34a-46ce-8b0b-91ff2d318708"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "stock_list = AddTRYXToStockList(stock_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "04df127e-2f6a-4129-b3a1-f34a7042f49f",
      "metadata": {
        "id": "04df127e-2f6a-4129-b3a1-f34a7042f49f",
        "outputId": "e95fe89d-7562-4533-e266-03be52844c53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['KOZAA.IS', 'AKSEN.IS', 'TOASO.IS', 'TAVHL.IS', 'TCELL.IS', 'PETKM.IS', 'EKGYO.IS', 'KCHOL.IS', 'ASELS.IS', 'BIMAS.IS', 'TUPRS.IS', 'ENKAI.IS', 'ARCLK.IS', 'ODAS.IS', 'KRDMD.IS', 'ALARK.IS', 'HEKTS.IS', 'QUAGR.IS', 'FROTO.IS', 'GUBRF.IS', 'GARAN.IS', 'TURSG.IS', 'THYAO.IS', 'TRY=X']\n"
          ]
        }
      ],
      "source": [
        "print(stock_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "d4cc69ca-651b-47e6-96bb-0963d4a80829",
      "metadata": {
        "id": "d4cc69ca-651b-47e6-96bb-0963d4a80829"
      },
      "outputs": [],
      "source": [
        "def WriteStockListToCSV():\n",
        "    pd.DataFrame(stock_list).to_csv(f\"BEST_OF_{exchange}.csv\")\n",
        "    len(stock_list)\n",
        "\n",
        "WriteStockListToCSV()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1d23bc6-967c-47fc-acd4-b52726cad97a",
      "metadata": {
        "id": "b1d23bc6-967c-47fc-acd4-b52726cad97a"
      },
      "source": [
        "## STOCK_LIST BYPASS HERE <a name=\"STOCK_LIST_BY_PASS\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "25521d39-3dd8-4af5-befc-b1471c909943",
      "metadata": {
        "id": "25521d39-3dd8-4af5-befc-b1471c909943"
      },
      "outputs": [],
      "source": [
        "# stock_list = [\n",
        "#                       \"ASELS.IS\",\n",
        "#                       \"BIMAS.IS\",\n",
        "#                       \"FROTO.IS\",\n",
        "#                       \"KRDMD.IS\",\n",
        "#                       \"SASA.IS\" ,\n",
        "#                       \"SISE.IS\",\n",
        "#                       \"THYAO.IS\",\n",
        "#                       \"TOASO.IS\",\n",
        "#                       # \"TRILC.IS\",\n",
        "#                       \"VESBE.IS\",\n",
        "#                       \"EREGL.IS\",\n",
        "#                       \"TUPRS.IS\",\n",
        "#                   ]\n",
        "\n",
        "#stock_list = CRYPTOS\n",
        "\n",
        "\n",
        "# GZN PORTFOLIO\n",
        "# stock_list =  [ \"GARAN.IS\",  \"BIMAS.IS\", \"ALARK.IS\",  \"KOZAL.IS\",\n",
        "#               \"THYAO.IS\"]\n",
        "\n",
        "\n",
        "# stock_list =  [ \"ALARK.IS\",  \"KOZAL.IS\", \"QUAGR.IS\",\n",
        "#                 \"THYAO.IS\",  \"CANTE.IS\", \"TUPRS.IS\",\n",
        "#                 \"TOASO.IS\",  ]\n",
        "#stock_list = BIST100\n",
        "#stock_list = Clean_List( stock_list, Exclusion_BIST500)\n",
        "#stock_list = Clean_List( stock_list, YASAKLI_BIST500)\n",
        "#stock_list = FilterCorrelated(stock_list, CORR_FILTER, T0_START, T0_END)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "d1e87824-195c-4e57-af30-dc7b27bb0d34",
      "metadata": {
        "id": "d1e87824-195c-4e57-af30-dc7b27bb0d34",
        "outputId": "aaedb60b-f291-4416-a5e0-c57b8f719afd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['KOZAA.IS',\n",
              " 'AKSEN.IS',\n",
              " 'TOASO.IS',\n",
              " 'TAVHL.IS',\n",
              " 'TCELL.IS',\n",
              " 'PETKM.IS',\n",
              " 'EKGYO.IS',\n",
              " 'KCHOL.IS',\n",
              " 'ASELS.IS',\n",
              " 'BIMAS.IS',\n",
              " 'TUPRS.IS',\n",
              " 'ENKAI.IS',\n",
              " 'ARCLK.IS',\n",
              " 'ODAS.IS',\n",
              " 'KRDMD.IS',\n",
              " 'ALARK.IS',\n",
              " 'HEKTS.IS',\n",
              " 'QUAGR.IS',\n",
              " 'FROTO.IS',\n",
              " 'GUBRF.IS',\n",
              " 'GARAN.IS',\n",
              " 'TURSG.IS',\n",
              " 'THYAO.IS',\n",
              " 'TRY=X']"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "stock_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2901d93-2c4d-412d-9ae1-208718d5b05c",
      "metadata": {
        "id": "f2901d93-2c4d-412d-9ae1-208718d5b05c"
      },
      "source": [
        "## ADD USDTRY TO STOCK_LIST <a name=\"Add USDTRY to stock_list\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "5eacb654-76a4-4584-b0e8-664dc710c36d",
      "metadata": {
        "id": "5eacb654-76a4-4584-b0e8-664dc710c36d"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "15c43bac-d89e-40fe-980c-1f5143fd6787",
      "metadata": {
        "id": "15c43bac-d89e-40fe-980c-1f5143fd6787",
        "outputId": "d020bdff-f3b9-44c7-d845-5c4da98e36bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['KOZAA.IS',\n",
              " 'AKSEN.IS',\n",
              " 'TOASO.IS',\n",
              " 'TAVHL.IS',\n",
              " 'TCELL.IS',\n",
              " 'PETKM.IS',\n",
              " 'EKGYO.IS',\n",
              " 'KCHOL.IS',\n",
              " 'ASELS.IS',\n",
              " 'BIMAS.IS',\n",
              " 'TUPRS.IS',\n",
              " 'ENKAI.IS',\n",
              " 'ARCLK.IS',\n",
              " 'ODAS.IS',\n",
              " 'KRDMD.IS',\n",
              " 'ALARK.IS',\n",
              " 'HEKTS.IS',\n",
              " 'QUAGR.IS',\n",
              " 'FROTO.IS',\n",
              " 'GUBRF.IS',\n",
              " 'GARAN.IS',\n",
              " 'TURSG.IS',\n",
              " 'THYAO.IS',\n",
              " 'TRY=X']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "stock_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7d0d3dc-d77a-4a0f-b1e2-73fb01c2f18a",
      "metadata": {
        "id": "a7d0d3dc-d77a-4a0f-b1e2-73fb01c2f18a"
      },
      "source": [
        "## DOWNLOAD_ASSETS_FOR SELECTED DATES <a name=\"Download_Assets_For_Dates\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "8f4bcd12-3840-48b5-84e0-16b7d005fc7f",
      "metadata": {
        "id": "8f4bcd12-3840-48b5-84e0-16b7d005fc7f",
        "outputId": "63e4a299-1066-4e71-d8ca-bf3d9c00b328",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************************************************************************\n",
            "Starting Download of filtered 24 BIST30 assets\n",
            "****************************************************************************************************\n",
            "Downloading KOZAA.IS\n",
            "Downloading AKSEN.IS\n",
            "Downloading TOASO.IS\n",
            "Downloading TAVHL.IS\n",
            "Downloading TCELL.IS\n",
            "Downloading PETKM.IS\n",
            "Downloading EKGYO.IS\n",
            "Downloading KCHOL.IS\n",
            "Downloading ASELS.IS\n",
            "Downloading BIMAS.IS\n",
            "Downloading TUPRS.IS\n",
            "Downloading ENKAI.IS\n",
            "Downloading ARCLK.IS\n",
            "Downloading ODAS.IS\n",
            "Downloading KRDMD.IS\n",
            "Downloading ALARK.IS\n",
            "Downloading HEKTS.IS\n",
            "Downloading QUAGR.IS\n",
            "Downloading FROTO.IS\n",
            "Downloading GUBRF.IS\n",
            "Downloading GARAN.IS\n",
            "Downloading TURSG.IS\n",
            "Downloading THYAO.IS\n",
            "Downloading TRY=X\n",
            "****************************************************************************************************\n",
            " DOWNLOADED 24 TICKERS from BIST30\n",
            "****************************************************************************************************\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "UTILITY U=020 : DOWNLOAD_ASSETS_&_WRITE_DF BY SELECTING WEEKDAY DATA ONLY\n",
        "--------------------------------------------\n",
        "- CHANGES WORKING DIRECTORY\n",
        "- SET FLAG TO NEW_DOWNLOAD\n",
        "- GETS DATA FOR ALL ASSETS IN stock_list FROM YAHOO FINANCE\n",
        "- FILTERS WEEKEND DATA OUT\n",
        "- WRITES DATA IN df and price_list\n",
        "- WRITES DATA IN CSV FILES\n",
        "\n",
        "DIKKAT: stock_list in dataframe degil list olmasi gerekli !!!\n",
        "\n",
        "'''\n",
        "def DownloadAssetsAndWriteToCSVs(stock_list):\n",
        "    new_download = True\n",
        "    price_list = []\n",
        "    if new_download:\n",
        "        print(LENGTH*\"*\")\n",
        "        print(f\"Starting Download of filtered {len(stock_list)} {exchange} assets\")\n",
        "        print(LENGTH*\"*\")\n",
        "        for tick in stock_list:\n",
        "            try:   # added 1/07/22\n",
        "                print(f\"Downloading {tick}\")\n",
        "                yf_tick = yf.Ticker(tick)\n",
        "                df = yf_tick.history(interval='1d', auto_adjust=True, start=T0_START, end=T0_END, back_adjust = True, rounding=True)\n",
        "                #df = web.DataReader(tick, \"yahoo\", T0_START, T0_END)[\"Adj Close\"]\n",
        "                df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "                df.dropna(how='all', inplace=True)\n",
        "                price_list.append(df)\n",
        "            except Exception as e:    # added 1/07/22\n",
        "                print(e, tick)        # added 1/07/22\n",
        "        print(LENGTH*\"*\")\n",
        "        print(f\" DOWNLOADED {len(stock_list)} TICKERS from {exchange}\")\n",
        "        print(LENGTH*\"*\")\n",
        "\n",
        "        # exclude weekends\n",
        "\n",
        "\n",
        "        #df = df[df.index.dayofweek < 5]\n",
        "\n",
        "        ## Save datafiles to disk\n",
        "\n",
        "        for i,df in enumerate(price_list):\n",
        "            df.to_csv(f\"{stock_list[i]}.csv\")\n",
        "\n",
        "\n",
        "\n",
        "    # UTILITY U=021 : FETCH_ASSETS_FROM_CSV_FILES_&_WRITE_DF\n",
        "    # --------------------------------------------\n",
        "    # - CHANGES WORKING DIRECTORY\n",
        "    # - SET FLAG TO NEW_DOWNLOAD\n",
        "    # - GETS DATA FOR ALL ASSETS IN stock_list FROM CSV FILES\n",
        "    # - PUTS DATA in df\n",
        "    #\n",
        "\n",
        "\n",
        "    else:\n",
        "        price = {}\n",
        "        print(LENGTH*\"*\")\n",
        "        print(\"Fetching Downloaded CSV Files ...\")\n",
        "        print(LENGTH*\"*\")\n",
        "        for tick in stock_list:\n",
        "            print(f\"Fetching {tick}\")\n",
        "            filename = f\"{tick}.csv\"\n",
        "            df = pd.read_csv(filename)\n",
        "            price[tick] = df\n",
        "        print(LENGTH*\"*\")\n",
        "        #print('Done ...Time elapsed (hh:mm:ss.ms) {}'.format(datetime.now() - start_time))\n",
        "        print(LENGTH*\"*\")\n",
        "\n",
        "DownloadAssetsAndWriteToCSVs(stock_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "e17afdc7-25de-426e-ba72-d1e187a2ecf2",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "e17afdc7-25de-426e-ba72-d1e187a2ecf2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "9e51f016-a821-4807-ab33-46bdb14561d6",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "9e51f016-a821-4807-ab33-46bdb14561d6"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from datetime import datetime, timedelta\n",
        "\n",
        "# def omit_dates(df, list_years, list_dates, omit_days_near=3, omit_weekends=False):\n",
        "#     '''\n",
        "#     Given a Pandas dataframe with a DatetimeIndex, remove rows that have a date\n",
        "#     near a given list of dates and/or a date on a weekend.\n",
        "\n",
        "#     Parameters:\n",
        "#     ----------\n",
        "\n",
        "#     df : Pandas dataframe\n",
        "\n",
        "#     list_years : list of str\n",
        "#         Contains a list of years in string form\n",
        "#     list_dates : list of str\n",
        "#         Contains a list of dates in string form encoded as MM-DD\n",
        "#     omit_days_near : int\n",
        "#         Threshold of days away from list_dates to remove. For example, if\n",
        "#         omit_days_near=3, then omit all days that are 3 days away from\n",
        "#         any date in list_dates.\n",
        "#     omit_weekends : bool\n",
        "#         If true, omit dates that are on weekends.\n",
        "\n",
        "#     Returns:\n",
        "#     -------\n",
        "#     Pandas dataframe\n",
        "#         New resulting dataframe with dates omitted.\n",
        "#     '''\n",
        "\n",
        "#     if not isinstance(df, pd.core.frame.DataFrame):\n",
        "#         raise ValueError(\"df is expected to be a Pandas dataframe, not %s\" % type(df).__name__)\n",
        "\n",
        "#     if not isinstance(df.index, pd.tseries.index.DatetimeIndex):\n",
        "#         raise ValueError(\"Dataframe is expected to have an index of DateTimeIndex, not %s\" %\n",
        "#                          type(df.index).__name__)\n",
        "\n",
        "#     if not isinstance(list_years, list):\n",
        "#         list_years = [list_years]\n",
        "\n",
        "#     if not isinstance(list_dates, list):\n",
        "#         list_dates = [list_dates]\n",
        "\n",
        "#     result = df.copy()\n",
        "\n",
        "#     if omit_weekends:\n",
        "#         result = result.loc[result.index.dayofweek < 5]\n",
        "\n",
        "#     omit_dates = [ '%s-%s' % (year, date) for year in list_years for date in list_dates ]\n",
        "\n",
        "#     for date in omit_dates:\n",
        "#         result = result.loc[abs(result.index.date - datetime.strptime(date, '%Y-%m-%d').date()) > timedelta(omit_days_near)]\n",
        "\n",
        "#     return result\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "f49016bc-d4b9-4f62-84de-9efbc48a8036",
      "metadata": {
        "id": "f49016bc-d4b9-4f62-84de-9efbc48a8036"
      },
      "outputs": [],
      "source": [
        "def omit_dates(df, omit_weekends=False):\n",
        "#     '''\n",
        "#     Given a Pandas dataframe with a DatetimeIndex, remove rows that have a date\n",
        "#     near a given list of dates and/or a date on a weekend.\n",
        "\n",
        "#     Parameters:\n",
        "#     ----------\n",
        "\n",
        "#     df : Pandas dataframe\n",
        "\n",
        "#     list_years : list of str\n",
        "#         Contains a list of years in string form\n",
        "#     list_dates : list of str\n",
        "#         Contains a list of dates in string form encoded as MM-DD\n",
        "#     omit_days_near : int\n",
        "#         Threshold of days away from list_dates to remove. For example, if\n",
        "#         omit_days_near=3, then omit all days that are 3 days away from\n",
        "#         any date in list_dates.\n",
        "#     omit_weekends : bool\n",
        "#         If true, omit dates that are on weekends.\n",
        "\n",
        "#     Returns:\n",
        "#     -------\n",
        "#     Pandas dataframe\n",
        "#         New resulting dataframe with dates omitted.\n",
        "#     '''\n",
        "\n",
        "#    if not isinstance(df, pd.core.frame.DataFrame):\n",
        "#         raise ValueError(\"df is expected to be a Pandas dataframe, not %s\" % type(df).__name__)\n",
        "\n",
        "#    if not isinstance(df.index, pd.tseries.index.DatetimeIndex):\n",
        "#         raise ValueError(\"Dataframe is expected to have an index of DateTimeIndex, not %s\" %\n",
        "#                          type(df.index).__name__)\n",
        "\n",
        "#     if not isinstance(list_years, list):\n",
        "#         list_years = [list_years]\n",
        "\n",
        "#     if not isinstance(list_dates, list):\n",
        "#         list_dates = [list_dates]\n",
        "\n",
        "    result = df.copy()\n",
        "\n",
        "    if omit_weekends:\n",
        "\n",
        "        result['day-of-week'] = result.index.weekday()\n",
        "        result = result.loc[result['day-of-week'] < 5]\n",
        "\n",
        "#     omit_dates = [ '%s-%s' % (year, date) for year in list_years for date in list_dates ]\n",
        "\n",
        "#     for date in omit_dates:\n",
        "#         result = result.loc[abs(result.index.date - datetime.strptime(date, '%Y-%m-%d').date()) > timedelta(omit_days_near)]\n",
        "\n",
        "    return result\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e7e5a0e-329d-435d-870c-a143da073a79",
      "metadata": {
        "id": "4e7e5a0e-329d-435d-870c-a143da073a79"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "5c02063b-df67-4bc6-98eb-ddd2b0399f9d",
      "metadata": {
        "id": "5c02063b-df67-4bc6-98eb-ddd2b0399f9d"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b7f5316-9683-488f-8088-c692ab28d662",
      "metadata": {
        "id": "4b7f5316-9683-488f-8088-c692ab28d662"
      },
      "source": [
        "## Merge All CSV Files to form DF: li <a name=\"Merge_All_CSV_Files\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "ebc1e551",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "ebc1e551",
        "outputId": "ac7cc651-6f0f-4e31-c847-8dab42f2c748",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV files merged\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "UTILITY U=001A : CSV_MERGER_DATE_REVERSED\n",
        "--------------------------------------------\n",
        "- FUNCTION NAME: def CSV_2_DF_REV_ORDER()\n",
        "- input: exhange name, stocklist\n",
        "- output: sorted (DF)\n",
        "- READS desired assets from csv files\n",
        "- APPENDS the 'close' columns required in a single df name `li`\n",
        "- SORTS dataframe in reversed order\n",
        "- WRITES to csv file\n",
        "\n",
        "'''\n",
        "\n",
        "def MergeCSVFiles(stock_list):\n",
        "    import pandas as pd\n",
        "    import os\n",
        "\n",
        "    pf_data = pd.DataFrame()\n",
        "    li = pd.DataFrame() # my real portfolio dataframe\n",
        "    rets = pd.DataFrame()\n",
        "    names = []\n",
        "    count = len(stock_list)\n",
        "\n",
        "    #os.chdir(wd)\n",
        "    #for file in sorted2.Stock:\n",
        "    for file in stock_list:\n",
        "\n",
        "        pf_data = pd.read_csv(f\"{file}.csv\", index_col='Date', parse_dates=True, keep_date_col = True, infer_datetime_format=True, dayfirst=True, decimal=\",\")\n",
        "        li = pd.concat( [li,pf_data['Close']],axis=1) #, ignore_index=True)\n",
        "        st_name = file.split('.',maxsplit = 1)\n",
        "        names.append(st_name[0])\n",
        "\n",
        "    li.columns = names\n",
        "\n",
        "    #USDTRY CONVERSION\n",
        "\n",
        "\n",
        "    li = li.rename_axis(index=\"Date\")\n",
        "    sorted = li.sort_values(by=['Date'], ascending=[False])\n",
        "    # exclude weekends\n",
        "\n",
        "    #sorted = sorted[sorted.index.dayofweek < 5]\n",
        "    #sorted = omit_dates(sorted, omit_weekends=True)\n",
        "    sorted.to_csv(f\"{exchange}_Close.csv\")\n",
        "\n",
        "    print(\"CSV files merged\")\n",
        "    return(f\"{exchange}_Close.csv\")\n",
        "\n",
        "\n",
        "csv = MergeCSVFiles(stock_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90feb996",
      "metadata": {
        "id": "90feb996"
      },
      "source": [
        "Saving the Stock data in csv file (Code commented after use)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "5b9d3622-b186-4f69-ac5f-c5e0917efdf3",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "5b9d3622-b186-4f69-ac5f-c5e0917efdf3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "4b44b0f7",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "4b44b0f7",
        "outputId": "ca32579e-cb44-4421-ac33-04246c217fa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [KOZAA, AKSEN, TOASO, TAVHL, TCELL, PETKM, EKGYO, KCHOL, ASELS, BIMAS, TUPRS, ENKAI, ARCLK, ODAS, KRDMD, ALARK, HEKTS, QUAGR, FROTO, GUBRF, GARAN, TURSG, THYAO, TRY=X]\n",
              "Index: []\n",
              "\n",
              "[0 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0cd6a98e-cbf3-4e67-926d-2a569ec8307d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>KOZAA</th>\n",
              "      <th>AKSEN</th>\n",
              "      <th>TOASO</th>\n",
              "      <th>TAVHL</th>\n",
              "      <th>TCELL</th>\n",
              "      <th>PETKM</th>\n",
              "      <th>EKGYO</th>\n",
              "      <th>KCHOL</th>\n",
              "      <th>ASELS</th>\n",
              "      <th>BIMAS</th>\n",
              "      <th>...</th>\n",
              "      <th>KRDMD</th>\n",
              "      <th>ALARK</th>\n",
              "      <th>HEKTS</th>\n",
              "      <th>QUAGR</th>\n",
              "      <th>FROTO</th>\n",
              "      <th>GUBRF</th>\n",
              "      <th>GARAN</th>\n",
              "      <th>TURSG</th>\n",
              "      <th>THYAO</th>\n",
              "      <th>TRY=X</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>0 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0cd6a98e-cbf3-4e67-926d-2a569ec8307d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0cd6a98e-cbf3-4e67-926d-2a569ec8307d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0cd6a98e-cbf3-4e67-926d-2a569ec8307d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-03be8295-2218-4907-beb0-f7009d9dd801\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03be8295-2218-4907-beb0-f7009d9dd801')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-03be8295-2218-4907-beb0-f7009d9dd801 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "def ReadMergedCSVToPfData(CSVfilename):\n",
        "    pf_data=pd.read_csv(CSVfilename)\n",
        "    pf_data.set_index(\"Date\", inplace = True)\n",
        "    pf_data = pf_data.sort_values(by=['Date'], ascending=[True])\n",
        "    pf_data.dropna(inplace=True)\n",
        "    return pf_data\n",
        "    # exclude weekends\n",
        "\n",
        "    #pf_date = pf_data[pf_data.index.dayofweek < 5]\n",
        "    #pf_data[\"GC=F\"] = ConvertOunceToGram( pf_data[\"TRY=X\"].astype(float), pf_data[\"GC=F\"].astype(float))\n",
        "    #pf_data[\"Close\"] = pf_data[\"GC=F\"]\n",
        "    #pf_data[\"Close\"].to_csv('GC=F.csv')\n",
        "    #pf_data.drop(\"Close\", axis=1, inplace=True)\n",
        "    #pf_data.tail(20)\n",
        "\n",
        "\n",
        "pf_data = ReadMergedCSVToPfData(f\"{exchange}_Close.csv\")\n",
        "pf_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98ccb76a-f1a9-4b79-b4ad-80dafc4b9c51",
      "metadata": {
        "id": "98ccb76a-f1a9-4b79-b4ad-80dafc4b9c51"
      },
      "source": [
        "## CONVERT ALL FIGURES TO USD TRY <a name=\"Convert_To_USD\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a72459e4",
      "metadata": {
        "tags": [],
        "id": "a72459e4"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "672294e5-a110-42fd-bd52-5fb7b412c1d6",
      "metadata": {
        "id": "672294e5-a110-42fd-bd52-5fb7b412c1d6"
      },
      "outputs": [],
      "source": [
        "def ConvertTimeseriesToUSD(PFDATA):\n",
        "    if exchange == \"BIST500\" or exchange == \"BIST30\" :\n",
        "        new_names = []\n",
        "        for i in stock_list:\n",
        "            sl = i.split('.',maxsplit = 1)\n",
        "            new_names.append(sl[0])\n",
        "        for i in new_names:\n",
        "            if i != 'GC=F' and i != 'CL=F':\n",
        "                PFDATA[i] = pd.Series(PFDATA[i] / PFDATA['TRY=X'])\n",
        "        return PFDATA\n",
        "\n",
        "pf_data = ConvertTimeseriesToUSD(pf_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "22ce1d0f-a668-4222-a44a-82b0bfbcf3c5",
      "metadata": {
        "tags": [],
        "id": "22ce1d0f-a668-4222-a44a-82b0bfbcf3c5",
        "outputId": "18707d2d-4927-4eb2-c6c8-179fbe77e31a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [KOZAA, AKSEN, TOASO, TAVHL, TCELL, PETKM, EKGYO, KCHOL, ASELS, BIMAS, TUPRS, ENKAI, ARCLK, ODAS, KRDMD, ALARK, HEKTS, QUAGR, FROTO, GUBRF, GARAN, TURSG, THYAO, TRY=X]\n",
              "Index: []\n",
              "\n",
              "[0 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9af146e-1a0c-4ef5-9f2e-e686e2acc9fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>KOZAA</th>\n",
              "      <th>AKSEN</th>\n",
              "      <th>TOASO</th>\n",
              "      <th>TAVHL</th>\n",
              "      <th>TCELL</th>\n",
              "      <th>PETKM</th>\n",
              "      <th>EKGYO</th>\n",
              "      <th>KCHOL</th>\n",
              "      <th>ASELS</th>\n",
              "      <th>BIMAS</th>\n",
              "      <th>...</th>\n",
              "      <th>KRDMD</th>\n",
              "      <th>ALARK</th>\n",
              "      <th>HEKTS</th>\n",
              "      <th>QUAGR</th>\n",
              "      <th>FROTO</th>\n",
              "      <th>GUBRF</th>\n",
              "      <th>GARAN</th>\n",
              "      <th>TURSG</th>\n",
              "      <th>THYAO</th>\n",
              "      <th>TRY=X</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>0 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9af146e-1a0c-4ef5-9f2e-e686e2acc9fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a9af146e-1a0c-4ef5-9f2e-e686e2acc9fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a9af146e-1a0c-4ef5-9f2e-e686e2acc9fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e7fa14b4-8330-4b80-89b4-f2d54a22ba6e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e7fa14b4-8330-4b80-89b4-f2d54a22ba6e')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e7fa14b4-8330-4b80-89b4-f2d54a22ba6e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "\n",
        "pf_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "31deae14",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "31deae14",
        "outputId": "fa6ed190-f4f3-4148-9a36-18342cac3986",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "pf_data.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f0fd873",
      "metadata": {
        "tags": [],
        "id": "3f0fd873"
      },
      "source": [
        "### Analyzing Data for Backtesting <a name=\"Analyze_BackTest\"></a>look_back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "c6db17fa",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "c6db17fa",
        "outputId": "04915053-4c94-4469-d688-85f7fa7966a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       KOZAA  AKSEN  TOASO  TAVHL  TCELL  PETKM  EKGYO  KCHOL  ASELS  BIMAS  \\\n",
              "count  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
              "mean     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "std      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "min      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "25%      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "50%      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "75%      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "max      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "\n",
              "       ...  KRDMD  ALARK  HEKTS  QUAGR  FROTO  GUBRF  GARAN  TURSG  THYAO  \\\n",
              "count  ...  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
              "mean   ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "std    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "min    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "25%    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "50%    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "75%    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "max    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "\n",
              "       TRY=X  \n",
              "count  0.000  \n",
              "mean     NaN  \n",
              "std      NaN  \n",
              "min      NaN  \n",
              "25%      NaN  \n",
              "50%      NaN  \n",
              "75%      NaN  \n",
              "max      NaN  \n",
              "\n",
              "[8 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9fd6ac3-f6b0-4b22-8c34-6780043a79a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>KOZAA</th>\n",
              "      <th>AKSEN</th>\n",
              "      <th>TOASO</th>\n",
              "      <th>TAVHL</th>\n",
              "      <th>TCELL</th>\n",
              "      <th>PETKM</th>\n",
              "      <th>EKGYO</th>\n",
              "      <th>KCHOL</th>\n",
              "      <th>ASELS</th>\n",
              "      <th>BIMAS</th>\n",
              "      <th>...</th>\n",
              "      <th>KRDMD</th>\n",
              "      <th>ALARK</th>\n",
              "      <th>HEKTS</th>\n",
              "      <th>QUAGR</th>\n",
              "      <th>FROTO</th>\n",
              "      <th>GUBRF</th>\n",
              "      <th>GARAN</th>\n",
              "      <th>TURSG</th>\n",
              "      <th>THYAO</th>\n",
              "      <th>TRY=X</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9fd6ac3-f6b0-4b22-8c34-6780043a79a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b9fd6ac3-f6b0-4b22-8c34-6780043a79a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b9fd6ac3-f6b0-4b22-8c34-6780043a79a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a74c8653-f5e4-4cd5-9a63-2b010f4031a4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a74c8653-f5e4-4cd5-9a63-2b010f4031a4')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a74c8653-f5e4-4cd5-9a63-2b010f4031a4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "pf_data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84a79a6c",
      "metadata": {
        "id": "84a79a6c"
      },
      "source": [
        "#### Finding Daily returns\n",
        "\n",
        "Formulas used -> Ratio of present Day's return to Yesterday's return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "1b5e24e8",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "1b5e24e8",
        "outputId": "991ee2aa-3162-4e86-a01a-9083c4989613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       KOZAA  AKSEN  TOASO  TAVHL  TCELL  PETKM  EKGYO  KCHOL  ASELS  BIMAS  \\\n",
              "count  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
              "mean     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "std      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "min      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "25%      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "50%      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "75%      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "max      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "\n",
              "       ...  KRDMD  ALARK  HEKTS  QUAGR  FROTO  GUBRF  GARAN  TURSG  THYAO  \\\n",
              "count  ...  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
              "mean   ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "std    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "min    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "25%    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "50%    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "75%    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "max    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
              "\n",
              "       TRY=X  \n",
              "count  0.000  \n",
              "mean     NaN  \n",
              "std      NaN  \n",
              "min      NaN  \n",
              "25%      NaN  \n",
              "50%      NaN  \n",
              "75%      NaN  \n",
              "max      NaN  \n",
              "\n",
              "[8 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06fbec49-e455-460b-b6f4-8a7e2958a899\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>KOZAA</th>\n",
              "      <th>AKSEN</th>\n",
              "      <th>TOASO</th>\n",
              "      <th>TAVHL</th>\n",
              "      <th>TCELL</th>\n",
              "      <th>PETKM</th>\n",
              "      <th>EKGYO</th>\n",
              "      <th>KCHOL</th>\n",
              "      <th>ASELS</th>\n",
              "      <th>BIMAS</th>\n",
              "      <th>...</th>\n",
              "      <th>KRDMD</th>\n",
              "      <th>ALARK</th>\n",
              "      <th>HEKTS</th>\n",
              "      <th>QUAGR</th>\n",
              "      <th>FROTO</th>\n",
              "      <th>GUBRF</th>\n",
              "      <th>GARAN</th>\n",
              "      <th>TURSG</th>\n",
              "      <th>THYAO</th>\n",
              "      <th>TRY=X</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06fbec49-e455-460b-b6f4-8a7e2958a899')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06fbec49-e455-460b-b6f4-8a7e2958a899 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06fbec49-e455-460b-b6f4-8a7e2958a899');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0b6cb2cc-1f08-4b11-bd20-cc6a1854ebf8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b6cb2cc-1f08-4b11-bd20-cc6a1854ebf8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0b6cb2cc-1f08-4b11-bd20-cc6a1854ebf8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "pf_data.pct_change().describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bde2488",
      "metadata": {
        "id": "7bde2488"
      },
      "source": [
        "#### In finance, we generally use logarithmic returns for analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "ffa94a3c-485e-44f4-abf5-92f023559b9c",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "ffa94a3c-485e-44f4-abf5-92f023559b9c",
        "outputId": "4bff2816-0dfb-4fee-bb2f-25e9b7710c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-940fda346fd8>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mDrawSelectedAssetsPerformance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpf_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-53-940fda346fd8>\u001b[0m in \u001b[0;36mDrawSelectedAssetsPerformance\u001b[0;34m(pf_data)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# plt.figure()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#(pf_data[Metals]/pf_data[Metals].iloc[0]).plot(figsize = (15,30))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0mpf_data\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Seçilen {exchange} hisselerinin son {pf_data.shape[0]} günü \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1555\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "def DrawSelectedAssetsPerformance(pf_data):\n",
        "    from PIL import Image as im\n",
        "    fig = plt.figure(dpi=250) # plt.figure()\n",
        "    #(pf_data[Metals]/pf_data[Metals].iloc[0]).plot(figsize = (15,30))\n",
        "    (pf_data/pf_data.iloc[-pf_data.shape[0]]).tail(pf_data.shape[0]).plot(figsize = (15,10))\n",
        "    plt.grid(True)\n",
        "    plt.title(f\"Seçilen {exchange} hisselerinin son {pf_data.shape[0]} günü \")\n",
        "    plt.savefig(\"Fig_001_BIST30_Selected.jpg\", format='jpg', dpi=300)\n",
        "    from IPython.display import Image\n",
        "    Image(url=\"Fig_001_BIST30_Selected.jpg\")\n",
        "\n",
        "\n",
        "DrawSelectedAssetsPerformance(pf_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1142d324-39bf-4945-bdcd-1bee2536041f",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "1142d324-39bf-4945-bdcd-1bee2536041f"
      },
      "outputs": [],
      "source": [
        "pf_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d80a418-74a5-4054-8ea2-bb686f5b3c2a",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "0d80a418-74a5-4054-8ea2-bb686f5b3c2a"
      },
      "outputs": [],
      "source": [
        "pf_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fbe44f9-5164-4e03-8eb4-1962dcacad9e",
      "metadata": {
        "id": "1fbe44f9-5164-4e03-8eb4-1962dcacad9e"
      },
      "outputs": [],
      "source": [
        "pf_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5611368a",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "5611368a"
      },
      "outputs": [],
      "source": [
        "def ConvertTimeSeriesToReturns(pf_data):\n",
        "    log_returns = np.log(pf_data/pf_data.shift(1))\n",
        "    return log_returns\n",
        "\n",
        "\n",
        "def PlotCorrelations(log_returns, figname):\n",
        "    plt.figure(figsize=(18,18))\n",
        "    plt.title(f\"Korelasyon Tablosu\")\n",
        "    sns.heatmap(log_returns.corr(),linecolor='white',linewidths=1,annot=True)\n",
        "    plt.savefig(f\"{figname}_Coorelations.jpg\", format='jpg', dpi=300)\n",
        "    from IPython.display import Image\n",
        "    Image(url=f\"{figname}_Coorelations.jpg\")\n",
        "\n",
        "log_returns = ConvertTimeSeriesToReturns(pf_data)\n",
        "PlotCorrelations(log_returns, \"Fig_004\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0312c8ba-c864-458b-ac94-ca8295ca3795",
      "metadata": {
        "id": "0312c8ba-c864-458b-ac94-ca8295ca3795"
      },
      "outputs": [],
      "source": [
        "def PlotCorrelationsLessThanCorrFilter(log_returns, CORR_FILTER):\n",
        "    plt.figure(figsize=(16,16))\n",
        "    c = log_returns.corr()\n",
        "    sns.heatmap((c >= CORR_FILTER) ,linecolor='white',linewidths=1,annot = True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "PlotCorrelationsLessThanCorrFilter(log_returns, CORR_FILTER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "052e5759-b9a7-4bae-8396-b7e4eb39fce3",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "052e5759-b9a7-4bae-8396-b7e4eb39fce3"
      },
      "outputs": [],
      "source": [
        "# log_returns.drop(index=log_returns.index[0], axis=0, inplace=True)\n",
        "# log_returns\n",
        "\n",
        "# pd.isnull(log_returns).sum()[pd.isnull(log_returns).sum() > 0]\n",
        "\n",
        "def ReplaceLogReturns():\n",
        "    log_returns.drop(index=log_returns.index[0], axis=0, inplace=True)\n",
        "\n",
        "ReplaceLogReturns()\n",
        "\n",
        "\n",
        "def CheckForNull():\n",
        "    pd.isnull(log_returns).sum()[pd.isnull(log_returns).sum() > 0]\n",
        "\n",
        "CheckForNull()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f0e1648",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "0f0e1648"
      },
      "outputs": [],
      "source": [
        "# min_val = (log_returns.sum()*100).min() # returns within lookbakc period\n",
        "\n",
        "\n",
        "def FindMinOfSeries(log_returns):\n",
        "    min_val = (log_returns.sum()*100).min() # returns within lookbakc period\n",
        "    return min_val\n",
        "\n",
        "min_val = FindMinOfSeries(log_returns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3f48224-59c1-458f-ac55-4f15e709f0cb",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "d3f48224-59c1-458f-ac55-4f15e709f0cb"
      },
      "outputs": [],
      "source": [
        "# max_val = (log_returns.sum()*100).max() # returns within lookbakc period\n",
        "\n",
        "\n",
        "def FindMaxOfSeries(log_returns):\n",
        "    max_val = (log_returns.sum()*100).max() # returns within lookbakc period\n",
        "    return max_val\n",
        "\n",
        "\n",
        "max_val = FindMaxOfSeries(log_returns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c48d3de-465a-4f91-94f8-742c0117e1f0",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "4c48d3de-465a-4f91-94f8-742c0117e1f0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "86dd66c6",
      "metadata": {
        "id": "86dd66c6"
      },
      "source": [
        "Let's calculate the annual average return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e397ba8",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "6e397ba8"
      },
      "outputs": [],
      "source": [
        "np.round(log_returns.mean() *100,4).tail(60).max() # Stock market is open for almost 250 days in an year"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0db9dedb",
      "metadata": {
        "id": "0db9dedb"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9d12422",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "b9d12422"
      },
      "outputs": [],
      "source": [
        "np.round(log_returns.std().mean(),4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c8de92-2487-417a-847e-e9fa17edb4c8",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "d9c8de92-2487-417a-847e-e9fa17edb4c8"
      },
      "outputs": [],
      "source": [
        "# log_returns[['ARCLK','XU100']].cov()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef06b07f-5e2a-4ed4-b44b-72212feedbe9",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "ef06b07f-5e2a-4ed4-b44b-72212feedbe9"
      },
      "outputs": [],
      "source": [
        "# log_returns[['XU100']].var()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "624447c9",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "624447c9"
      },
      "outputs": [],
      "source": [
        "# beta = log_returns[['ARCLK','XU100']].cov() / log_returns[['XU100']].var()\n",
        "# beta.iloc[0][1]\n",
        "log_returns.index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e916687",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "0e916687"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a2e869d-1fcd-4654-b217-627884a79f14",
      "metadata": {
        "id": "7a2e869d-1fcd-4654-b217-627884a79f14"
      },
      "outputs": [],
      "source": [
        "len(log_returns.mean()*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d813488-8c01-4c4c-84bb-c82b16cd6205",
      "metadata": {
        "id": "8d813488-8c01-4c4c-84bb-c82b16cd6205"
      },
      "outputs": [],
      "source": [
        "def PrintSharpePerformance():\n",
        "    yearly_rets = np.round(log_returns.mean() * 252,2) # Mean returns annualized for year\n",
        "    yearly_rets\n",
        "    vol = np.round(log_returns.std()*np.sqrt(252),3) # annualized version of std deviation\n",
        "    vol\n",
        "    sharpe = (yearly_rets - risk_free_rate)/vol\n",
        "    sharpe\n",
        "    max_sr_vol = vol[sharpe.argmax()] # risk corresponding to maximum sharpe ratio\n",
        "    max_sr_ret = yearly_rets[sharpe.argmax()] # return corresponding to maximum sharpe ratio\n",
        "    # plt.figure(figsize=(10,10))\n",
        "    # plt.scatter(vol, log_returns.mean()*100, c=sharpe, cmap='viridis')\n",
        "    # plt.colorbar(label='Sharpe Ratio')\n",
        "    # plt.xlabel('Volatility')\n",
        "    # plt.ylabel('Return')\n",
        "    # plt.title('Some BIST assets')\n",
        "    # plt.scatter(max_sr_vol, max_sr_ret,c='red', s=50) # red dot\n",
        "\n",
        "    # plt.text(vol, log_returns.mean()*100, s=log_returns.mean().index)\n",
        "    ASSETS = log_returns.mean().index\n",
        "\n",
        "    #plt.text(vol, log_returns.mean()*100, ASSETS)\n",
        "\n",
        "    # labels = ['Variable {0}'.format(i+1) for i in np.arange(len(ASSETS))]\n",
        "    # for i in np.arange (0,len(ASSETS)):\n",
        "\n",
        "    print(f\"Sharpe Ratio = {sharpe[1]}\")\n",
        "    print(f\"Max Sharpe Ratio = {sharpe.max()}\")\n",
        "    print(f\"Max Sharpe Ratio Return = {max_sr_ret}\")\n",
        "    print(f\"Max Sharpe Ratio Volatility = {max_sr_vol}\")\n",
        "    return vol, ASSETS,sharpe\n",
        "\n",
        "vol, ASSETS,sharpe = PrintSharpePerformance()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a01862f-f954-40ac-bec3-1092e42ea1e3",
      "metadata": {
        "id": "6a01862f-f954-40ac-bec3-1092e42ea1e3"
      },
      "outputs": [],
      "source": [
        "def plot_with_labels(coord, labels, sharpe):\n",
        "    assert len(coord) == len(labels), 'coord len is not equal to labels len'\n",
        "    plt.figure(figsize=(10, 10))  # in inches\n",
        "    for i, label in enumerate(labels): #get (0, label)\n",
        "        x, y = coord[i] #2 dim\n",
        "        #plt.scatter(x, y)\n",
        "        # yearly_rets = np.round(log_returns.mean() * 252,2) # Mean returns annualized for year\n",
        "        # vol = np.round(log_returns.std()*np.sqrt(252),3) # annualized version of std deviation\n",
        "\n",
        "        #sharpe = (y - risk_free_rate)/x\n",
        "        plt.scatter(x, y, c=sharpe[i], cmap='viridis')\n",
        "        plt.annotate(label,\n",
        "                xy=(x, y), #show point\n",
        "                xytext=(5, 2), #show annotate\n",
        "                textcoords='offset points',\n",
        "                ha='left',\n",
        "                va='bottom')\n",
        "\n",
        "    plt.colorbar(label='Sharpe Ratio')\n",
        "    plt.xlabel('Volatility %')\n",
        "    plt.ylabel('Return')\n",
        "    plt.grid(True)\n",
        "    plt.title(f'Best {len(log_returns.mean())} of BIST R-R Map')\n",
        "    plt.savefig(\"Fig_002_R-R_Map.jpg\", format='jpg', dpi=300)\n",
        "    plt.show()\n",
        "    return \"Fig_002_R-R_Map.jpg\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63422398-8f1d-471d-bcb6-aaad70a0c7cc",
      "metadata": {
        "id": "63422398-8f1d-471d-bcb6-aaad70a0c7cc"
      },
      "outputs": [],
      "source": [
        "def PlotRRMap():\n",
        "    coord = list(zip(vol, log_returns.mean()*100))\n",
        "    labels = ASSETS\n",
        "    aa = plot_with_labels(coord, labels, sharpe)\n",
        "    from IPython.display import Image\n",
        "    Image(url=aa)\n",
        "\n",
        "PlotRRMap()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7151829",
      "metadata": {
        "id": "b7151829"
      },
      "source": [
        "#### Plotting Correlation HeatMap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a170bc5",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "8a170bc5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# plt.figure(figsize=(15,8))\n",
        "# sns.heatmap(log_returns.corr(),linecolor='white',linewidths=1,annot=True)\n",
        "# plt.title(\"correlation heatmap of stocks\")\n",
        "# plt.show()\n",
        "# len(sharpe)\n",
        "\n",
        "PlotCorrelations(log_returns, figname=\"Fig+008\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93804f6e",
      "metadata": {
        "id": "93804f6e"
      },
      "source": [
        "#### Using heatmap to find strongly positive or strongly negative correlated stocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27d599d1",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "27d599d1"
      },
      "outputs": [],
      "source": [
        "stock_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d547f002-692c-4354-931a-1b8ae236c768",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "d547f002-692c-4354-931a-1b8ae236c768"
      },
      "outputs": [],
      "source": [
        "# # plt.figure(figsize=(15,8))\n",
        "# c = log_returns.corr()\n",
        "# sns.heatmap((c < -0.51) ,linecolor='white',linewidths=1,annot = True)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "783e390a",
      "metadata": {
        "id": "783e390a"
      },
      "source": [
        "- From the heatmaps, we can observe that there is no pair with negative correlation\n",
        "- We only have some pairs of stocks from banking sector with  high positive correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9cbccee",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "c9cbccee"
      },
      "outputs": [],
      "source": [
        "# sns.pairplot(pf_data,palette='coolwarm')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81fb1f5b",
      "metadata": {
        "id": "81fb1f5b"
      },
      "source": [
        "- The pair plots also signify the same result that there is no pair of stocks with high negative correlation. We don't find any pair-plot with upper-left to lower-right pattern.\n",
        "- The pairs with high positive correlation have scatter plot with lower-left to upper-right pattern .\n",
        "- Other pairs don't form any pattern."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64880153",
      "metadata": {
        "tags": [],
        "id": "64880153"
      },
      "source": [
        "### Markowitz Model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ad8e153",
      "metadata": {
        "id": "4ad8e153"
      },
      "source": [
        "\n",
        "- We model our assets by their expected return, $E[R]$ and their risk, which is expressed as their standard deviation, $\\sigma$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec628315",
      "metadata": {
        "id": "ec628315"
      },
      "source": [
        "- Our investment decisions are expressed by investing 100% of our wealth in assets( here, stocks), where each particular investment represents a proportion of our total wealth."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7639a7a4",
      "metadata": {
        "id": "7639a7a4"
      },
      "source": [
        "\n",
        "- We will now implement Markowitz Model. This model assists in the selection of the most efficient portfolios by analyzing various possible portfolios of the selected stocks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70a24d2e",
      "metadata": {
        "id": "70a24d2e"
      },
      "source": [
        "- We invest $w_i$ in $stock_i$ for every i, such that"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac32f00",
      "metadata": {
        "id": "fac32f00"
      },
      "source": [
        "- The expected return of the portfolio constructed would be"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc47483b",
      "metadata": {
        "id": "dc47483b"
      },
      "source": [
        "<h2>\n",
        "$$E[R_p] = \\Sigma^{n}_{i=1} w_i E[R_i]$$</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb1d3328",
      "metadata": {
        "id": "eb1d3328"
      },
      "source": [
        "and the risk associated with the portfolio would be\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0082f634",
      "metadata": {
        "id": "0082f634"
      },
      "source": [
        "$$ S = \\frac{E[R_p] - R_f}{\\sigma(R_p)} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da4a5fe3",
      "metadata": {
        "id": "da4a5fe3"
      },
      "source": [
        "Here, $R_f$ is the risk free rate of return. we have taken risk free rate yearly government interest rate of Turkey on July 2022, i.e %14."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8245cdf1-3a17-400f-b5f0-5fd7ce8e063f",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "8245cdf1-3a17-400f-b5f0-5fd7ce8e063f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "122e1533",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "122e1533"
      },
      "outputs": [],
      "source": [
        "# A function for generating a numpy array containing random weights that add upto 1\n",
        "def RandWeights(size):\n",
        "    weight = np.random.dirichlet(alpha = np.ones(size))\n",
        "    # BURAYA MAKSIMUM AGIRLIGIN %20 OLABILECEGI KOSULU EKLE\n",
        "    return weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2c73b76-0818-4aaa-b5f0-6f5627c0be13",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "c2c73b76-0818-4aaa-b5f0-6f5627c0be13"
      },
      "outputs": [],
      "source": [
        "a = RandWeights(10)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2683ad0e",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "2683ad0e"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# A function to generate the avg return, risk and the sharpe ratio of the portfolio\n",
        "# correponding to the weight array passed\n",
        "def portfolio_stats(weight):\n",
        "\n",
        "    # Convert to array in case list was passed instead.\n",
        "    weight = np.array(weight)\n",
        "    port_return = np.sum(log_returns.mean() * weight) * 252\n",
        "    #port_return = log_returns.mean() * weight\n",
        "    port_risk = np.sqrt(np.dot(weight.T, np.dot(log_returns.cov() * 252, weight)))\n",
        "    #port_risk = np.sqrt(np.dot(weight.T, np.dot(log_returns.cov() * 252, weight))) / np.sqrt(252)\n",
        "    sharpe = (port_return - risk_free_rate)/port_risk\n",
        "\n",
        "    return {'return': port_return, 'risk': port_risk, 'sharpe': sharpe}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16e7b420",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "16e7b420"
      },
      "outputs": [],
      "source": [
        "# Trying to generate random weights\n",
        "\n",
        "# length = len(log_returns.columns)\n",
        "# weight = RandWeights(length)\n",
        "# weight\n",
        "\n",
        "\n",
        "def CalculateRandomWeights():\n",
        "    length = len(log_returns.columns)\n",
        "    weight = RandWeights(length)\n",
        "    return length, weight\n",
        "\n",
        "length, weight = CalculateRandomWeights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4664c1d8",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "4664c1d8"
      },
      "outputs": [],
      "source": [
        "# Generating Portfolio Statistics\n",
        "# pf_stats = portfolio_stats(weight)\n",
        "\n",
        "# pf_return = pf_stats['return']\n",
        "# pf_risk = pf_stats['risk']\n",
        "# pf_sharpe = pf_stats['sharpe']\n",
        "\n",
        "# pf_stats\n",
        "\n",
        "# Generating Portfolio Statistics\n",
        "def EvaluatePortfolio(weight):\n",
        "\n",
        "    pf_stats = portfolio_stats(weight)\n",
        "    pf_return = pf_stats['return']\n",
        "    pf_risk = pf_stats['risk']\n",
        "    pf_sharpe = pf_stats['sharpe']\n",
        "    return pf_stats\n",
        "\n",
        "\n",
        "pf_stats = EvaluatePortfolio(weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c5e0c05",
      "metadata": {
        "id": "3c5e0c05"
      },
      "source": [
        "#### We will now run a monte carlo simulation to generate random portfolios. We will use the results of simulation to draw an efficient frontier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "258977b0",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "258977b0"
      },
      "outputs": [],
      "source": [
        "\n",
        "def Monte_Carlo(iterations):\n",
        "    portfolio_returns = []\n",
        "    portfolio_risks = []\n",
        "    for x in range (iterations):\n",
        "        weight = RandWeights(length)\n",
        "        pf_stats = portfolio_stats(weight)\n",
        "        portfolio_returns.append(pf_stats['return'])\n",
        "        portfolio_risks.append(pf_stats['risk'])\n",
        "\n",
        "    portfolio_returns = np.array(portfolio_returns)\n",
        "    portfolio_risks = np.array(portfolio_risks)\n",
        "    return portfolio_returns, portfolio_risks\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42dbb927-7e1b-484b-b5b7-bff5f4cc399c",
      "metadata": {
        "tags": [],
        "id": "42dbb927-7e1b-484b-b5b7-bff5f4cc399c"
      },
      "source": [
        "### Generate random Markowitz portfolios via Montecarlo for Sharpe Analysis <a name=\"Generate_Markowitz\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3296696",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "a3296696"
      },
      "outputs": [],
      "source": [
        "def MonteCarloAnalysis():\n",
        "    portfolio_returns, portfolio_risks = Monte_Carlo(CASES)\n",
        "    sharpe = (portfolio_returns - Rfr) / portfolio_risks\n",
        "    max_sr_ret = portfolio_returns[sharpe.argmax()] # return corresponding to maximum sharpe ratio\n",
        "    max_sr_vol = portfolio_risks[sharpe.argmax()] # risk corresponding to maximum sharpe ratio\n",
        "    plt.figure(figsize=(18,10))\n",
        "    plt.scatter(portfolio_risks, portfolio_returns, c=sharpe, cmap='viridis')\n",
        "    plt.colorbar(label='Sharpe Oranı')\n",
        "    plt.title(f\"{CASES} adet {exchange} Portföyünün Montecarlo Analizi\")\n",
        "    plt.xlabel('Risk')\n",
        "    plt.ylabel('Getiri')\n",
        "    plt.scatter(max_sr_vol, max_sr_ret,c='red', s=50) # red dot\n",
        "    plt.grid(True)\n",
        "    plt.savefig(\"Fig_003_Montecarlo.jpg\", format='jpg', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    from IPython.display import Image\n",
        "    Image(url=\"Fig_003_Montecarlo.jpg\")\n",
        "\n",
        "    print(f\"max Sharpe Ratio = {sharpe.max()}\")\n",
        "    print(f\"max Sharpe Ratio return = {max_sr_ret}\")\n",
        "    print(f\"max Sharpe Ratio volatility = {max_sr_vol}\")\n",
        "    return portfolio_returns, portfolio_risks, sharpe\n",
        "\n",
        "portfolio_returns, portfolio_risks, sharpe = MonteCarloAnalysis()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc3af555",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "dc3af555"
      },
      "outputs": [],
      "source": [
        "\n",
        "def OptimizationWithSharpeRatio():\n",
        "\n",
        "    def FindNegSharpe(weight):\n",
        "        return (-1)*portfolio_stats(weight)['sharpe']\n",
        "\n",
        "    res = minimize(\n",
        "          FindNegSharpe,\n",
        "          RandWeights(length),\n",
        "          method = 'SLSQP',\n",
        "          constraints=[\n",
        "            {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
        "          ],\n",
        "          bounds=[(P_BOUND_LO, P_BOUND_HI) for i in range(length)]\n",
        "        )\n",
        "\n",
        "    return res\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "498beecf-0af9-453f-ac89-a1aa6669a12b",
      "metadata": {
        "id": "498beecf-0af9-453f-ac89-a1aa6669a12b"
      },
      "source": [
        "Think like Harry Markowitz. Write python code for generation of best Sharpe Ratio and the least drawdown portfolio out of all input assets  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f70947e-3eea-42cb-b17d-d3279dbea9f1",
      "metadata": {
        "id": "2f70947e-3eea-42cb-b17d-d3279dbea9f1"
      },
      "outputs": [],
      "source": [
        "def OptimizationWithLDD(rets):\n",
        "\n",
        "    def FindNegSharpe(weight):\n",
        "        neg_sharpe = (-1)*portfolio_stats(weight)['sharpe']\n",
        "        drawdown = (1 + weight * rets).cumprod().apply(np.log).cummin()\n",
        "        drawdown = (1 - drawdown.iloc[-1]) * 100\n",
        "        return neg_sharpe, drawdown\n",
        "\n",
        "    res = minimize(\n",
        "          FindNegSharpe,\n",
        "          RandWeights(length),\n",
        "          method = 'SLSQP',\n",
        "          constraints=[\n",
        "            {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
        "          ],\n",
        "          bounds=[(P_BOUND_LO, P_BOUND_HI) for i in range(length)]\n",
        "        )\n",
        "\n",
        "    return res\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "016f0be9",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "016f0be9"
      },
      "outputs": [],
      "source": [
        "# def OptimizationWithLeastDrawdown(returns):\n",
        "\n",
        "#     from scipy.optimize import minimize\n",
        "#     def portfolio_performance(weights, returns):\n",
        "#         portfolio_return = np.sum(returns.mean() * weights) * 252\n",
        "#         portfolio_variance = np.sqrt(np.dot(weights.T, np.dot(returns.cov() * 252, weights)))\n",
        "#         sharpe_ratio = portfolio_return / portfolio_variance\n",
        "#         drawdown = (1 + weights * returns).cumprod().apply(np.log).cummin()\n",
        "#         drawdown = (1 - drawdown.iloc[-1]) * 100\n",
        "#         return -sharpe_ratio, drawdown\n",
        "\n",
        "#     def optimize_portfolio(returns):\n",
        "#         num_assets = returns.shape[1]\n",
        "#         args = (returns,)\n",
        "#         constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
        "#         bounds = tuple((0, 1) for asset in range(num_assets))\n",
        "#         initial_guess = num_assets * [1. / num_assets,]\n",
        "#         opt_results = minimize(portfolio_performance, initial_guess, args=args, method='SLSQP', bounds=bounds, constraints=constraints)\n",
        "#         return opt_results.x\n",
        "\n",
        "#     # Use the Markowitz optimization method to find the portfolio with the highest Sharpe ratio and the least drawdown\n",
        "#     weights = optimize_portfolio(returns)\n",
        "\n",
        "#     # Print the weights of the optimized portfolio\n",
        "#     return(weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "edd6a59b-915f-4ae0-8374-d0c8628d4dc0",
      "metadata": {
        "id": "edd6a59b-915f-4ae0-8374-d0c8628d4dc0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8373805c-6d66-4470-86da-1ce19200da99",
      "metadata": {
        "id": "8373805c-6d66-4470-86da-1ce19200da99"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a09ef55f",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "a09ef55f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def OptimizationForAGivenReturn(target_return):\n",
        "\n",
        "    def fun(weight):\n",
        "        pf_stats = portfolio_stats(weight)\n",
        "        _risk = pf_stats['risk']\n",
        "        return _risk\n",
        "\n",
        "    res = minimize(\n",
        "      fun,\n",
        "      RandWeights(length),\n",
        "      method = 'SLSQP',\n",
        "      constraints=[{'type':'eq','fun': lambda x: portfolio_stats(x)['return']-target_return},\n",
        "                   {'type':'eq','fun': lambda x: np.sum(x)-1}],\n",
        "      bounds=[(P_BOUND_LO, P_BOUND_HI) for i in range(length)]\n",
        "    )\n",
        "\n",
        "    return res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41ef8376",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "41ef8376"
      },
      "outputs": [],
      "source": [
        "# OptimizationForAGivenReturn(max_sr_ret)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "083ce380",
      "metadata": {
        "id": "083ce380"
      },
      "source": [
        "- For a return of 40%, we can find the optimal portfolio corresponding to the weights generated above"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8349409",
      "metadata": {
        "id": "a8349409"
      },
      "source": [
        "#### Finding portfolio that provide the minimum risk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d640ac4-d35e-401e-8cde-c3845efe6ccf",
      "metadata": {
        "id": "2d640ac4-d35e-401e-8cde-c3845efe6ccf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "146dadcd",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "146dadcd"
      },
      "outputs": [],
      "source": [
        "\n",
        "def OptimizingWithMinRisk():\n",
        "\n",
        "    def fun(weight):\n",
        "        pf_stats = portfolio_stats(weight)\n",
        "        _risk = pf_stats['risk']\n",
        "        return _risk\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    res = minimize(\n",
        "      fun,\n",
        "      RandWeights(length),\n",
        "      method = 'SLSQP',\n",
        "      constraints=[\n",
        "        {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.},\n",
        "      ],\n",
        "      bounds=[(P_BOUND_LO, P_BOUND_HI) for i in range(length)]\n",
        "    )\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09662e9f",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "09662e9f"
      },
      "outputs": [],
      "source": [
        "OptimizingWithMinRisk()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da0541e3",
      "metadata": {
        "tags": [],
        "id": "da0541e3"
      },
      "source": [
        "### Plotting the efficient Frontier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54a34f34",
      "metadata": {
        "id": "54a34f34"
      },
      "source": [
        "- The efficient frontier is the set of optimal portfolios that offer the highest expected return for a defined level of risk or the lowest risk for a given level of expected return. Portfolios that lie below the efficient frontier are sub-optimal because they do not provide enough return for the level of risk.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a2e5d20",
      "metadata": {
        "id": "6a2e5d20"
      },
      "source": [
        "- We will plot the efficient frontier by taking the optimal portfolios for all possible returns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "048a1a27-6e5a-42da-9441-3f51e9c17e15",
      "metadata": {
        "id": "048a1a27-6e5a-42da-9441-3f51e9c17e15"
      },
      "source": [
        "### Find Optimal weights For Highest Sharpe Ratio and Least Drawdown <a name=\"Least_MDD\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ecbf27f-e806-4f29-8a3b-a3daba07c548",
      "metadata": {
        "id": "2ecbf27f-e806-4f29-8a3b-a3daba07c548"
      },
      "outputs": [],
      "source": [
        "log_returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b91f9b4-9ee6-431e-b1a0-0968ce6d0917",
      "metadata": {
        "id": "4b91f9b4-9ee6-431e-b1a0-0968ce6d0917"
      },
      "outputs": [],
      "source": [
        "#OptimizationWithLDD(log_returns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d61727-ae70-4196-b878-62be01f12110",
      "metadata": {
        "id": "b5d61727-ae70-4196-b878-62be01f12110"
      },
      "outputs": [],
      "source": [
        "#Optimal_Weights_For_Least_Drawdown = OptimizationWithLeastDrawdown(log_returns).x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7eb45f1",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "b7eb45f1"
      },
      "outputs": [],
      "source": [
        "# target_returns = np.linspace(portfolio_returns.min(), portfolio_returns.max(),20)\n",
        "\n",
        "# minimal_risks = []\n",
        "# for target_return in target_returns:\n",
        "#     optimal = OptimizationForAGivenReturn(target_return)\n",
        "#     minimal_risks.append(optimal['fun'])\n",
        "\n",
        "# minimal_risks = np.array(minimal_risks)\n",
        "# print(minimal_risks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "935cc8b1-6a90-448b-a19c-24164a1c7a67",
      "metadata": {
        "tags": [],
        "id": "935cc8b1-6a90-448b-a19c-24164a1c7a67"
      },
      "source": [
        "### Find Optimal weights For Highest Sharpe Ratio <a name=\"Optimal_Sharpe\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0eb58053",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "0eb58053"
      },
      "outputs": [],
      "source": [
        "# plt.figure(figsize=(18,10))\n",
        "\n",
        "# plt.scatter(portfolio_risks, portfolio_returns,\n",
        "#             c = ( portfolio_returns / portfolio_risks),\n",
        "#             marker = 'o', cmap='viridis')\n",
        "\n",
        "\n",
        "\n",
        "# # # Plotting the efficient frontier\n",
        "# # plt.scatter(minimal_risks,\n",
        "# #             target_returns,\n",
        "# #             c = (target_returns / minimal_risks),\n",
        "# #             marker = 'x')\n",
        "\n",
        "\n",
        "# # Plotting the portfolio that has highest Sharpe Ratio\n",
        "# Optimal_weights_For_Highest_Sharpe_Ratio = OptimizationWithSharpeRatio().x\n",
        "# print(f\"Optimal_weights_For_Highest_Sharpe_Ratio = {Optimal_weights_For_Highest_Sharpe_Ratio}\")\n",
        "# plt.plot(portfolio_stats(Optimal_weights_For_Highest_Sharpe_Ratio)['risk'],\n",
        "#          portfolio_stats(Optimal_weights_For_Highest_Sharpe_Ratio)['return'],\n",
        "#          'r*',\n",
        "#          markersize = 25.0, label = \"Portfolio corresponding to max sharpe\")\n",
        "\n",
        "\n",
        "\n",
        "# # # Plotting the optimal portfolio that has lowest risk\n",
        "# Optimal_weights_For_Lowest_Risk = OptimizingWithMinRisk().x\n",
        "# print(f\"Optimal_weights_For_Lowest_Risk = {Optimal_weights_For_Lowest_Risk}\")\n",
        "\n",
        "# plt.plot(portfolio_stats(Optimal_weights_For_Lowest_Risk)['risk'],\n",
        "#          portfolio_stats(Optimal_weights_For_Lowest_Risk)['return'],\n",
        "#          'g*',\n",
        "#          markersize = 25.0, label = \"Portfolio corresponding to lowest risk\")\n",
        "\n",
        "# #Plotting the optimal portfolio for 250% annual returns\n",
        "# Optimal_weights_for_Percent_Returns = OptimizationForAGivenReturn(3).x\n",
        "# Optimal_weights_for_twenty_five_percent_returns = OptimizationForAGivenReturn(1).x\n",
        "# Optimal_weights_for_Percent_Returns\n",
        "# plt.plot(portfolio_stats(Optimal_weights_for_twenty_five_percent_returns)['risk'],\n",
        "#          portfolio_stats(Optimal_weights_for_twenty_five_percent_returns)['return'],\n",
        "#          'b*',\n",
        "#          markersize = 25.0, label = \"Optimal Portfolio corresponding to 100% return\")\n",
        "\n",
        "\n",
        "# # Plotting the optimal portfolio for 150% annual returns\n",
        "# Optimal_weights_for_thirty_five_percent_returns = OptimizationForAGivenReturn(1.5).x\n",
        "\n",
        "# plt.plot(portfolio_stats(Optimal_weights_for_thirty_five_percent_returns)['risk'],\n",
        "#          portfolio_stats(Optimal_weights_for_thirty_five_percent_returns)['return'],\n",
        "#          'm*',\n",
        "#          markersize = 25.0, label = \"Optimal Portfolio corresponding to 150% return\")\n",
        "\n",
        "# plt.title(\"Risk Return Map\",fontsize = 25)\n",
        "# plt.grid(True)\n",
        "# plt.xlabel('Portfolio Risk',fontsize = 20)\n",
        "# plt.ylabel('Portfolio Return', fontsize = 20)\n",
        "\n",
        "# plt.legend(prop={'size': 10})\n",
        "# plt.colorbar(label='Sharpe ratio')\n",
        "\n",
        "# plt.savefig(\"Fig_005_RRMAP.jpg\", format='jpg', dpi=300)\n",
        "\n",
        "# from IPython.display import Image\n",
        "# Image(url=\"Fig_005_RRMAP.jpg\")\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "431a3349-268f-4cca-951a-1e13613c813f",
      "metadata": {
        "id": "431a3349-268f-4cca-951a-1e13613c813f"
      },
      "outputs": [],
      "source": [
        "def PlotandOptimizeWeightsForReturns():\n",
        "    plt.figure(figsize=(18,10))\n",
        "    plt.scatter(portfolio_risks, portfolio_returns,\n",
        "                c = ( portfolio_returns / portfolio_risks),\n",
        "                marker = 'o', cmap='viridis')\n",
        "\n",
        "\n",
        "\n",
        "    # # Plotting the efficient frontier\n",
        "    # plt.scatter(minimal_risks,\n",
        "    #             target_returns,\n",
        "    #             c = (target_returns / minimal_risks),\n",
        "    #             marker = 'x')\n",
        "\n",
        "\n",
        "    # Plotting the portfolio that has highest Sharpe Ratio\n",
        "    Optimal_weights_For_Highest_Sharpe_Ratio = OptimizationWithSharpeRatio().x\n",
        "    print(f\"Optimal_weights_For_Highest_Sharpe_Ratio = {Optimal_weights_For_Highest_Sharpe_Ratio}\")\n",
        "    plt.plot(portfolio_stats(Optimal_weights_For_Highest_Sharpe_Ratio)['risk'],\n",
        "             portfolio_stats(Optimal_weights_For_Highest_Sharpe_Ratio)['return'],\n",
        "             'r*',\n",
        "             markersize = 25.0, label = \"Portfolio corresponding to max sharpe\")\n",
        "\n",
        "\n",
        "\n",
        "    # # Plotting the optimal portfolio that has lowest risk\n",
        "    Optimal_weights_For_Lowest_Risk = OptimizingWithMinRisk().x\n",
        "    print(f\"Optimal_weights_For_Lowest_Risk = {Optimal_weights_For_Lowest_Risk}\")\n",
        "\n",
        "    plt.plot(portfolio_stats(Optimal_weights_For_Lowest_Risk)['risk'],\n",
        "             portfolio_stats(Optimal_weights_For_Lowest_Risk)['return'],\n",
        "             'g*',\n",
        "             markersize = 25.0, label = \"Portfolio corresponding to lowest risk\")\n",
        "\n",
        "    #Plotting the optimal portfolio for 250% annual returns\n",
        "    Optimal_weights_for_Percent_Returns = OptimizationForAGivenReturn(3).x\n",
        "    Optimal_weights_for_twenty_five_percent_returns = OptimizationForAGivenReturn(1).x\n",
        "    Optimal_weights_for_Percent_Returns\n",
        "    plt.plot(portfolio_stats(Optimal_weights_for_twenty_five_percent_returns)['risk'],\n",
        "             portfolio_stats(Optimal_weights_for_twenty_five_percent_returns)['return'],\n",
        "             'b*',\n",
        "             markersize = 25.0, label = \"Optimal Portfolio corresponding to 100% return\")\n",
        "\n",
        "\n",
        "    # Plotting the optimal portfolio for 150% annual returns\n",
        "    Optimal_weights_for_thirty_five_percent_returns = OptimizationForAGivenReturn(1.5).x\n",
        "\n",
        "    plt.plot(portfolio_stats(Optimal_weights_for_thirty_five_percent_returns)['risk'],\n",
        "             portfolio_stats(Optimal_weights_for_thirty_five_percent_returns)['return'],\n",
        "             'm*',\n",
        "             markersize = 25.0, label = \"Optimal Portfolio corresponding to 150% return\")\n",
        "\n",
        "    plt.title(\"Risk Return Map\",fontsize = 25)\n",
        "    plt.grid(True)\n",
        "    plt.xlabel('Portfolio Risk',fontsize = 20)\n",
        "    plt.ylabel('Portfolio Return', fontsize = 20)\n",
        "\n",
        "    plt.legend(prop={'size': 10})\n",
        "    plt.colorbar(label='Sharpe ratio')\n",
        "\n",
        "    plt.savefig(\"Fig_005_RRMAP.jpg\", format='jpg', dpi=300)\n",
        "\n",
        "    from IPython.display import Image\n",
        "    Image(url=\"Fig_005_RRMAP.jpg\")\n",
        "    plt.show()\n",
        "    return Optimal_weights_For_Highest_Sharpe_Ratio\n",
        "\n",
        "Optimal_weights_For_Highest_Sharpe_Ratio = PlotandOptimizeWeightsForReturns()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd8f860f-4e8d-4a2c-b902-2e515f0fe4f4",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "bd8f860f-4e8d-4a2c-b902-2e515f0fe4f4"
      },
      "outputs": [],
      "source": [
        "#portfolio_stats(Optimal_weights_for_Percent_Returns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e99517f5-4822-43c2-a55f-c5e0766eff4c",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "e99517f5-4822-43c2-a55f-c5e0766eff4c"
      },
      "outputs": [],
      "source": [
        "#portfolio_stats(Optimal_weights_For_Lowest_Risk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f8458a3-4399-438e-96f5-3eb6d66c6dd0",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "3f8458a3-4399-438e-96f5-3eb6d66c6dd0"
      },
      "outputs": [],
      "source": [
        "portfolio_stats(Optimal_weights_For_Highest_Sharpe_Ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c82d019-611b-48dc-9a74-57dd0557f4de",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "6c82d019-611b-48dc-9a74-57dd0557f4de"
      },
      "outputs": [],
      "source": [
        "# WEIGHT_HSR = portfolio_stats(Optimal_weights_For_Highest_Sharpe_Ratio)['return']\n",
        "# STDDEV_HSR = portfolio_stats(Optimal_weights_For_Highest_Sharpe_Ratio)['risk']/np.sqrt(252)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa0c7ca0-f7d1-4d4a-ab7b-0b4ed2e64989",
      "metadata": {
        "id": "fa0c7ca0-f7d1-4d4a-ab7b-0b4ed2e64989"
      },
      "outputs": [],
      "source": [
        "def FindWeights():\n",
        "    WEIGHT_HSR = portfolio_stats(Optimal_weights_For_Highest_Sharpe_Ratio)['return']\n",
        "    STDDEV_HSR = portfolio_stats(Optimal_weights_For_Highest_Sharpe_Ratio)['risk']/np.sqrt(252)\n",
        "    Optimal_weights_for_Percent_Returns = OptimizationForAGivenReturn(WEIGHT_HSR).x\n",
        "    print(portfolio_stats(Optimal_weights_for_Percent_Returns))\n",
        "    print(np.round(Optimal_weights_For_Highest_Sharpe_Ratio,4))\n",
        "    return np.round(Optimal_weights_For_Highest_Sharpe_Ratio,4)\n",
        "\n",
        "\n",
        "Optimal_weights_for_Percent_Returns = FindWeights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1193c39f-5048-4eb0-9f08-9953c2cf5aa8",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "1193c39f-5048-4eb0-9f08-9953c2cf5aa8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f850390-fd19-4133-a82a-2f047e78a235",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "0f850390-fd19-4133-a82a-2f047e78a235"
      },
      "outputs": [],
      "source": [
        "# Optimal_weights_for_Percent_Returns = OptimizationForAGivenReturn(WEIGHT_HSR).x\n",
        "# portfolio_stats(Optimal_weights_for_Percent_Returns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79b620bc-062a-454c-896e-fb954c698ca7",
      "metadata": {
        "tags": [],
        "id": "79b620bc-062a-454c-896e-fb954c698ca7"
      },
      "source": [
        "### Present Optimal Portfolio For Highest Sharpe Ratio <a name=\"Optimal_Portfolio\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "396f5224-7aa9-425b-9a40-cdd45c172b7a",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "396f5224-7aa9-425b-9a40-cdd45c172b7a"
      },
      "outputs": [],
      "source": [
        "\n",
        "#w = np.round(Optimal_weights_for_Percent_Returns,4)\n",
        "#w = np.round(Optimal_weights_For_Lowest_Risk,4)\n",
        "\n",
        "\n",
        "# BEST_PF = pd.Series(w*100, stock_list)\n",
        "# print(\"% weights of BEST PF\")\n",
        "# index = w>=0.01\n",
        "# Final_TEFAS_PF = pd.DataFrame(BEST_PF[index].round(3),  columns=['%'] )\n",
        "# Portfolio_Weights = w[index].round(4)\n",
        "# Portfolio_Assets = BEST_PF[index]\n",
        "# Portfolio_Amounts = Portfolio_Weights*CURRENT_T2\n",
        "# Final_TEFAS_PF[f\"Amount in {CURRENT_T2} {currency}\"] = np.round(Portfolio_Amounts,2)\n",
        "# pf_stats = portfolio_stats(Optimal_weights_For_Highest_Sharpe_Ratio)\n",
        "# print(portfolio_stats(Optimal_weights_For_Highest_Sharpe_Ratio))\n",
        "# Final_TEFAS_PF.sort_values(by=['%'], ascending=[False], inplace = True)\n",
        "# Final_TEFAS_PF\n",
        "\n",
        "w = np.round(Optimal_weights_For_Highest_Sharpe_Ratio,4)\n",
        "\n",
        "def OptimizeWeights(w,stock_list):\n",
        "\n",
        "    BEST_PF = pd.Series(w*100, stock_list)\n",
        "    print(\"% weights of BEST PF\")\n",
        "    index = w>=0.01\n",
        "    a = pd.DataFrame(BEST_PF[index].round(3),  columns=['%'] )\n",
        "    Portfolio_Weights = w[index].round(4)\n",
        "    Portfolio_Assets = BEST_PF[index]\n",
        "    Portfolio_Amounts = Portfolio_Weights*CURRENT_T2\n",
        "    a[f\"Amount in {CURRENT_T2} {currency}\"] = np.round(Portfolio_Amounts,2)\n",
        "    pf_stats = portfolio_stats(Optimal_weights_For_Highest_Sharpe_Ratio)\n",
        "    print(portfolio_stats(Optimal_weights_For_Highest_Sharpe_Ratio))\n",
        "    a.sort_values(by=['%'], ascending=[False], inplace = True)\n",
        "    print(a[f\"Amount in {CURRENT_T2} {currency}\"])\n",
        "    return a\n",
        "\n",
        "Final_TEFAS_PF = OptimizeWeights(Optimal_weights_for_Percent_Returns, stock_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5d1879c-3d72-40d8-8f8f-9094db847d56",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "c5d1879c-3d72-40d8-8f8f-9094db847d56"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a0b5d62-c4ca-4cc7-837e-f61ff202e2bb",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "8a0b5d62-c4ca-4cc7-837e-f61ff202e2bb"
      },
      "outputs": [],
      "source": [
        "#! pip install openpyxl\n",
        "import openpyxl\n",
        "\n",
        "Kurallar = pd.DataFrame()\n",
        "Kural_1 = \"Bu excelin size gönderildigi gün içerisinde saat en erken 17:00, en geç 17:50'de BIST'te alim talimatlarının verilmesi gerekmektedir.\"\n",
        "# Kural_2 = \"Mevcut portföyde 2 kere üstüste %9-10 tavan kapatmış hisse varsa ertesi gün açılışa tüm PF için satış yazılacaktır.\"\n",
        "# Kural_3 = \"Mevcut portföyde 2 kere üstüste -(%9-10) taban kapatmış hisse varsa ertesi gün açılışa tüm PF için satış yazılacaktır.\"\n",
        "Kural_2 = \"Mevcut Portfoyde herhangibir hissede %1.5 ve üzeri kar varsa + yeni portfoyde bu hisse yoksa, karin izlendigi hisseye en geç saat 11:00'de satış talimatı verilir \"\n",
        "Kural_3 = \"Mevcut portfoyde herhangibir hissede %1.5 ve üzeri kar varsa + Yeni portfoyde daha düşük miktarda ayni hisseden varsa, karin izlendigi hisseye fark adet kadar satış talimatı en geç saat 11:00'de verilir\"\n",
        "Kural_4 = \"Mevcut portfoyde herhangibir hissede %1.5 ve üzeri kar varsa + Yeni portfoyde daha yüksek miktarda ayni hisseden varsa, karin izlendigi hisseye fark adet kadar aliş talimatı en erken saat 17:00'de verilir\"\n",
        "Kural_5 = \"Mevcut portfoyde herhangibir hissede %1.5 in altinda kar/zarar varsa + PF karda degilse, hissede %1.5 gelen kadar beklenir, gelince sadece hisseye en geç saat 11:00'de satış talimatı verilir\"\n",
        "Kural_6 = \"Mevcut portfoyde herhangibir hissede %1.5 in altinda kar/zarar varsa + PF %1.5 karda ise, hissede %1.5 gelen kadar beklenmeksizin tüm PF'ye en geç saat 11:00'de satış talimatı verilir\"\n",
        "Kural_7 = \"Işbu dosya kullanıcıya özeldir, başka kişilerle paylaşılamaz.\"\n",
        "\n",
        "Kurallar= {'No':[1,2,3,4,5,6,7],'Kural':[Kural_1,Kural_2, Kural_3, Kural_4,Kural_5,Kural_6,Kural_7]}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59858a21-005e-4b8d-b4b5-0d2abd8a7526",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "59858a21-005e-4b8d-b4b5-0d2abd8a7526"
      },
      "outputs": [],
      "source": [
        "Kurallar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86f33a8e-c85b-478f-98b8-069a91951390",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "86f33a8e-c85b-478f-98b8-069a91951390"
      },
      "outputs": [],
      "source": [
        "#names = Final_TEFAS_PF.index\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b068c32-c81d-4acd-8d77-6ee989d8634c",
      "metadata": {
        "id": "7b068c32-c81d-4acd-8d77-6ee989d8634c"
      },
      "outputs": [],
      "source": [
        "# USDTRY CONVERSION\n",
        "# if 'TRY=X' not in names:\n",
        "#     names = AddToStockList(names, 'TRY=X')\n",
        "\n",
        "#names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c6d50b7-010d-416d-9b03-5549fe7070f6",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "5c6d50b7-010d-416d-9b03-5549fe7070f6"
      },
      "outputs": [],
      "source": [
        "pf_return = np.round(pf_stats['return'],2)\n",
        "pf_risk = pf_stats['risk']\n",
        "pf_sharpe = np.round(pf_stats['sharpe'],2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8176647-b673-4e34-8644-73da73a1a582",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "a8176647-b673-4e34-8644-73da73a1a582"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "Performance = pd.DataFrame()\n",
        "Performance = {'Performans':[\"Sharpe Oranı\",\"Standard Sapma\",\"Yıl Getiri %\", \"Hf Getiri %\"],\n",
        "               'Deger':[pf_sharpe,\n",
        "                        np.round(pf_risk/np.sqrt(252),4),\n",
        "                        np.round(pf_return*100,4),\n",
        "                        np.round(pf_return/252*100*5,4)]} # returns within lookbakc period ] }\n",
        "Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c3a62c0-4da6-4415-a792-0c244050f214",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "1c3a62c0-4da6-4415-a792-0c244050f214"
      },
      "outputs": [],
      "source": [
        "filename_statement = f\"{exchange}_v{version}_HI{P_BOUND_HI*100}_LO{P_BOUND_LO*100}_BK{BACKTEST_PERIOD}D-FW{FW_TEST_PERIOD}D-SH{pf_sharpe}-ON{T1_START}\"\n",
        "\n",
        "filename = filename_statement + \".xlsx\"\n",
        "#os.chdir(out)\n",
        "\n",
        "with pd.ExcelWriter(filename) as writer:  # doctest: +SKIP\n",
        "    Final_TEFAS_PF.to_excel(writer, sheet_name = 'Portföy')\n",
        "    df = pd.DataFrame(Kurallar)\n",
        "    df.to_excel(writer, sheet_name='Kurallar')\n",
        "    df = pd.DataFrame(Performance)\n",
        "    df.to_excel(writer, sheet_name='Performans')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ec0d28c-fcf6-4173-ad66-f64304f959b5",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "3ec0d28c-fcf6-4173-ad66-f64304f959b5"
      },
      "outputs": [],
      "source": [
        "Final_TEFAS_PF['sharpe']=np.round(pf_sharpe, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afbf946f-4263-4a3f-96b6-b19398502bca",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "afbf946f-4263-4a3f-96b6-b19398502bca"
      },
      "outputs": [],
      "source": [
        "Final_TEFAS_PF['Std Dev %']=pf_risk/np.sqrt(252)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fb9aeba-0a18-437a-a186-1f01bfca60d9",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "7fb9aeba-0a18-437a-a186-1f01bfca60d9"
      },
      "outputs": [],
      "source": [
        "\n",
        "Final_TEFAS_PF['Yearly Return %'] = np.round(pf_stats['return']*100,4)\n",
        "Final_TEFAS_PF['Weekly Return %'] = np.round(Final_TEFAS_PF['Yearly Return %'] / 52, 4)\n",
        "#Final_TEFAS_PF['Max Drawdown %'] = np.round((1.0-OrderedTable['PF_Value']/OrderedTable['PF_Value'].cummax()).max(),4)\n",
        "Final_TEFAS_PF.to_csv(filename_statement+\".csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0958f01a-d97f-4439-9c94-d1fd2d893ec0",
      "metadata": {
        "id": "0958f01a-d97f-4439-9c94-d1fd2d893ec0"
      },
      "source": [
        "Email service provider\tSMTP address\tSMTP port\n",
        "Gmail\tsmtp.gmail.com\t587\n",
        "Outlook\tsmtp-mail.outlook.com\t587\n",
        "yahoo\tsmtp.mail.yahoo.com\t587\n",
        "Office365\tsmtp.office365.com\t587\n",
        "AWS SES\temail-smtp.region-1.amazonaws.com\t587"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0dfeae3-0a2c-4243-8de5-394f951dc465",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "e0dfeae3-0a2c-4243-8de5-394f951dc465"
      },
      "outputs": [],
      "source": [
        "print(Final_TEFAS_PF.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c59b0c3-eb03-4bff-9947-0dc718e8c4dc",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "2c59b0c3-eb03-4bff-9947-0dc718e8c4dc"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=015 : PORTFOLIO_GENERATOR_NO_REBALANCE\n",
        "--------------------------------------------\n",
        "- DOWNLOADS selected assets and order them inside `Ordered` dataframe\n",
        "- GETS Initl=ial prices\n",
        "- SETS PF Weights Manually\n",
        "- CALCULATES Amount of each asset = UPdate_Captial * Weights\n",
        "- CALCULATES chares of each asset\n",
        "- CALCULATES PF Value by dot product operation of shares and prices\n",
        "- CALCULATE Residue cash that we cannot buy any shares\n",
        "- ADDS Residue cash to the PF\n",
        "\n",
        "'''\n",
        "\n",
        "Residue_Cash = CURRENT_T2\n",
        "#os.chdir(wd)\n",
        "OrderedTable = pd.DataFrame()\n",
        "df = pd.DataFrame()\n",
        "names = Final_TEFAS_PF.index\n",
        "filename = f\"{names[0]}.csv\"\n",
        "df = pd.read_csv(filename) #change 1\n",
        "#df = pd.read_csv(filename, index_col='Date', parse_dates=True, keep_date_col = True, infer_datetime_format=True, dayfirst=True, decimal=\",\")\n",
        "\n",
        "OrderedTable[\"Date\"] = df.iloc[:,0] #change 3\n",
        "\n",
        "# init_weight = np.round(1/len(names),5)\n",
        "# Portfolio_Weights = [ init_weight for i in range(len(names))]\n",
        "\n",
        "Portfolio_Weights = Final_TEFAS_PF['%']/100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3161b1bc-7889-4aaf-8eca-b3b9aee84e29",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "3161b1bc-7889-4aaf-8eca-b3b9aee84e29"
      },
      "outputs": [],
      "source": [
        "Portfolio_Weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b35e334e-b581-4a04-8551-a9fa1f920012",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "b35e334e-b581-4a04-8551-a9fa1f920012"
      },
      "outputs": [],
      "source": [
        "# names = AddTRYXToStockList(names)\n",
        "\n",
        "for tick in names:\n",
        "    print(f\"Fetching {tick}\")\n",
        "    filename = f\"{tick}.csv\"\n",
        "    df = pd.read_csv(filename)\n",
        "    #df = pd.read_csv(filename, index_col='Date', parse_dates=True, keep_date_col = True, infer_datetime_format=True, dayfirst=True, decimal=\",\") #change 2\n",
        "    OrderedTable[f\"{tick}\"] = df['Close']  # get each ETFs column write inside OrderedTable\n",
        "\n",
        "OrderedTable.dropna(inplace=True)\n",
        "\n",
        "OrderedTable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd508de6-494f-4957-898c-23e17aea6173",
      "metadata": {
        "id": "bd508de6-494f-4957-898c-23e17aea6173"
      },
      "outputs": [],
      "source": [
        "# USDTRY CONVERSION\n",
        "# if 'TRY=X' in OrderedTable.columns:\n",
        "#     for i in OrderedTable.columns:\n",
        "#         if i != 'GC=F' and i != 'CL=F' and i != 'Date':\n",
        "#             OrderedTable[i] = pd.Series(OrderedTable[i] / OrderedTable['TRY=X'])\n",
        "\n",
        "OrderedTable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "886c83a3-3d61-46a8-9d77-ce287b05e421",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "886c83a3-3d61-46a8-9d77-ce287b05e421"
      },
      "outputs": [],
      "source": [
        "TodaysPrices = OrderedTable.iloc[-1,0:]\n",
        "PurchasePrices = TodaysPrices\n",
        "print(f\"\\n Final prices: \\n{TodaysPrices} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69891979-a13b-457f-8ec3-031e66ec77dd",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "69891979-a13b-457f-8ec3-031e66ec77dd"
      },
      "outputs": [],
      "source": [
        "InitialPrices = OrderedTable.iloc[0,1:]\n",
        "#InitialPrices = OrderedTable.iloc[-23,1:]\n",
        "\n",
        "print(f\"\\n Initial prices: \\n{InitialPrices} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e04140c-6fbf-4b97-824b-dfa66d80548f",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "7e04140c-6fbf-4b97-824b-dfa66d80548f"
      },
      "outputs": [],
      "source": [
        "OrderedTable.tail(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f11671ac-c9f9-416a-8202-f4c6622ecd3f",
      "metadata": {
        "id": "f11671ac-c9f9-416a-8202-f4c6622ecd3f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bc114d5-e478-4b76-b7aa-a961600ee192",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "8bc114d5-e478-4b76-b7aa-a961600ee192"
      },
      "outputs": [],
      "source": [
        "Update_Capital = Residue_Cash # add the cash not used for stocks\n",
        "\n",
        "Portfolio_Amounts = np.multiply(Update_Capital, Portfolio_Weights )\n",
        "print(f\" Portfolio amounts: \\n{Portfolio_Amounts} \\n\")\n",
        "\n",
        "\n",
        "Final_TEFAS_PF\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3c8d679-ebd7-4438-ad60-b0dd4295f783",
      "metadata": {
        "id": "a3c8d679-ebd7-4438-ad60-b0dd4295f783"
      },
      "outputs": [],
      "source": [
        "display(Final_TEFAS_PF)\n",
        "#Final_TEFAS_PF = Final_TEFAS_PF.append({ index: 'TRY=X', '%':0, 'Amount in 100000 TL':0, 'sharpe':0 , 'Std Dev %':0 , 'Yearly Return %':0 , 'Weekly Return %':0}, ignore_index=True)\n",
        "#Final_TEFAS_PF.loc[len(Final_TEFAS_PF.index)] = ['TRY=X',\"0\",\"0\",\"0\",\"0\",\"0\",\"0\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec6a9868-687b-4df4-96c7-865168c5606e",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "ec6a9868-687b-4df4-96c7-865168c5606e"
      },
      "outputs": [],
      "source": [
        "Portfolio_Shares = np.trunc((Portfolio_Amounts / InitialPrices)) # determine shares\n",
        "print(f\" Portfolio shares: \\n{Portfolio_Shares} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a30392df-ff8d-43a8-a3ea-f9a831b7d707",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "a30392df-ff8d-43a8-a3ea-f9a831b7d707"
      },
      "outputs": [],
      "source": [
        "Prices = OrderedTable.iloc[:,1:]\n",
        "Prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69558e59-c5c1-4210-ba43-c9f93d355799",
      "metadata": {
        "id": "69558e59-c5c1-4210-ba43-c9f93d355799"
      },
      "outputs": [],
      "source": [
        "FirstPrices = OrderedTable.iloc[0,0:len(names)]\n",
        "FirstPrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd44c754-589d-4c27-acbf-732f3c64ec21",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "fd44c754-589d-4c27-acbf-732f3c64ec21"
      },
      "outputs": [],
      "source": [
        "OrderedTable['PF_Value'] = np.dot(Portfolio_Shares, Prices.T)  # PF_VALUE = dot product of shares and their prices !!!!\n",
        "OrderedTable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b44eebb6-35ad-4d8f-9dbe-9bce1ffefc57",
      "metadata": {
        "id": "b44eebb6-35ad-4d8f-9dbe-9bce1ffefc57"
      },
      "outputs": [],
      "source": [
        "\n",
        "# OrderedTable = ConvertTimeSeriesToUSD(OrderedTable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e693aa1-7aea-4192-8c41-7b4e3c85587e",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "1e693aa1-7aea-4192-8c41-7b4e3c85587e"
      },
      "outputs": [],
      "source": [
        "Residue_Cash = Update_Capital - OrderedTable.PF_Value.iloc[0] # !!!\n",
        "print(f\" Residue cash: {Residue_Cash} \\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e528065d-66b5-4b24-9d18-d9b833c223ca",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "e528065d-66b5-4b24-9d18-d9b833c223ca"
      },
      "outputs": [],
      "source": [
        "OrderedTable['PF_Value'] += Residue_Cash\n",
        "\n",
        "Update_Capital = OrderedTable.PF_Value.iloc[-1] # Update_Captial =  value of the PF at the end of every quarter\n",
        "\n",
        "print(f\" Portfolio capital at the end of period: {Update_Capital} \\n\")\n",
        "print(\" Ordered Table: \\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "740bfad4-1288-4e3c-bb92-bf4738efaa79",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "740bfad4-1288-4e3c-bb92-bf4738efaa79"
      },
      "outputs": [],
      "source": [
        "OrderedTable['pct_change'] = OrderedTable['PF_Value'].pct_change()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8bd1e1c-7832-4ef4-8255-01ec5a8b4a4a",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "b8bd1e1c-7832-4ef4-8255-01ec5a8b4a4a"
      },
      "outputs": [],
      "source": [
        "OrderedTable['pct_change'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c907a56e-da34-470d-9649-4ac0b1e35f13",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "c907a56e-da34-470d-9649-4ac0b1e35f13"
      },
      "outputs": [],
      "source": [
        "OrderedTable.set_index(\"Date\", inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3d1869b-f3b5-4027-a07f-56376341fb3f",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "c3d1869b-f3b5-4027-a07f-56376341fb3f"
      },
      "outputs": [],
      "source": [
        "OrderedTable.index= pd.to_datetime(OrderedTable.index)  # PYFOLIO nun düzgün çalışması icin bu gerekli"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "139e80dc-8dcd-4633-8992-f7625d59c53e",
      "metadata": {
        "tags": [],
        "id": "139e80dc-8dcd-4633-8992-f7625d59c53e"
      },
      "source": [
        "### Present Backtesting Performance <a name=\"Backtest_perf\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "769506a6-3241-4355-afab-bd32d00609e9",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "769506a6-3241-4355-afab-bd32d00609e9"
      },
      "outputs": [],
      "source": [
        "# !pip install pyfolio\n",
        "import pyfolio\n",
        "print(f\"********* PORTFOLIO TEARSHEET *************** \")\n",
        "\n",
        "try:\n",
        "    returns_tear_sheet = pyfolio.create_returns_tear_sheet(OrderedTable['pct_change'].dropna(),return_fig=True)\n",
        "except Exception as e:\n",
        "    print(\"Error generating returns tear sheet:\", e)\n",
        "    returns_tear_sheet = None\n",
        "\n",
        "print(\"********* end of TEARSHEET **************\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40b900b5-d043-4499-a295-744ad29cf043",
      "metadata": {
        "id": "40b900b5-d043-4499-a295-744ad29cf043"
      },
      "source": [
        "CHATGPT: Write python script to create an html file that can visualize all output data created by pyfolio.create_returns_tear_sheet(OrderedTable['pct_change'].dropna()) command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6123e600-45fd-42b4-a608-38df4a33d8e1",
      "metadata": {
        "id": "6123e600-45fd-42b4-a608-38df4a33d8e1"
      },
      "outputs": [],
      "source": [
        "returns_tear_sheet.savefig(\"Fig_006_Ret_Tear_sheet.jpg\", format='jpg', dpi=300)\n",
        "\n",
        "from IPython.display import Image\n",
        "Image(url=\"Fig_006_Ret_Tear_sheet.jpg\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e20111c1-df97-4f1c-b56b-2cd332582141",
      "metadata": {
        "id": "e20111c1-df97-4f1c-b56b-2cd332582141"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ae0eab8-bbe4-4b6f-82ad-6284e675c8ff",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "7ae0eab8-bbe4-4b6f-82ad-6284e675c8ff"
      },
      "outputs": [],
      "source": [
        "L = len(OrderedTable['PF_Value'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "377263f3-f58a-4027-825f-3fedab91f3c8",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "377263f3-f58a-4027-825f-3fedab91f3c8"
      },
      "outputs": [],
      "source": [
        "L\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beb10212-9c9e-44ce-8ddb-a97de3cd4364",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "beb10212-9c9e-44ce-8ddb-a97de3cd4364"
      },
      "outputs": [],
      "source": [
        "MaxDrawdown=(1.0-OrderedTable['PF_Value']/OrderedTable['PF_Value'].cummax()).max()\n",
        "MaxDrawdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69932a37-6fa0-44f6-b70d-99401bdf9674",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "69932a37-6fa0-44f6-b70d-99401bdf9674"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "\n",
        "PLOTTED =  names\n",
        "\n",
        "(OrderedTable[PLOTTED] / OrderedTable[PLOTTED].iloc[0]).plot(figsize = (16,10))\n",
        "plt.xlabel('Gün')\n",
        "plt.ylabel('Fiyat')\n",
        "plt.grid(True)\n",
        "plt.title(f\"Markov Markowitz portföy hisselerinin {BACKTEST_PERIOD} günlük backtest performansı\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47af23b3-9591-47aa-b9f9-a618f8840b57",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "47af23b3-9591-47aa-b9f9-a618f8840b57"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.title(f'Ideal Markov Markowitz Portföyünün son {look_back} günü')\n",
        "plt.xlabel('Tarih')\n",
        "plt.ylabel('Fiyat')\n",
        "(OrderedTable['PF_Value'] / OrderedTable['PF_Value'].iloc[0]).plot(figsize = (16,10))\n",
        "plt.savefig('PF_grafik')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0de3e696-a7cb-4e3f-80f5-8d7e2cfcfdd1",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "0de3e696-a7cb-4e3f-80f5-8d7e2cfcfdd1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.heatmap(OrderedTable.corr(),linecolor='white',linewidths=1,annot=True)\n",
        "plt.title(\"Portföyün Korelasyon Haritası\")\n",
        "plt.show()\n",
        "plt.savefig(\"korelasyon.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f9fdc88-6fa7-41fd-8a99-16aa9ed4b872",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "0f9fdc88-6fa7-41fd-8a99-16aa9ed4b872"
      },
      "outputs": [],
      "source": [
        "MaxDrawdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80cb2432-3fd7-4862-82ae-0c210a28cc00",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "80cb2432-3fd7-4862-82ae-0c210a28cc00"
      },
      "outputs": [],
      "source": [
        "Portfolio_Weights * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50a51ce9-021e-4138-88af-20db3e47548d",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "50a51ce9-021e-4138-88af-20db3e47548d"
      },
      "outputs": [],
      "source": [
        "Portfolio_Weights*CURRENT_T2\n",
        "Ideal_PF_Weights = Portfolio_Weights\n",
        "Ideal_PF_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34b3a7d8",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "34b3a7d8"
      },
      "outputs": [],
      "source": [
        "### Download Data for Forward Testing Performance <a name=\"download_fwtest\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b25b06f4-3c6b-43d1-82bf-fd867cc8e0c1",
      "metadata": {
        "id": "b25b06f4-3c6b-43d1-82bf-fd867cc8e0c1"
      },
      "outputs": [],
      "source": [
        "names\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4aa2fe0-34eb-44b2-ad87-fa6e967e42b9",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "b4aa2fe0-34eb-44b2-ad87-fa6e967e42b9"
      },
      "outputs": [],
      "source": [
        "# NOW DOWNLOAD START FROM today-look_back, FOR FW TESTING UNTIL TODAY\n",
        "\n",
        "'''\n",
        "UTILITY U=020 : DOWNLOAD_ASSETS_&_WRITE_DF_FOR_FW_TESTING\n",
        "--------------------------------------------\n",
        "- CHANGES WORKING DIRECTORY\n",
        "- SET FLAG TO NEW_DOWNLOAD\n",
        "- GETS DATA FOR ALL ASSETS IN stock_list FROM YAHOO FINANCE\n",
        "- WRITES DATA IN df and price_list\n",
        "- WRITES DATA IN CSV FILES\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "# T1_START = date.today() - timedelta( days = 30)\n",
        "# T1_END   = date.today() - timedelta( days = 1)\n",
        "\n",
        "\n",
        "\n",
        "LENGTH = 64\n",
        "#os.chdir(wd)\n",
        "\n",
        "new_download = True\n",
        "\n",
        "price_list = []\n",
        "if FW_TEST_PERIOD > FW_TEST_LIMIT :\n",
        "    if new_download:\n",
        "        print(LENGTH*\"*\")\n",
        "        print(\"Starting Download ...\")\n",
        "        print(LENGTH*\"*\")\n",
        "        for tick in names:\n",
        "            try:   # added 2/07/22\n",
        "                print(f\"Downloading {tick}\")\n",
        "                yf_tick = yf.Ticker(tick)\n",
        "                df = yf_tick.history(interval='1d', auto_adjust=True, start=T1_START, end=T1_END, back_adjust = True, rounding=True)\n",
        "                df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "                df.dropna(how='all', inplace=True)\n",
        "                price_list.append(df)\n",
        "            except Exception as e:    # added 2/07/22\n",
        "                print(e, tick)        # added 2/07/22\n",
        "        print(LENGTH*\"*\")\n",
        "        print(LENGTH*\"*\")\n",
        "        if \"GC=F\" in names: # added 3/07/22\n",
        "            tick = \"TRY=X\"\n",
        "            try:   # added 3/07/22\n",
        "                print(f\"Downloading {tick}\")\n",
        "                yf_tick = yf.Ticker(tick)\n",
        "                df = yf_tick.history(interval='1d', auto_adjust=True, start=T1_START, end=T1_END, back_adjust = True, rounding=True)\n",
        "                df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "                df.dropna(how='all', inplace=True)\n",
        "            except Exception as e:    # added 3/07/22\n",
        "                print(e, tick)        # added 3/07/22\n",
        "\n",
        "    ## Save datafiles to disk\n",
        "\n",
        "        for i,dframe in enumerate(price_list):\n",
        "            dframe.to_csv(f\"{names[i]}.csv\")\n",
        "        if \"GC=F\" in names: # added 3/07/22\n",
        "            df.to_csv(\"TRY=X.csv\")\n",
        "\n",
        "    #\n",
        "    # UTILITY U=021 : FETCH_ASSETS_FROM_CSV_FILES_&_WRITE_DF\n",
        "    # --------------------------------------------\n",
        "    # - CHANGES WORKING DIRECTORY\n",
        "    # - SET FLAG TO NEW_DOWNLOAD\n",
        "    # - GETS DATA FOR ALL ASSETS IN stock_list FROM CSV FILES\n",
        "    # - PUTS DATA in df\n",
        "    #\n",
        "\n",
        "    else:\n",
        "        price = {}\n",
        "        print(LENGTH*\"*\")\n",
        "        print(\"Fetching Downloaded CSV Files ...\")\n",
        "        print(LENGTH*\"*\")\n",
        "        for tick in names:\n",
        "            print(f\"Fetching {tick}\")\n",
        "            filename = f\"{tick}.csv\"\n",
        "            df = pd.read_csv(filename)\n",
        "            price[tick] = df\n",
        "        print(LENGTH*\"*\")\n",
        "        #print('Done ...Time elapsed (hh:mm:ss.ms) {}'.format(datetime.now() - start_time))\n",
        "        print(LENGTH*\"*\")\n",
        "\n",
        "else:\n",
        "    print(\"FW TEST NOT PERFORMED\")\n",
        "len(names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe9f85c0-a389-4258-8daf-1dcff811c4ab",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "fe9f85c0-a389-4258-8daf-1dcff811c4ab"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=001 : CSV_MERGER_FOR_FW_TESTING\n",
        "--------------------------------------------\n",
        "- READS desired assets from csv files\n",
        "- APPENDS the 'close' columns required in a single df name `li`\n",
        "- DROPS NA rows\n",
        "'''\n",
        "Portfolio_Assets = names\n",
        "\n",
        "li = pd.DataFrame() # my real portfolio dataframe\n",
        "\n",
        "rets = pd.DataFrame()\n",
        "\n",
        "names = []\n",
        "\n",
        "count = len(Portfolio_Assets)\n",
        "import os\n",
        "#os.chdir(wd)\n",
        "#for file in sorted2.Stock:\n",
        "if FW_TEST_PERIOD > FW_TEST_LIMIT:\n",
        "    for file in Portfolio_Assets:\n",
        "        df = pd.read_csv(f\"{file}.csv\", index_col='Date', parse_dates=True, infer_datetime_format=True)\n",
        "        li = pd.concat([li,df['Close']],axis=1, ignore_index=False)\n",
        "        st_name = file.split('.',maxsplit = 1)\n",
        "        names.append(st_name[0])\n",
        "\n",
        "    li.columns = names\n",
        "    li = li.dropna()\n",
        "\n",
        "    if \"GC=F\" in Portfolio_Assets: # added 3/07/22\n",
        "        df = pd.read_csv(\"TRY=X.csv\", index_col='Date', parse_dates=True, infer_datetime_format=True)\n",
        "        li[\"GC=F\"] = ConvertOunceToGram( df[\"Close\"].astype(float), li[\"GC=F\"].astype(float))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbbc4adb-596f-443f-8930-8b4e126fddad",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "fbbc4adb-596f-443f-8930-8b4e126fddad"
      },
      "outputs": [],
      "source": [
        "Portfolio_Assets\n",
        "Best_Assets =  Portfolio_Assets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45fa7299-6155-428f-979f-c8aca3df6dfe",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "45fa7299-6155-428f-979f-c8aca3df6dfe"
      },
      "outputs": [],
      "source": [
        "Portfolio_Assets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9529c98-cafb-465b-83ff-d6fc5495dc33",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "d9529c98-cafb-465b-83ff-d6fc5495dc33"
      },
      "outputs": [],
      "source": [
        "if FW_TEST_PERIOD > FW_TEST_LIMIT:\n",
        "    Final_TEFAS_PF.index = names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f6a2f15-708c-4266-9a22-8ae79ac9dc8c",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "1f6a2f15-708c-4266-9a22-8ae79ac9dc8c"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=003 : SET_DRX-AI_PORTFOLIO_PROPERTIES_FOR_FORWARD_TESTING\n",
        "-------------------------------------------------------------------\n",
        "- SETS desired assets names\n",
        "- SETS number of shares for each asset\n",
        "- SETS extra cash value\n",
        "- PRINTS these as a table\n",
        "'''\n",
        "if FW_TEST_PERIOD > FW_TEST_LIMIT:\n",
        "    import pandas as pd\n",
        "    Portfolio_Assets = Final_TEFAS_PF.index\n",
        "    import math\n",
        "    #Portfolio_Shares = int(Final_TEFAS_PF[f\"Amount in {CURRENT_T2} {currency}\"] / li.iloc[0,0:])\n",
        "    Portfolio_Shares = np.trunc(Final_TEFAS_PF[f\"Amount in {CURRENT_T2} {currency}\"] / li.iloc[0,0:])\n",
        "\n",
        "    #print(f\"\\n Initial prices: \\n{InitialPrices} \\n\")\n",
        "    Portfolio_Shares\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7691cd8b-4b89-4ee3-9ca9-332a86bc2273",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "7691cd8b-4b89-4ee3-9ca9-332a86bc2273"
      },
      "outputs": [],
      "source": [
        "#Final_TEFAS_PF['Amount in 100000 TL']\n",
        "#1/li.iloc[0,0:]\n",
        "#Portfolio_Shares = np.multiply(Final_TEFAS_PF['Amount in 100000 TL'], 1/li.iloc[0,0:])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e614d58-3386-4be6-9985-c06b9c377728",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "7e614d58-3386-4be6-9985-c06b9c377728"
      },
      "outputs": [],
      "source": [
        "if FW_TEST_PERIOD > FW_TEST_LIMIT:\n",
        "    Cash_Plus_MFs = 0# cash + fon + temettü\n",
        "    Current_PF = pd.Series(Portfolio_Shares, Portfolio_Assets)\n",
        "    print(Current_PF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6604687e-083f-434c-937a-77daff5ac06d",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "6604687e-083f-434c-937a-77daff5ac06d"
      },
      "outputs": [],
      "source": [
        "Portfolio_Shares\n",
        "Best_Shares = Portfolio_Shares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0379ad7a-ab16-41da-8e40-42bf2eee75a0",
      "metadata": {
        "id": "0379ad7a-ab16-41da-8e40-42bf2eee75a0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c40ef0d-c4bb-4c26-bafc-51db849a5ef2",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "8c40ef0d-c4bb-4c26-bafc-51db849a5ef2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faec05ac-101f-4772-a223-5be5a8a059c1",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "faec05ac-101f-4772-a223-5be5a8a059c1"
      },
      "outputs": [],
      "source": [
        "# GENERATE YAHOO PORTFOLIO COMPATIBLE IMPORTABLE CSV FILE\n",
        "#read_PF=pd.DataFrame(pd.read_csv('YF_PROTOTYPE.csv')) # read a prototype\n",
        "read_PF=pd.DataFrame(pd.read_csv('YF_PROTOTYPE_XU100.csv')) # read a prototype\n",
        "\n",
        "protoype_len = len(read_PF)\n",
        "\n",
        "read_PF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88eee88a-e012-4a61-b126-816bf93b1252",
      "metadata": {
        "id": "88eee88a-e012-4a61-b126-816bf93b1252"
      },
      "outputs": [],
      "source": [
        "best_len = len(Best_Assets)\n",
        "diff = best_len - protoype_len\n",
        "diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4897a8c2-222c-4248-8bc1-48015d83bb22",
      "metadata": {
        "id": "4897a8c2-222c-4248-8bc1-48015d83bb22"
      },
      "outputs": [],
      "source": [
        "np.round(Best_Shares,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28e2a9f0-7cc7-4423-acf1-90410527866e",
      "metadata": {
        "id": "28e2a9f0-7cc7-4423-acf1-90410527866e"
      },
      "outputs": [],
      "source": [
        "lastCloses = PurchasePrices\n",
        "len(lastCloses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60326962-8813-4afa-933d-6503d7648341",
      "metadata": {
        "id": "60326962-8813-4afa-933d-6503d7648341"
      },
      "outputs": [],
      "source": [
        "df_line = {}\n",
        "if diff>0:\n",
        "    for i in np.arange(0,diff):  # add number of rows = diff to prototype portfolio dataframe\n",
        "        read_PF = read_PF.append(df_line, ignore_index = True)\n",
        "elif diff<0:\n",
        "    while diff<0:\n",
        "        read_PF = read_PF.iloc[:-1 , :] # delete number of rows = diff from pr ototype portfolio dataframe\n",
        "        diff  +=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab439eda-ac35-42e1-8dbf-6aeaca751001",
      "metadata": {
        "id": "ab439eda-ac35-42e1-8dbf-6aeaca751001"
      },
      "outputs": [],
      "source": [
        "read_PF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2683abf-a514-4121-aaeb-28e5d4b36937",
      "metadata": {
        "id": "b2683abf-a514-4121-aaeb-28e5d4b36937"
      },
      "outputs": [],
      "source": [
        "lastCloses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e757c54-a8c8-425d-a04c-9fd79a68bad2",
      "metadata": {
        "id": "4e757c54-a8c8-425d-a04c-9fd79a68bad2"
      },
      "outputs": [],
      "source": [
        "FirstPrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "967a4247-c24f-40db-9d1d-eeff25343d79",
      "metadata": {
        "id": "967a4247-c24f-40db-9d1d-eeff25343d79"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "for ba in Best_Assets:\n",
        "    read_PF.Symbol[i] = ba\n",
        "    i=i+1\n",
        "i = 0\n",
        "for bs in Best_Shares:\n",
        "    read_PF.Quantity[i] = np.round(bs,0)\n",
        "    i=i+1\n",
        "\n",
        "# for i in np.arange(0,len(lastCloses)-1):\n",
        "#     #read_PF['Purchase Price'][i] = lastCloses[i+1]\n",
        "#     read_PF['Purchase Price'][i] = FirstPrices[i]\n",
        "#     i=i+1\n",
        "for i in np.arange(0,len(FirstPrices)-1):\n",
        "    read_PF['Purchase Price'][i] = FirstPrices[i+1]\n",
        "    i=i+1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "949ce670-e5c5-4ca4-875f-adc58559a50a",
      "metadata": {
        "id": "949ce670-e5c5-4ca4-875f-adc58559a50a"
      },
      "outputs": [],
      "source": [
        "i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b57f6a4-98d8-4eaa-9126-d3067dcf06ed",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "1b57f6a4-98d8-4eaa-9126-d3067dcf06ed"
      },
      "outputs": [],
      "source": [
        "read_PF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10c8ac1d-672a-4439-8486-24d20dbeb1a4",
      "metadata": {
        "id": "10c8ac1d-672a-4439-8486-24d20dbeb1a4"
      },
      "outputs": [],
      "source": [
        "if  exchange == \"BIST500\":\n",
        "    read_PF = read_PF.append({'Symbol':'XU100.IS', 'Quantity':0.00001, 'Purchase Price':'3000'}, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cb331a1-c2f2-4e77-823f-e8c6824a46bd",
      "metadata": {
        "id": "2cb331a1-c2f2-4e77-823f-e8c6824a46bd"
      },
      "outputs": [],
      "source": [
        "read_PF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c175d73c-99e2-4152-b676-e80aba15d2ea",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "c175d73c-99e2-4152-b676-e80aba15d2ea"
      },
      "outputs": [],
      "source": [
        "read_PF.to_csv(\"YF_IDEAL.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "920169ea-a44f-42a7-9e40-1adac32bc468",
      "metadata": {
        "tags": [],
        "id": "920169ea-a44f-42a7-9e40-1adac32bc468"
      },
      "source": [
        "### Present Forward Testing Performance <a name=\"present_fwtest\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47c688ef-b4f8-4ac6-acf0-dabb8361505b",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "47c688ef-b4f8-4ac6-acf0-dabb8361505b"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=002 : PORTFOLIO_CALCULATOR\n",
        "--------------------------------------------\n",
        "- READS column of individual assets\n",
        "- CALCULATES the portfolio value as `li[Portfolio]` appended to df `li`\n",
        "- CALCULATES daily log returns for every column of li and writes to `rets`\n",
        "- CALCULATES daily PF Index and writes to `li[Portfolio_Index] and normal daily returns and writes to `li[PF_Returns]`\n",
        "- PRINTS the tear sheet of varios statistics\n",
        "'''\n",
        "import matplotlib.pyplot as plt\n",
        "import pyfolio as pf\n",
        "import numpy as np\n",
        "if FW_TEST_PERIOD > FW_TEST_LIMIT:\n",
        "    totals = []\n",
        "    ADD = 0\n",
        "    for i in np.arange(0,count):\n",
        "        ADD +=  li[f\"{names[i]}\"] * Portfolio_Shares[i]\n",
        "        totals.append(li[f\"{names[i]}\"] * Portfolio_Shares[i])\n",
        "\n",
        "    ADD += Cash_Plus_MFs # FONLARI EKLEDIK\n",
        "\n",
        "    #li = pd.concat([li, ADD], axis=1, ignore_index=False)\n",
        "    li['My Portfolio'] = ADD\n",
        "    print(f\"Stocks selected = {names}\")\n",
        "    print(f\"Number of stocks selected = {len(names)}\")\n",
        "\n",
        "    for file in li.columns:\n",
        "        a = np.log(li[f\"{file}\"] / (li[f\"{file}\"].shift(1)))\n",
        "        rets[f\"{file}\"]= a\n",
        "\n",
        "    print(\" My Portfolio\", li.round(2))\n",
        "\n",
        "    print(\" Returns\", rets.round(6))\n",
        "\n",
        "    plt.plot(li['My Portfolio'])\n",
        "\n",
        "    # li['Portfolio'] = ADD # cash added\n",
        "    li['Index'] = li['My Portfolio'] / li['My Portfolio'].iloc[0]\n",
        "    li['PF_Returns'] = ((li['My Portfolio']-li['My Portfolio'].shift(1)) / li['My Portfolio'].shift(1)).fillna(method=\"ffill\").round(6)\n",
        "    li.dropna()\n",
        "\n",
        "    print(f\"\\n======= PF Weights======================\")\n",
        "    print(Portfolio_Weights * 100)\n",
        "    print(f\"********* FW TESTING RESULTS *************** \")\n",
        "    print(f\"********* PORTFOLIO TEARSHEET *************** \")\n",
        "    #pf.create_simple_tear_sheet(li['PF_Returns'].dropna())\n",
        "    pf.create_returns_tear_sheet(li['PF_Returns'].dropna())\n",
        "    print(\"********* end of TEARSHEET **************\\n\")\n",
        "\n",
        "    pystats_df = pf.timeseries.perf_stats(li['PF_Returns'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e9675fc-e9f1-4f6b-9473-33656aa6766e",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "5e9675fc-e9f1-4f6b-9473-33656aa6766e"
      },
      "outputs": [],
      "source": [
        "if FW_TEST_PERIOD > FW_TEST_LIMIT:\n",
        "    TodaysPrices = li.iloc[-1,0:]\n",
        "    print(f\"\\n Todays prices: \\n{TodaysPrices} \\n\")\n",
        "\n",
        "#CURRENT_T2 = TodaysPrices['Portfolio']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8ca18f0-69d2-4ea7-8e98-85156957ebc3",
      "metadata": {
        "tags": [],
        "id": "d8ca18f0-69d2-4ea7-8e98-85156957ebc3"
      },
      "source": [
        "### My Own Manual Portfolio Performance <a name=\"my_own\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4ff2a44-bd3c-4b0b-ab77-b4c45c3a7864",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "b4ff2a44-bd3c-4b0b-ab77-b4c45c3a7864"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=003 : SET_CURRENT_PORTFOLIO_PROPERTIES of MY MANUAL PF\n",
        "-----------------------------------------------------------------\n",
        "- SETS desired assets names\n",
        "- SETS number of shares for each asset\n",
        "- SETS extra cash value\n",
        "- PRINTS these as a table\n",
        "'''\n",
        "\n",
        "import pandas as pd    #TI3 mimic as for 29 April 2022\n",
        "\n",
        "Portfolio_Assets = MyAssets\n",
        "\n",
        "Portfolio_Shares = MyShares\n",
        "\n",
        "Cash_Plus_MFs = 0 # cash + fon + temettü\n",
        "\n",
        "\n",
        "Current_PF = pd.Series(Portfolio_Shares, Portfolio_Assets)\n",
        "print(Current_PF)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a1fcd16-2bb7-4471-9262-9b7c3fdd84e1",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "2a1fcd16-2bb7-4471-9262-9b7c3fdd84e1"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=020 : DOWNLOAD_ASSETS_&_WRITE_DF_FOR_FW_TESTING FOR MY MANUAL PF\n",
        "--------------------------------------------\n",
        "- CHANGES WORKING DIRECTORY\n",
        "- SET FLAG TO NEW_DOWNLOAD\n",
        "- GETS DATA FOR ALL ASSETS IN stock_list FROM YAHOO FINANCE\n",
        "- WRITES DATA IN df and price_list\n",
        "- WRITES DATA IN CSV FILES\n",
        "\n",
        "'''\n",
        "\n",
        "LENGTH = 64\n",
        "#os.chdir(wd)\n",
        "\n",
        "new_download = True\n",
        "\n",
        "price_list = []\n",
        "\n",
        "if FW_TEST_PERIOD <= FW_TEST_LIMIT:\n",
        "    T1_START = T0_START\n",
        "    T1_END = T0_END\n",
        "\n",
        "if new_download:\n",
        "    print(LENGTH*\"*\")\n",
        "    print(\"Starting Download ...\")\n",
        "    print(LENGTH*\"*\")\n",
        "    for tick in Portfolio_Assets:\n",
        "        try:\n",
        "            print(f\"Downloading {tick}\")\n",
        "            yf_tick = yf.Ticker(tick)\n",
        "            df = yf_tick.history(interval='1d', auto_adjust=True, start=T1_START, end=T1_END, back_adjust = True, rounding=True)\n",
        "            df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "            df.dropna(how='all', inplace=True)\n",
        "            price_list.append(df)\n",
        "        except Exception as e:    # added 1/07/22\n",
        "            print(e, tick)        # added 1/07/22\n",
        "\n",
        "    print(LENGTH*\"*\")\n",
        "    if \"GC=F\" in Portfolio_Assets: # added 3/07/22\n",
        "        tick = \"TRY=X\"\n",
        "        try:\n",
        "            print(f\"Downloading {tick}\")\n",
        "            yf_tick = yf.Ticker(tick)\n",
        "            df = yf_tick.history(interval='1d', auto_adjust=True, start=T1_START, end=T1_END, back_adjust = True, rounding=True)\n",
        "            df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "            df.dropna(how='all', inplace=True)\n",
        "            price_list.append(df)\n",
        "        except Exception as e:    # added 1/07/22\n",
        "            print(e, tick)        # added 1/07/22\n",
        "    print(LENGTH*\"*\")\n",
        "    print(LENGTH*\"*\")\n",
        "\n",
        "## Save datafiles to disk\n",
        "\n",
        "    for i,df in enumerate(price_list):\n",
        "        df.to_csv(f\"{Portfolio_Assets[i]}.csv\")\n",
        "\n",
        "#\n",
        "# UTILITY U=021 : FETCH_ASSETS_FROM_CSV_FILES_&_WRITE_DF\n",
        "# --------------------------------------------\n",
        "# - CHANGES WORKING DIRECTORY\n",
        "# - SET FLAG TO NEW_DOWNLOAD\n",
        "# - GETS DATA FOR ALL ASSETS IN stock_list FROM CSV FILES\n",
        "# - PUTS DATA in df\n",
        "#\n",
        "\n",
        "else:\n",
        "    price = {}\n",
        "    print(LENGTH*\"*\")\n",
        "    print(\"Fetching Downloaded CSV Files ...\")\n",
        "    print(LENGTH*\"*\")\n",
        "    for tick in names:\n",
        "        print(f\"Fetching {tick}\")\n",
        "        filename = f\"{tick}.csv\"\n",
        "        df = pd.read_,csv(filename)\n",
        "        price[tick] = df\n",
        "    print(LENGTH*\"*\")\n",
        "    #print('Done ...Time elapsed (hh:mm:ss.ms) {}'.format(datetime.now() - start_time))\n",
        "    print(LENGTH*\"*\")\n",
        "\n",
        "len(Portfolio_Assets)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b4d3e9a-88cf-4716-9b1c-cfea59c5bb4b",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "9b4d3e9a-88cf-4716-9b1c-cfea59c5bb4b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1993a9e1-3d87-4bce-9655-bfca790088d9",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "1993a9e1-3d87-4bce-9655-bfca790088d9"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=001 : MY MANUAL PF CSV_MERGER_FOR_FW_TESTING\n",
        "--------------------------------------------\n",
        "- READS desired assets from csv files\n",
        "- APPENDS the 'close' columns required in a single df name `li`\n",
        "- DROPS NA rows\n",
        "'''\n",
        "# Portfolio_Assets = names\n",
        "\n",
        "# if FW_TEST_PERIOD !=0:\n",
        "mypf = pd.DataFrame() # my real portfolio dataframe\n",
        "\n",
        "rets = pd.DataFrame()\n",
        "\n",
        "names = []\n",
        "\n",
        "# if 'TRY=X' not in Portfolio_Assets:\n",
        "#     Portfolio_Assets = AddToStockList(Portfolio_Assets, 'TRY=X')\n",
        "\n",
        "count = len(Portfolio_Assets)\n",
        "import os\n",
        "#os.chdir(wd)\n",
        "#for file in sorted2.Stock:\n",
        "for file in Portfolio_Assets:\n",
        "    df = pd.read_csv(f\"{file}.csv\", index_col='Date', parse_dates=True, infer_datetime_format=True)\n",
        "    mypf = pd.concat([mypf,df['Close']],axis=1, ignore_index=False)\n",
        "    st_name = file.split('.',maxsplit = 1)\n",
        "    names.append(st_name[0])\n",
        "\n",
        "mypf.columns = names\n",
        "mypf = mypf.dropna(axis=0)\n",
        "\n",
        "\n",
        "\n",
        "# if 'TRY=X' in mypf.columns:\n",
        "#     for i in mypf.columns:\n",
        "#         if i != 'GC=F' and i != 'CL=F':\n",
        "#             mypf[i] = pd.Series(mypf[i] / mypf['TRY=X'])\n",
        "\n",
        "mypf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21cc0667-a7f0-4cbc-8078-1f9625756d65",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "21cc0667-a7f0-4cbc-8078-1f9625756d65"
      },
      "source": [
        "### Present My Own Portfolio Performance <a name=\"present_own\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "764c7541-7fff-493a-ac7e-341597c519d1",
      "metadata": {
        "id": "764c7541-7fff-493a-ac7e-341597c519d1"
      },
      "outputs": [],
      "source": [
        "mypf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e68d6df3-357e-4555-aa83-2465f314bc0a",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "e68d6df3-357e-4555-aa83-2465f314bc0a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4c65df2-25d4-4738-b261-877dac81a919",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "e4c65df2-25d4-4738-b261-877dac81a919"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=002 : MY MANUAL PORTFOLIO_CALCULATOR (li. ==> mypf.)\n",
        "--------------------------------------------\n",
        "- READS column of individual assets\n",
        "- CALCULATES the portfolio value as `li[Portfolio]` appended to df `li`\n",
        "- CALCULATES daily log returns for every column of li and writes to `rets`\n",
        "- CALCULATES daily PF Index and writes to `li[Portfolio_Index] and normal daily returns and writes to `li[PF_Returns]`\n",
        "- PRINTS the tear sheet of varios statistics\n",
        "'''\n",
        "import matplotlib.pyplot as plt\n",
        "import pyfolio as pf\n",
        "import numpy as np\n",
        "# if FW_TEST_PERIOD !=0:\n",
        "totals = []\n",
        "ADD = 0\n",
        "#for i in np.arange(0,count):\n",
        "for i in np.arange(0,len(mypf.columns)-1):\n",
        "    if names[i] == \"GC=F\":\n",
        "        ADD +=  mypf[f\"{names[i]}\"] * mypf[\"TRY=X\"] * Portfolio_Shares[i]\n",
        "    else:\n",
        "        ADD +=  mypf[f\"{names[i]}\"] * Portfolio_Shares[i]\n",
        "        totals.append(mypf[f\"{names[i]}\"] * Portfolio_Shares[i])\n",
        "\n",
        "ADD += Cash_Plus_MFs # FONLARI EKLEDIK\n",
        "ADD += 0# FONLARI EKLEDIK\n",
        "#li = pd.concat([li, ADD], axis=1, ignore_index=False)\n",
        "mypf['My Portfolio'] = ADD\n",
        "print(f\"Stocks selected = {names}\")\n",
        "print(f\"Number of stocks selected = {len(names)}\")\n",
        "\n",
        "# for file in li.columns:\n",
        "#     a = np.log(li[f\"{file}\"] / (li[f\"{file}\"].shift(1)))\n",
        "#     rets[f\"{file}\"]= a\n",
        "\n",
        "for file in mypf.columns:\n",
        "    a = np.log(mypf[f\"{file}\"] / (mypf[f\"{file}\"].shift(1)))\n",
        "    rets[f\"{file}\"]= a\n",
        "\n",
        "print(\" My Portfolio\", mypf.round(2).tail(60))\n",
        "\n",
        "print(\" Returns\", rets.round(5).tail(60))\n",
        "\n",
        "plt.plot(mypf['My Portfolio'])\n",
        "\n",
        "# li['Portfolio'] = ADD # cash added\n",
        "mypf['Index'] = mypf['My Portfolio'] / mypf['My Portfolio'].iloc[0]\n",
        "mypf['PF_Returns'] = ((mypf['My Portfolio']-mypf['My Portfolio'].shift(1)) / mypf['My Portfolio'].shift(1)).fillna(method=\"ffill\").round(6)\n",
        "\n",
        "print(f\"\\n======= PF Weights======================\")\n",
        "print(f\"********* PORTFOLIO TEARSHEET *************** \")\n",
        "#pf.create_returns_tear_sheet(mypf['PF_Returns'].dropna())\n",
        "pf.create_simple_tear_sheet(mypf['PF_Returns'].dropna())\n",
        "print(\"********* end of TEARSHEET **************\\n\")\n",
        "mypf.index = pd.DatetimeIndex(mypf.index)\n",
        "mypf['My Portfolio'].pct_change().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9e6b9e0-845e-4630-8198-1cfef7b5bccd",
      "metadata": {
        "id": "c9e6b9e0-845e-4630-8198-1cfef7b5bccd"
      },
      "outputs": [],
      "source": [
        "totals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65a38f51-7379-41ff-8e9d-66bbebc0ec84",
      "metadata": {
        "id": "65a38f51-7379-41ff-8e9d-66bbebc0ec84"
      },
      "outputs": [],
      "source": [
        "# TodaysPrices = mypf.iloc[-1,:-3]\n",
        "# PurchasePrices = mypf.iloc[0,:-3]\n",
        "# print(f\"\\n Purchase prices: \\n{PurchasePrices} \\n\")\n",
        "# print(f\"\\n Final prices: \\n{TodaysPrices} \\n\")\n",
        "# Best_Assets =  names\n",
        "# len(Best_Assets)\n",
        "# TOTALPFVAL = mypf.iloc[-1,-3]\n",
        "# Best_Shares = Portfolio_Shares\n",
        "# Portfolio_Weights = np.multiply(Best_Shares ,TodaysPrices) / TOTALPFVAL\n",
        "# Portfolio_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bf7ce9b-639a-49d2-8466-71e3ee06b162",
      "metadata": {
        "id": "3bf7ce9b-639a-49d2-8466-71e3ee06b162"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "082442e9-1173-406b-98d9-7bfe62837624",
      "metadata": {
        "id": "082442e9-1173-406b-98d9-7bfe62837624"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "893cefd0-c5c4-4d9a-9ec0-83fedc86c85f",
      "metadata": {
        "id": "893cefd0-c5c4-4d9a-9ec0-83fedc86c85f"
      },
      "outputs": [],
      "source": [
        "Portfolio_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd929e21-4e47-4a37-9d98-5a914f8b73a6",
      "metadata": {
        "id": "fd929e21-4e47-4a37-9d98-5a914f8b73a6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6605c5cf-c48d-4934-8533-8ba16da60bf5",
      "metadata": {
        "id": "6605c5cf-c48d-4934-8533-8ba16da60bf5"
      },
      "outputs": [],
      "source": [
        "len(Best_Shares)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26aee7f5-4345-4826-80b3-c81a5011889b",
      "metadata": {
        "id": "26aee7f5-4345-4826-80b3-c81a5011889b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d341fac6-3fb4-4545-bcac-94c1ec3a09c1",
      "metadata": {
        "id": "d341fac6-3fb4-4545-bcac-94c1ec3a09c1"
      },
      "outputs": [],
      "source": [
        "#mypf['My Portfolio'].pct_change().mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b760a17-29cd-4358-94bf-0879df9af0d8",
      "metadata": {
        "id": "5b760a17-29cd-4358-94bf-0879df9af0d8"
      },
      "outputs": [],
      "source": [
        "#result['day-of-week'] = result.index.weekday()\n",
        "#        result = result.loc[result['day-of-week'] < 5]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2509ec6f-6438-449c-bc50-ca4fbaea3041",
      "metadata": {
        "tags": [],
        "id": "2509ec6f-6438-449c-bc50-ca4fbaea3041"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e57d4bc5-7b1a-49f5-bd26-769b326856fa",
      "metadata": {
        "id": "e57d4bc5-7b1a-49f5-bd26-769b326856fa"
      },
      "outputs": [],
      "source": [
        "Ideal_PF_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3295377-dcf1-4d18-af93-fec6d75f1642",
      "metadata": {
        "id": "b3295377-dcf1-4d18-af93-fec6d75f1642"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de2b5ac4-a0ce-4440-ac51-76da289ffc5a",
      "metadata": {
        "id": "de2b5ac4-a0ce-4440-ac51-76da289ffc5a"
      },
      "outputs": [],
      "source": [
        "Ideal_PF_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d253264-b49e-43eb-a243-e3bb88105b6e",
      "metadata": {
        "id": "0d253264-b49e-43eb-a243-e3bb88105b6e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18e1a838-0b4a-4e8e-b6d0-0c191bf769a4",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "18e1a838-0b4a-4e8e-b6d0-0c191bf769a4"
      },
      "outputs": [],
      "source": [
        "# !pip install xlsxwriter\n",
        "# import xlsxwriter\n",
        "\n",
        "# workbook = xlsxwriter.Workbook('ShoppingList.xlsx')\n",
        "# worksheet = workbook.add_worksheet()\n",
        "\n",
        "# row = 0\n",
        "# col = 0\n",
        "\n",
        "# for key in SHOPPING_LIST.keys():\n",
        "#     row += 1\n",
        "#     worksheet.write(row, col, key)\n",
        "#     for item in SHOPPING_LIST.items():\n",
        "#         worksheet.write(row, col, item)\n",
        "#         row += 1\n",
        "\n",
        "# workbook.close()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9810ccd-e156-4eaf-a47b-eaea75bf7d23",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "f9810ccd-e156-4eaf-a47b-eaea75bf7d23"
      },
      "outputs": [],
      "source": [
        "# ShoppingList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c44bebee-d1c4-4545-b979-67acc0413d8f",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "c44bebee-d1c4-4545-b979-67acc0413d8f"
      },
      "outputs": [],
      "source": [
        "# from PIL import Image\n",
        "\n",
        "# file_in = \"PF_grafik.png\"\n",
        "# img = Image.open(file_in)\n",
        "# file_out = 'test1.bmp'\n",
        "# print(len(img.split())) # test\n",
        "# if len(img.split()) == 4:\n",
        "#     # prevent IOError: cannot write mode RGBA as BMP\n",
        "#     r, g, b, a = img.split()\n",
        "#     img = Image.merge(\"RGB\", (r, g, b))\n",
        "#     img.save(file_out)\n",
        "# else:\n",
        "#     img.save(file_out)\n",
        "\n",
        "# !pip install xlwt\n",
        "# from xlwt import Workbook\n",
        "# w = Workbook()\n",
        "# ws = w.add_sheet('Grafikler')\n",
        "# ws.insert_bitmap(file_out, 0, 0)\n",
        "# w.save(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10e52dc2-d119-4cea-b1d2-aa16846ad952",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "10e52dc2-d119-4cea-b1d2-aa16846ad952"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22c2cc0c",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "22c2cc0c"
      },
      "outputs": [],
      "source": [
        "### Plot Sector Graph for Ideal PF <a name=\"sector_graph\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32c34d8c-3251-4a52-af9e-3bba24f06ee3",
      "metadata": {
        "pycharm": {
          "is_executing": true
        },
        "id": "32c34d8c-3251-4a52-af9e-3bba24f06ee3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "    #plt.tight_layout()\n",
        "plot_sector_counts(Portfolio_Weights*100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7234a423-38ce-4e85-89c0-954da50ef0d4",
      "metadata": {
        "tags": [],
        "id": "7234a423-38ce-4e85-89c0-954da50ef0d4"
      },
      "source": [
        "### Write Ideal PF to Yahoo Portfolio Compatible CSV file <a name=\"yahoo_pf\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "763a81ff-6e24-4ba2-8908-38e594c55089",
      "metadata": {
        "id": "763a81ff-6e24-4ba2-8908-38e594c55089"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(70*'-')\n",
        "print(70*'-')\n",
        "print(70*'-')\n",
        "print(70*'-')\n",
        "#input(\"Any key to continue\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0daef23e-e964-4844-a9d4-c4dbc9a2b533",
      "metadata": {
        "id": "0daef23e-e964-4844-a9d4-c4dbc9a2b533"
      },
      "source": [
        "### Read PF From yahoo Portfolio again to calculate Last-Day-Weights of Selected PF <a name=\"Update_weights\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "117a7e01-8088-47c9-9f92-971fc8a2a157",
      "metadata": {
        "id": "117a7e01-8088-47c9-9f92-971fc8a2a157"
      },
      "outputs": [],
      "source": [
        "TodaysPrices = mypf.iloc[-1,:-3]\n",
        "PurchasePrices = mypf.iloc[0,:-3]\n",
        "TOTALPFVAL = mypf.iloc[-1,-3]\n",
        "print(f\"\\n Purchase prices: \\n{PurchasePrices} \\n\")\n",
        "print(f\"\\n Final prices: \\n{TodaysPrices} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7964033c-94a7-4ac2-81c5-7d151888cbfd",
      "metadata": {
        "id": "7964033c-94a7-4ac2-81c5-7d151888cbfd"
      },
      "outputs": [],
      "source": [
        "Best_Assets =  Portfolio_Assets\n",
        "Best_Shares = Portfolio_Shares\n",
        "\n",
        "Portfolio_Weights = np.multiply(Best_Shares, TodaysPrices) / TOTALPFVAL\n",
        "Portfolio_Weights.index += '.IS'\n",
        "plot_sector_counts(Portfolio_Weights*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52882df9-1f38-48e2-8f94-8a2814c0bbba",
      "metadata": {
        "id": "52882df9-1f38-48e2-8f94-8a2814c0bbba"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e9e02c9-a688-4f69-9498-91b8420b9b03",
      "metadata": {
        "id": "3e9e02c9-a688-4f69-9498-91b8420b9b03"
      },
      "outputs": [],
      "source": [
        "read_PF=pd.DataFrame(pd.read_csv('YF_PROTOTYPE_XU100.csv')) # read a prototype\n",
        "\n",
        "protoype_len = len(read_PF)\n",
        "\n",
        "protoype_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cb1336a-396f-40d6-ac26-16ff60362964",
      "metadata": {
        "id": "7cb1336a-396f-40d6-ac26-16ff60362964"
      },
      "outputs": [],
      "source": [
        "best_len = len(PurchasePrices)\n",
        "diff = best_len - protoype_len\n",
        "diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e00bb6a2-68df-46a2-ba3b-0f4b47a1a5e3",
      "metadata": {
        "id": "e00bb6a2-68df-46a2-ba3b-0f4b47a1a5e3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39da3e3b-964b-4807-ab7c-6ec5cfbfdfdf",
      "metadata": {
        "id": "39da3e3b-964b-4807-ab7c-6ec5cfbfdfdf"
      },
      "outputs": [],
      "source": [
        "df_line = {}\n",
        "if diff>0:\n",
        "    for i in np.arange(0,diff):  # add number of rows = diff to prototype portfolio dataframe\n",
        "        read_PF = read_PF.append(df_line, ignore_index = True)\n",
        "elif diff<0:\n",
        "    while diff<0:\n",
        "        read_PF = read_PF.iloc[:-1 , :] # delete number of rows = diff from pr ototype portfolio dataframe\n",
        "        diff  +=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82e47ae7-0057-4e51-b6d9-c61489e7cf81",
      "metadata": {
        "id": "82e47ae7-0057-4e51-b6d9-c61489e7cf81"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "for ba in Portfolio_Weights.index:\n",
        "    read_PF.Symbol[i] = ba\n",
        "    i=i+1\n",
        "i = 0\n",
        "for bs in Best_Shares:\n",
        "    read_PF.Quantity[i] = np.round(bs,0)\n",
        "    i=i+1\n",
        "\n",
        "for i in np.arange(0,len(PurchasePrices)-1):\n",
        "    read_PF['Purchase Price'][i] = PurchasePrices[i+1]\n",
        "    i=i+1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a59a105-713f-4c37-8be2-4543abfda6bb",
      "metadata": {
        "id": "6a59a105-713f-4c37-8be2-4543abfda6bb"
      },
      "outputs": [],
      "source": [
        "read_PF = read_PF.append({'Symbol':'XU100.IS', 'Quantity':0.00001, 'Purchase Price':'3000'}, ignore_index=True)\n",
        "read_PF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e784fb4d-7b73-4275-bc1b-3691b11a5cfc",
      "metadata": {
        "id": "e784fb4d-7b73-4275-bc1b-3691b11a5cfc"
      },
      "outputs": [],
      "source": [
        "read_PF.to_csv(\"YF_MYPF.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bcb79cc-23c2-4ae6-880a-73e0843da62d",
      "metadata": {
        "id": "4bcb79cc-23c2-4ae6-880a-73e0843da62d"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(70*'-')\n",
        "print(70*'-')\n",
        "print(70*'-')\n",
        "print(70*'-')\n",
        "#input(\"Any key to continue\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6fd07ed-0607-4b17-9f30-68d9cf26863b",
      "metadata": {
        "id": "b6fd07ed-0607-4b17-9f30-68d9cf26863b"
      },
      "outputs": [],
      "source": [
        "#PF = pd.DataFrame(pd.read_csv(f\"EXPORT_{exchange}_MPT_v520D_BK100D-FW200D-SH17.86-ST2022-01-04.csv\"))\n",
        "os.chdir(root)\n",
        "PF = pd.DataFrame(pd.read_csv(\"IDEAL.csv\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7704440c-ac54-47e5-b032-1d259bdc395d",
      "metadata": {
        "id": "7704440c-ac54-47e5-b032-1d259bdc395d"
      },
      "outputs": [],
      "source": [
        "PF['Purchased Value'] = PF['Purchase Price'] * PF['Quantity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57434c00-30ed-4617-8770-7cfe82ac2fa8",
      "metadata": {
        "id": "57434c00-30ed-4617-8770-7cfe82ac2fa8"
      },
      "outputs": [],
      "source": [
        "PF['Market Value'] = PF['Current Price'] * PF['Quantity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d991e937-d138-4b67-9771-03afe191c61b",
      "metadata": {
        "id": "d991e937-d138-4b67-9771-03afe191c61b"
      },
      "outputs": [],
      "source": [
        "PF['PnL %'] = (PF['Market Value'] - PF['Purchased Value']) / PF['Purchased Value'] *100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b318db1-8a99-4e2f-8767-142ae2f68392",
      "metadata": {
        "id": "5b318db1-8a99-4e2f-8767-142ae2f68392"
      },
      "outputs": [],
      "source": [
        "PF.index = PF.Symbol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91969a51-10f0-4419-8876-dbc3b543fd98",
      "metadata": {
        "id": "91969a51-10f0-4419-8876-dbc3b543fd98"
      },
      "outputs": [],
      "source": [
        "PF['Start PF %'] = np.round((PF['Purchased Value'] / PF['Purchased Value'].sum()) *100, 5)\n",
        "PF['End PF %'] = np.round((PF['Market Value'] / PF['Market Value'].sum()) *100, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3e0f4aa-a40f-4ae6-992f-9d4fc2255191",
      "metadata": {
        "id": "a3e0f4aa-a40f-4ae6-992f-9d4fc2255191"
      },
      "outputs": [],
      "source": [
        "PF.sort_values( by=[\"Start PF %\"], ascending=[False], inplace = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb07e538-aa19-40ab-94ab-b208bc9f13e1",
      "metadata": {
        "id": "fb07e538-aa19-40ab-94ab-b208bc9f13e1"
      },
      "outputs": [],
      "source": [
        "IDEALPF = PF[['Quantity','Purchase Price','Purchased Value','Current Price','Market Value',  'Start PF %', 'End PF %', 'PnL %']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d8aff42-3dba-4c74-aa6d-ba1e946cfb67",
      "metadata": {
        "id": "3d8aff42-3dba-4c74-aa6d-ba1e946cfb67"
      },
      "outputs": [],
      "source": [
        "IDEALPF['Market Value'].sum()\n",
        "CURRENT_T2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36e5acec-e2fd-401f-b160-225df3c539ea",
      "metadata": {
        "id": "36e5acec-e2fd-401f-b160-225df3c539ea"
      },
      "outputs": [],
      "source": [
        "PV = IDEALPF['Purchased Value'].sum()\n",
        "FV = IDEALPF['Market Value'].sum()\n",
        "\n",
        "IDEALPF['Purchase Amount'] = np.trunc(IDEALPF['End PF %']*CURRENT_T2/100)\n",
        "IDEALPF['End Quantity'] = np.trunc(IDEALPF['Purchase Amount'] / IDEALPF['Current Price'])\n",
        "IDEALPF\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "825d15e6-70f3-4012-b376-f8ab6ebbff7c",
      "metadata": {
        "id": "825d15e6-70f3-4012-b376-f8ab6ebbff7c"
      },
      "outputs": [],
      "source": [
        "plot_sector_counts(IDEALPF['End PF %'].dropna())\n",
        "\n",
        "print(f\"Start PF value = {PV:.2f}\")\n",
        "print(f\"Total PF value = {FV:.2f}\")\n",
        "print(f\"Total Revenue =  {FV-PV:.2f}\")\n",
        "print(f\"Total Revenue =  %{(FV-PV)/PV*100:.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f96bab42-c066-404e-ad5d-bacd3458dd82",
      "metadata": {
        "id": "f96bab42-c066-404e-ad5d-bacd3458dd82"
      },
      "outputs": [],
      "source": [
        "IDEALPF[['Current Price','End PF %','Purchase Amount','End Quantity']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd5b42b5-0e1a-4575-bad3-fc071758d21d",
      "metadata": {
        "id": "dd5b42b5-0e1a-4575-bad3-fc071758d21d"
      },
      "outputs": [],
      "source": [
        "TOTAL_PURCHASED = IDEALPF['Purchase Amount'].sum()\n",
        "print(f\"TO BE PURCHASED =  {TOTAL_PURCHASED:.2f} TL\")\n",
        "print(f\"CASH REMAINING =  {CURRENT_T2 - TOTAL_PURCHASED:.2f} TL\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9491662-c3c1-417b-8d37-734d4e7433b5",
      "metadata": {
        "id": "b9491662-c3c1-417b-8d37-734d4e7433b5"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=003 : SET_CURRENT_PORTFOLIO_PROPERTIES of MY MANUAL PF\n",
        "-----------------------------------------------------------------\n",
        "- SETS desired assets names\n",
        "- SETS number of shares for each asset\n",
        "- SETS extra cash value\n",
        "- PRINTS these as a table\n",
        "'''\n",
        "\n",
        "import pandas as pd    #TI3 mimic as for 29 April 2022\n",
        "\n",
        "\n",
        "Portfolio_Assets = IDEALPF.index\n",
        "Portfolio_Shares = IDEALPF['Quantity']\n",
        "Cash_Plus_MFs = 0 # cash + fon + temettü\n",
        "\n",
        "Current_PF = pd.Series(Portfolio_Shares, Portfolio_Assets)\n",
        "print(Current_PF)\n",
        "print('Number of stocks =',len(Current_PF))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ab02165-ee74-446d-9138-96ea41ac4ada",
      "metadata": {
        "id": "7ab02165-ee74-446d-9138-96ea41ac4ada"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=020 : DOWNLOAD_ASSETS_&_WRITE_DF_FOR_FW_TESTING FOR MY MANUAL PF\n",
        "--------------------------------------------\n",
        "- CHANGES WORKING DIRECTORY\n",
        "- SET FLAG TO NEW_DOWNLOAD\n",
        "- GETS DATA FOR ALL ASSETS IN stock_list FROM YAHOO FINANCE\n",
        "- WRITES DATA IN df and price_list\n",
        "- WRITES DATA IN CSV FILES\n",
        "\n",
        "'''\n",
        "\n",
        "LENGTH = 64\n",
        "#os.chdir(wd)\n",
        "\n",
        "new_download = True\n",
        "\n",
        "price_list = []\n",
        "if FW_TEST_PERIOD > FW_TEST_LIMIT:\n",
        "    if new_download:\n",
        "        print(LENGTH*\"*\")\n",
        "        print(\"Starting Download ...\")\n",
        "        print(LENGTH*\"*\")\n",
        "        for tick in Portfolio_Assets:\n",
        "            try:\n",
        "                print(f\"Downloading {tick}\")\n",
        "                yf_tick = yf.Ticker(tick)\n",
        "                df = yf_tick.history(interval='1d', auto_adjust=True, start=T1_START, end=T1_END, back_adjust = True, rounding=True)\n",
        "                df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "                df.dropna(how='all', inplace=True)\n",
        "                price_list.append(df)\n",
        "            except Exception as e:    # added 1/07/22\n",
        "                print(e, tick)        # added 1/07/22\n",
        "\n",
        "        print(LENGTH*\"*\")\n",
        "        if \"GC=F\" in Portfolio_Assets: # added 3/07/22\n",
        "            tick = \"TRY=X\"\n",
        "            try:\n",
        "                print(f\"Downloading {tick}\")\n",
        "                yf_tick = yf.Ticker(tick)\n",
        "                df = yf_tick.history(interval='1d', auto_adjust=True, start=T1_START, end=T1_END, back_adjust = True, rounding=True)\n",
        "                df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "                df.dropna(how='all', inplace=True)\n",
        "                price_list.append(df)\n",
        "            except Exception as e:    # added 1/07/22\n",
        "                print(e, tick)        # added 1/07/22\n",
        "        print(LENGTH*\"*\")\n",
        "        print(LENGTH*\"*\")\n",
        "\n",
        "    ## Save datafiles to disk\n",
        "\n",
        "        for i,df in enumerate(price_list):\n",
        "            df.to_csv(f\"{Portfolio_Assets[i]}.csv\")\n",
        "\n",
        "    #\n",
        "    # UTILITY U=021 : FETCH_ASSETS_FROM_CSV_FILES_&_WRITE_DF\n",
        "    # --------------------------------------------\n",
        "    # - CHANGES WORKING DIRECTORY\n",
        "    # - SET FLAG TO NEW_DOWNLOAD\n",
        "    # - GETS DATA FOR ALL ASSETS IN stock_list FROM CSV FILES\n",
        "    # - PUTS DATA in df\n",
        "    #\n",
        "else:\n",
        "    if new_download:\n",
        "        print(LENGTH*\"*\")\n",
        "        print(\"Starting Download ...\")\n",
        "        print(LENGTH*\"*\")\n",
        "        for tick in Portfolio_Assets:\n",
        "            try:\n",
        "                print(f\"Downloading {tick}\")\n",
        "                yf_tick = yf.Ticker(tick)\n",
        "                df = yf_tick.history(interval='1d', auto_adjust=True, start=T0_START, end=T0_END, back_adjust = True, rounding=True)\n",
        "                df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "                df.dropna(how='all', inplace=True)\n",
        "                price_list.append(df)\n",
        "            except Exception as e:    # added 1/07/22\n",
        "                print(e, tick)        # added 1/07/22\n",
        "\n",
        "        print(LENGTH*\"*\")\n",
        "        if \"GC=F\" in Portfolio_Assets: # added 3/07/22\n",
        "            tick = \"TRY=X\"\n",
        "            try:\n",
        "                print(f\"Downloading {tick}\")\n",
        "                yf_tick = yf.Ticker(tick)\n",
        "                df = yf_tick.history(interval='1d', auto_adjust=True, start=T0_START, end=T0_END, back_adjust = True, rounding=True)\n",
        "                df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "                df.dropna(how='all', inplace=True)\n",
        "                price_list.append(df)\n",
        "            except Exception as e:    # added 1/07/22\n",
        "                print(e, tick)        # added 1/07/22\n",
        "        print(LENGTH*\"*\")\n",
        "        print(LENGTH*\"*\")\n",
        "\n",
        "    ## Save datafiles to disk\n",
        "\n",
        "        for i,df in enumerate(price_list):\n",
        "            df.to_csv(f\"{Portfolio_Assets[i]}.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb30926b-72be-4f2f-bdeb-94de33e6e930",
      "metadata": {
        "id": "bb30926b-72be-4f2f-bdeb-94de33e6e930"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=001 : MY MANUAL PF CSV_MERGER_FOR_FW_TESTING\n",
        "--------------------------------------------\n",
        "- READS desired assets from csv files\n",
        "- APPENDS the 'close' columns required in a single df name `li`\n",
        "- DROPS NA rows\n",
        "'''\n",
        "# Portfolio_Assets = names\n",
        "\n",
        "mypf = pd.DataFrame() # my real portfolio dataframe\n",
        "\n",
        "rets = pd.DataFrame()\n",
        "\n",
        "names = []\n",
        "\n",
        "count = len(Portfolio_Assets)\n",
        "import os\n",
        "#os.chdir(wd)\n",
        "#for file in sorted2.Stock:\n",
        "for file in Portfolio_Assets:\n",
        "    df = pd.read_csv(f\"{file}.csv\", index_col='Date', parse_dates=True, infer_datetime_format=True)\n",
        "    mypf = pd.concat([mypf,df['Close']],axis=1, ignore_index=False)\n",
        "    st_name = file.split('.',maxsplit = 1)\n",
        "    names.append(st_name[0])\n",
        "\n",
        "mypf.columns = names\n",
        "#mypf = mypf.dropna(inplace=True)\n",
        "mypf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a894cb0d-890b-470c-b1d3-06095e1da7a4",
      "metadata": {
        "id": "a894cb0d-890b-470c-b1d3-06095e1da7a4"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=002 : MY MANUAL PORTFOLIO_CALCULATOR (li. ==> mypf.)\n",
        "--------------------------------------------\n",
        "- READS column of individual assets\n",
        "- CALCULATES the portfolio value as `li[Portfolio]` appended to df `li`\n",
        "- CALCULATES daily log returns for every column of li and writes to `rets`\n",
        "- CALCULATES daily PF Index and writes to `li[Portfolio_Index] and normal daily returns and writes to `li[PF_Returns]`\n",
        "- PRINTS the tear sheet of varios statistics\n",
        "'''\n",
        "import matplotlib.pyplot as plt\n",
        "import pyfolio as pf\n",
        "import numpy as np\n",
        "\n",
        "totals = []\n",
        "ADD = 0\n",
        "for i in np.arange(0,count):\n",
        "    if names[i] == \"GC=F\":\n",
        "        ADD +=  mypf[f\"{names[i]}\"] * mypf[\"TRY=X\"] * Portfolio_Shares[i]\n",
        "    else:\n",
        "        ADD +=  mypf[f\"{names[i]}\"] * Portfolio_Shares[i]\n",
        "        totals.append(mypf[f\"{names[i]}\"] * Portfolio_Shares[i])\n",
        "\n",
        "ADD += Cash_Plus_MFs # FONLARI EKLEDIK\n",
        "#li = pd.concat([li, ADD], axis=1, ignore_index=False)\n",
        "mypf['My Portfolio'] = ADD\n",
        "print(f\"Stocks selected = {names}\")\n",
        "print(f\"Number of stocks selected = {len(names)}\")\n",
        "\n",
        "\n",
        "\n",
        "# for file in li.columns:\n",
        "#     a = np.log(li[f\"{file}\"] / (li[f\"{file}\"].shift(1)))\n",
        "#     rets[f\"{file}\"]= a\n",
        "\n",
        "for file in mypf.columns:\n",
        "    a = np.log(mypf[f\"{file}\"] / (mypf[f\"{file}\"].shift(1)))\n",
        "    rets[f\"{file}\"]= a\n",
        "\n",
        "print(\" My Portfolio\", mypf.round(2).tail(60))\n",
        "\n",
        "print(\" Returns\", rets.round(5).tail(60))\n",
        "\n",
        "plt.plot(mypf['My Portfolio'])\n",
        "\n",
        "# li['Portfolio'] = ADD # cash added\n",
        "mypf['Index'] = mypf['My Portfolio'] / mypf['My Portfolio'].iloc[0]\n",
        "mypf['PF_Returns'] = ((mypf['My Portfolio']-mypf['My Portfolio'].shift(1)) / mypf['My Portfolio'].shift(1)).fillna(method=\"ffill\").round(6)\n",
        "\n",
        "\n",
        "print(f\"\\n======= PF Weights======================\")\n",
        "print(f\"********* PORTFOLIO TEARSHEET *************** \")\n",
        "pf.create_simple_tear_sheet(mypf['PF_Returns'].dropna())\n",
        "#pf.create_returns_tear_sheet(mypf['PF_Returns'].dropna())\n",
        "print(\"********* end of TEARSHEET **************\\n\")\n",
        "mypf.index = pd.DatetimeIndex(mypf.index)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "108ce71c-16ee-4a6e-900b-127eb363fe9d",
      "metadata": {
        "id": "108ce71c-16ee-4a6e-900b-127eb363fe9d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eb2960c-3732-4748-bc79-cddd0a5aa597",
      "metadata": {
        "id": "4eb2960c-3732-4748-bc79-cddd0a5aa597"
      },
      "outputs": [],
      "source": [
        "mypf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9786219-1ce0-4de2-a3b2-55ee77357c13",
      "metadata": {
        "id": "d9786219-1ce0-4de2-a3b2-55ee77357c13"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "50ba96bb-fef2-48de-9ceb-7013592cc5bc",
      "metadata": {
        "id": "50ba96bb-fef2-48de-9ceb-7013592cc5bc"
      },
      "source": [
        "## Portföy Alpha ve Beta Parametrelerinin Hesabı <a name=\"alpha_beta\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fe5eb2d-5c17-4c04-b453-6906121649fb",
      "metadata": {
        "id": "1fe5eb2d-5c17-4c04-b453-6906121649fb"
      },
      "source": [
        "$$\n",
        "    Stock\\ returns_i = \\alpha + \\beta * Market\\ returns_i\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c626799-ff5e-4250-b49d-2a6989997667",
      "metadata": {
        "id": "6c626799-ff5e-4250-b49d-2a6989997667"
      },
      "source": [
        "## Reference\n",
        "[Beta Calculations](https://financetrain.com/calculating-beta-using-market-model-regression-slope/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8639e7f6-fedb-4847-9403-8647b7a176b3",
      "metadata": {
        "id": "8639e7f6-fedb-4847-9403-8647b7a176b3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "from data import get_stock_data\n",
        "\n",
        "start_date = T1_START\n",
        "end_date = T1_END\n",
        "\n",
        "data = pd.DataFrame()\n",
        "data['XU100'] = mypf.XU100\n",
        "data['PORTFOLIO'] = mypf['My Portfolio']\n",
        "\n",
        "data\n",
        "\n",
        "data_pc = data.pct_change().dropna()*100\n",
        "data_pc.columns = ([\"%XU100\", \"%PF\"])\n",
        "data_pc.tail(30)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(data_pc[\"%XU100\"], data_pc[\"%PF\"],color='b')\n",
        "plt.ylabel(\"%PF\")\n",
        "plt.xlabel(\"%XU100\")\n",
        "plt.show()\n",
        "import statsmodels.api as sm\n",
        "model = sm.OLS( data_pc[\"%PF\"], data_pc[\"%XU100\"])\n",
        "line = model.fit()\n",
        "beta = line.params[0]\n",
        "print(\"BETA =\", line.params)\n",
        "#print(line.t_test([1]))\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(data_pc['%XU100'], data_pc['%PF'],color='b')\n",
        "x = data_pc['%XU100']\n",
        "y = data_pc['%PF']\n",
        "plt.plot(x, beta*x, color='r')\n",
        "plt.ylabel('%PF')\n",
        "plt.xlabel('%XU100')\n",
        "plt.show()\n",
        "m_x = x.mean()\n",
        "m_y = y.mean()\n",
        "s_x = x.std()\n",
        "s_y = y.std()\n",
        "\n",
        "Mean = pd.DataFrame([m_x,m_y])\n",
        "StDev = pd.DataFrame([s_x,s_y])\n",
        "\n",
        "# print(Mean.T)\n",
        "# print(StDev.T)\n",
        "\n",
        "# Zscore calc\n",
        "# z_x = (x - m_x) / s_x\n",
        "# print(z_x)\n",
        "# z_y = (y - m_y) / s_y\n",
        "# print(z_y)\n",
        "\n",
        "Z = pd.DataFrame([x,y])\n",
        "print(Z)\n",
        "\n",
        "r_xy = data_pc.corr()\n",
        "\n",
        "r_xy\n",
        "r_xy.iloc[1,0]\n",
        "#beta = r_xy.iloc[1,0] * s_y / s_x\n",
        "alpha = m_y - beta * m_x\n",
        "\n",
        "IDEALPF['Alpha'] = alpha\n",
        "IDEALPF['Beta'] = beta"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "209cf1e6-8e87-49b2-ac4c-3315e1fda99e",
      "metadata": {
        "id": "209cf1e6-8e87-49b2-ac4c-3315e1fda99e"
      },
      "source": [
        "### Index ve Portföyümüzün Risk ve Maksimum Çöküş Değerlerinin Hesaplanması <a name=\"vol_mdd\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ce86fc2-1138-4017-90a6-3b6bd502daf0",
      "metadata": {
        "id": "8ce86fc2-1138-4017-90a6-3b6bd502daf0"
      },
      "outputs": [],
      "source": [
        "# Calculate rolling standard deviation of SPY and Tesla\n",
        "# data['volatility XU100'] = data['XU100'].pct_change().rolling(10).std()\n",
        "# data['volatility PF']    = data['PORTFOLIO'].pct_change().rolling(10).std()\n",
        "# data['PF Index'] = data['PORTFOLIO'] * 0.00000016\n",
        "\n",
        "# data['PnL'] = data['PF Index'].diff()\n",
        "\n",
        "# data = data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7bb52c4-efbd-4004-a839-63330ed75473",
      "metadata": {
        "id": "e7bb52c4-efbd-4004-a839-63330ed75473"
      },
      "outputs": [],
      "source": [
        "# Plot Volatility of SPY and Tesla\n",
        "# data[['volatility XU100', 'volatility PF']].plot(figsize=(15, 15))\n",
        "\n",
        "# # Set the title and axes labels\n",
        "# plt.title('Volatility', fontsize=14)\n",
        "# plt.xlabel('Date', fontsize=12)\n",
        "# plt.ylabel('Standard Deviation of Returns', fontsize=12)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db739b39-5278-45af-9c02-ce6a8b614336",
      "metadata": {
        "id": "db739b39-5278-45af-9c02-ce6a8b614336"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b5116d-52e5-4d69-916f-666830ed25b1",
      "metadata": {
        "id": "83b5116d-52e5-4d69-916f-666830ed25b1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ae99d89-ebe0-43a2-a616-3fd356d0d7c7",
      "metadata": {
        "id": "6ae99d89-ebe0-43a2-a616-3fd356d0d7c7"
      },
      "outputs": [],
      "source": [
        "def calc_drawdown(price):\n",
        "\n",
        "    # Calculate the running maximum\n",
        "    running_max = np.maximum.accumulate(price.dropna())\n",
        "\n",
        "    # Ensure the value never drops below 1\n",
        "    running_max[running_max < 1] = 1\n",
        "\n",
        "    # Calculate the drawdown\n",
        "    drawdown = (price)/running_max - 1\n",
        "    return drawdown\n",
        "\n",
        "\n",
        "def plot_drawdown(drawdown, graph_title):\n",
        "\n",
        "    # Plot drawdown\n",
        "    plt.figure(figsize=(15, 7))\n",
        "    drawdown.plot(color='r')\n",
        "    plt.ylabel('Drawdown', fontsize=12)\n",
        "    plt.xlabel('Year-Month', fontsize=12)\n",
        "    plt.title(graph_title, fontsize=14)\n",
        "    plt.fill_between(drawdown.index, drawdown.values, color='red')\n",
        "    plt.grid(which=\"major\", color='k', linestyle='-.', linewidth=0.2)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c821912d-290b-4ee8-9644-2f29381764f6",
      "metadata": {
        "id": "c821912d-290b-4ee8-9644-2f29381764f6"
      },
      "outputs": [],
      "source": [
        "\n",
        "# drawdown_spy = calc_drawdown(data['XU100'])\n",
        "\n",
        "# # Calculate maximum drawdown of SPY\n",
        "# max_dd_spy = drawdown_spy.min()*100\n",
        "# print(\"The maximum drawdown of XU100 is %.2f\" % max_dd_spy)\n",
        "\n",
        "# # Plot SPY drawdown\n",
        "# plot_drawdown(drawdown_spy, 'XU100 Drawdown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29b46516-a97e-4550-a2f2-1ba281b0e071",
      "metadata": {
        "id": "29b46516-a97e-4550-a2f2-1ba281b0e071"
      },
      "outputs": [],
      "source": [
        "\n",
        "# drawdown_tsla = calc_drawdown(data['PORTFOLIO'])\n",
        "\n",
        "# # Calculate maximum drawdown of Tesla\n",
        "# max_dd_tsla = drawdown_tsla.min()*100\n",
        "# print(\"The maximum drawdown of PF is %.2f\" % max_dd_tsla)\n",
        "\n",
        "# # Plot Tesla drawdown\n",
        "# plot_drawdown(drawdown_tsla, 'PF Drawdown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9098bac3-26d1-4119-a43d-ec4ab21dca62",
      "metadata": {
        "id": "9098bac3-26d1-4119-a43d-ec4ab21dca62"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3f374db-1cdd-4325-bfc5-fe6233111f59",
      "metadata": {
        "tags": [],
        "id": "b3f374db-1cdd-4325-bfc5-fe6233111f59"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd42834c-9f93-4ea4-9fdc-5cc86d012dc0",
      "metadata": {
        "id": "cd42834c-9f93-4ea4-9fdc-5cc86d012dc0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1f2d2396-5562-493d-9b17-b96f20908c5b",
      "metadata": {
        "id": "1f2d2396-5562-493d-9b17-b96f20908c5b"
      },
      "source": [
        "### IDEAL.csv PORTFOLIO PERFORMANCE <a name=\"ideal_csv\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c0b6d47-0d16-4ab8-a333-fa23f8ef7f3c",
      "metadata": {
        "id": "5c0b6d47-0d16-4ab8-a333-fa23f8ef7f3c"
      },
      "outputs": [],
      "source": [
        "IDEALPF = IDEALPF.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0123a3d4-01a1-4040-9044-1f864ff54630",
      "metadata": {
        "id": "0123a3d4-01a1-4040-9044-1f864ff54630"
      },
      "outputs": [],
      "source": [
        "plot_sector_counts(IDEALPF['End PF %'].dropna())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a58ad98-b819-42d9-b26a-7ff243af9af0",
      "metadata": {
        "id": "9a58ad98-b819-42d9-b26a-7ff243af9af0"
      },
      "outputs": [],
      "source": [
        "Portfolio_Assets = IDEALPF.index\n",
        "Portfolio_Shares = IDEALPF.Quantity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3efc5504-963c-4d74-ad04-59ff0304ea6d",
      "metadata": {
        "id": "3efc5504-963c-4d74-ad04-59ff0304ea6d"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=020 : DOWNLOAD_ASSETS_&_WRITE_DF_FOR_FW_TESTING\n",
        "--------------------------------------------\n",
        "- CHANGES WORKING DIRECTORY\n",
        "- SET FLAG TO NEW_DOWNLOAD\n",
        "- GETS DATA FOR ALL ASSETS IN stock_list FROM YAHOO FINANCE\n",
        "- WRITES DATA IN df and price_list\n",
        "- WRITES DATA IN CSV FILES\n",
        "\n",
        "'''\n",
        "\n",
        "LENGTH = 64\n",
        "#os.chdir(wd)\n",
        "\n",
        "new_download = True\n",
        "\n",
        "price_list = []\n",
        "if FW_TEST_PERIOD > FW_TEST_LIMIT:\n",
        "    if new_download:\n",
        "        print(LENGTH*\"*\")\n",
        "        print(\"Starting Download ...\")\n",
        "        print(LENGTH*\"*\")\n",
        "        for tick in Portfolio_Assets:\n",
        "            try:\n",
        "                print(f\"Downloading {tick}\")\n",
        "                yf_tick = yf.Ticker(tick)\n",
        "                df = yf_tick.history(interval='1d', auto_adjust=True, start=T1_START, end=T1_END, back_adjust = True, rounding=True)\n",
        "                df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "                df.dropna(how='all', inplace=True)\n",
        "                price_list.append(df)\n",
        "            except Exception as e:    # added 1/07/22\n",
        "                print(e, tick)        # added 1/07/22\n",
        "\n",
        "        print(LENGTH*\"*\")\n",
        "        if \"GC=F\" in Portfolio_Assets: # added 3/07/22\n",
        "            tick = \"TRY=X\"\n",
        "            try:\n",
        "                print(f\"Downloading {tick}\")\n",
        "                yf_tick = yf.Ticker(tick)\n",
        "                df = yf_tick.history(interval='1d', auto_adjust=True, start=T1_START, end=T1_END, back_adjust = True, rounding=True)\n",
        "                df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "                df.dropna(how='all', inplace=True)\n",
        "                price_list.append(df)\n",
        "            except Exception as e:    # added 1/07/22\n",
        "                print(e, tick)        # added 1/07/22\n",
        "        print(LENGTH*\"*\")\n",
        "        print(LENGTH*\"*\")\n",
        "\n",
        "    ## Save datafiles to disk\n",
        "\n",
        "        for i,df in enumerate(price_list):\n",
        "            df.to_csv(f\"{Portfolio_Assets[i]}.csv\")\n",
        "\n",
        "    #\n",
        "    # UTILITY U=021 : FETCH_ASSETS_FROM_CSV_FILES_&_WRITE_DF\n",
        "    # --------------------------------------------\n",
        "    # - CHANGES WORKING DIRECTORY\n",
        "    # - SET FLAG TO NEW_DOWNLOAD\n",
        "    # - GETS DATA FOR ALL ASSETS IN stock_list FROM CSV FILES\n",
        "    # - PUTS DATA in df\n",
        "    #\n",
        "\n",
        "    else:\n",
        "        price = {}\n",
        "        print(LENGTH*\"*\")\n",
        "        print(\"Fetching Downloaded CSV Files ...\")\n",
        "        print(LENGTH*\"*\")\n",
        "        for tick in names:\n",
        "            print(f\"Fetching {tick}\")\n",
        "            filename = f\"{tick}.csv\"\n",
        "            df = pd.read_,csv(filename)\n",
        "            price[tick] = df\n",
        "        print(LENGTH*\"*\")\n",
        "        #print('Done ...Time elapsed (hh:mm:ss.ms) {}'.format(datetime.now() - start_time))\n",
        "        print(LENGTH*\"*\")\n",
        "\n",
        "    len(Portfolio_Assets)\n",
        "else :\n",
        "    if new_download:\n",
        "        print(LENGTH*\"*\")\n",
        "        print(\"Starting Download ...\")\n",
        "        print(LENGTH*\"*\")\n",
        "        for tick in Portfolio_Assets:\n",
        "            try:\n",
        "                print(f\"Downloading {tick}\")\n",
        "                yf_tick = yf.Ticker(tick)\n",
        "                df = yf_tick.history(interval='1d', auto_adjust=True, start=T0_START, end=T0_END, back_adjust = True, rounding=True)\n",
        "                df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "                df.dropna(how='all', inplace=True)\n",
        "                price_list.append(df)\n",
        "            except Exception as e:    # added 1/07/22\n",
        "                print(e, tick)        # added 1/07/22\n",
        "\n",
        "        print(LENGTH*\"*\")\n",
        "        if \"GC=F\" in Portfolio_Assets: # added 3/07/22\n",
        "            tick = \"TRY=X\"\n",
        "            try:\n",
        "                print(f\"Downloading {tick}\")\n",
        "                yf_tick = yf.Ticker(tick)\n",
        "                df = yf_tick.history(interval='1d', auto_adjust=True, start=T0_START, end=T0_END, back_adjust = True, rounding=True)\n",
        "                df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "                df.dropna(how='all', inplace=True)\n",
        "                price_list.append(df)\n",
        "            except Exception as e:    # added 1/07/22\n",
        "                print(e, tick)        # added 1/07/22\n",
        "        print(LENGTH*\"*\")\n",
        "        print(LENGTH*\"*\")\n",
        "\n",
        "    ## Save datafiles to disk\n",
        "\n",
        "        for i,df in enumerate(price_list):\n",
        "            df.to_csv(f\"{Portfolio_Assets[i]}.csv\")\n",
        "\n",
        "    #\n",
        "    # UTILITY U=021 : FETCH_ASSETS_FROM_CSV_FILES_&_WRITE_DF\n",
        "    # --------------------------------------------\n",
        "    # - CHANGES WORKING DIRECTORY\n",
        "    # - SET FLAG TO NEW_DOWNLOAD\n",
        "    # - GETS DATA FOR ALL ASSETS IN stock_list FROM CSV FILES\n",
        "    # - PUTS DATA in df\n",
        "    #\n",
        "\n",
        "    else:\n",
        "        price = {}\n",
        "        print(LENGTH*\"*\")\n",
        "        print(\"Fetching Downloaded CSV Files ...\")\n",
        "        print(LENGTH*\"*\")\n",
        "        for tick in names:\n",
        "            print(f\"Fetching {tick}\")\n",
        "            filename = f\"{tick}.csv\"\n",
        "            df = pd.read_,csv(filename)\n",
        "            price[tick] = df\n",
        "        print(LENGTH*\"*\")\n",
        "        #print('Done ...Time elapsed (hh:mm:ss.ms) {}'.format(datetime.now() - start_time))\n",
        "        print(LENGTH*\"*\")\n",
        "\n",
        "    len(Portfolio_Assets)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b0e8a2c-2557-4c95-94a9-0e81340c4a13",
      "metadata": {
        "id": "4b0e8a2c-2557-4c95-94a9-0e81340c4a13"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=001 : CSV_MERGER_FOR_FW_TESTING\n",
        "--------------------------------------------\n",
        "- READS desired assets from csv files\n",
        "- APPENDS the 'close' columns required in a single df name `li`\n",
        "- DROPS NA rows\n",
        "'''\n",
        "# Portfolio_Assets = names\n",
        "\n",
        "li = pd.DataFrame() # my real portfolio dataframe\n",
        "\n",
        "rets = pd.DataFrame()\n",
        "\n",
        "names = []\n",
        "\n",
        "count = len(Portfolio_Assets)\n",
        "import os\n",
        "#os.chdir(wd)\n",
        "#for file in sorted2.Stock:\n",
        "for file in Portfolio_Assets:\n",
        "    df = pd.read_csv(f\"{file}.csv\", index_col='Date', parse_dates=True, infer_datetime_format=True)\n",
        "    li = pd.concat([li,df['Close']],axis=1, ignore_index=False)\n",
        "    st_name = file.split('.',maxsplit = 1)\n",
        "    names.append(st_name[0])\n",
        "\n",
        "li.columns = names\n",
        "li = li.dropna(axis=0)\n",
        "\n",
        "li"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e21cbaaf-1fe6-4830-b26f-5f356088a00b",
      "metadata": {
        "id": "e21cbaaf-1fe6-4830-b26f-5f356088a00b"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=002 : PORTFOLIO_CALCULATOR\n",
        "--------------------------------------------\n",
        "- READS column of individual assets\n",
        "- CALCULATES the portfolio value as `li[Portfolio]` appended to df `li`\n",
        "- CALCULATES daily log returns for every column of li and writes to `rets`\n",
        "- CALCULATES daily PF Index and writes to `li[Portfolio_Index] and normal daily returns and writes to `li[PF_Returns]`\n",
        "- PRINTS the tear sheet of varios statistics\n",
        "'''\n",
        "import matplotlib.pyplot as plt\n",
        "import pyfolio as pf\n",
        "import numpy as np\n",
        "\n",
        "totals = []\n",
        "ADD = 0\n",
        "for i in np.arange(0,count):\n",
        "    if names[i] == \"GC=F\":\n",
        "        ADD +=  li[f\"{names[i]}\"] * li[\"TRY=X\"] * Portfolio_Shares[i]\n",
        "    else:\n",
        "        ADD +=  li[f\"{names[i]}\"] * Portfolio_Shares[i]\n",
        "        totals.append(li[f\"{names[i]}\"] * Portfolio_Shares[i])\n",
        "\n",
        "ADD += Cash_Plus_MFs # FONLARI EKLEDIK\n",
        "#li = pd.concat([li, ADD], axis=1, ignore_index=False)\n",
        "li['My Portfolio'] = ADD\n",
        "print(f\"Stocks selected = {names}\")\n",
        "print(f\"Number of stocks selected = {len(names)}\")\n",
        "\n",
        "for file in li.columns:\n",
        "    a = np.log(li[f\"{file}\"] / (li[f\"{file}\"].shift(1)))\n",
        "    rets[f\"{file}\"]= a\n",
        "\n",
        "print(\" My Portfolio\", li.round(2).tail(60))\n",
        "print(\" Returns\", rets.round(5).tail(60))\n",
        "plt.plot(li['My Portfolio'])\n",
        "\n",
        "# li['Portfolio'] = ADD # cash added\n",
        "\n",
        "\n",
        "print(li['My Portfolio'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c9af566-1345-4a0f-a364-9765eda8c91d",
      "metadata": {
        "id": "2c9af566-1345-4a0f-a364-9765eda8c91d"
      },
      "outputs": [],
      "source": [
        "li"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97da4917-9779-45d4-b45b-e603ab0e143b",
      "metadata": {
        "id": "97da4917-9779-45d4-b45b-e603ab0e143b"
      },
      "outputs": [],
      "source": [
        "\n",
        "li['Index'] = li['My Portfolio'] / li['My Portfolio'].iloc[0]\n",
        "li['PF_Returns'] = ((li['My Portfolio']-li['My Portfolio'].shift(1)) / li['My Portfolio'].shift(1)).fillna(method=\"ffill\").round(6)\n",
        "MDD = (1.0-li['My Portfolio']/li['My Portfolio'].cummax()).max()\n",
        "li['Max Drawdown'] = MDD\n",
        "\n",
        "pystats_df = pf.timeseries.perf_stats(li['PF_Returns'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2323302f-8381-428c-aef3-b5e2bba888c3",
      "metadata": {
        "id": "2323302f-8381-428c-aef3-b5e2bba888c3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85b59f86-5669-4d67-b8c6-cbe1332605df",
      "metadata": {
        "id": "85b59f86-5669-4d67-b8c6-cbe1332605df"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(f\"\\n======= PF Weights======================\")\n",
        "print(f\"********* PORTFOLIO TEARSHEET *************** \")\n",
        "pf.create_simple_tear_sheet(li['PF_Returns'].dropna())\n",
        "#pf.create_returns_tear_sheet(li['PF_Returns'].dropna())\n",
        "print(\"********* end of TEARSHEET **************\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b912c5c-2cd6-4288-ae48-2511da418799",
      "metadata": {
        "id": "8b912c5c-2cd6-4288-ae48-2511da418799"
      },
      "outputs": [],
      "source": [
        "os.chdir(out)\n",
        "# Move last 5 columns to first\n",
        "\n",
        "temp_cols=li.columns.tolist()\n",
        "new_cols=temp_cols[-4:] + temp_cols[:-4]\n",
        "li=li[new_cols]\n",
        "print(li)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd38942c-ca0c-4fea-ba80-ea65705dbe86",
      "metadata": {
        "id": "fd38942c-ca0c-4fea-ba80-ea65705dbe86"
      },
      "outputs": [],
      "source": [
        "filename = \"DashBoard_Ideal_PF.xlsx\"\n",
        "IDEALPF['Filename'] = filename_statement\n",
        "with pd.ExcelWriter(filename) as writer:  # doctest: +SKIP\n",
        "#    df = pd.DataFrame(Current_PF)\n",
        "#    df.to_excel(writer, sheet_name='Mevcut PF')\n",
        "    df = pd.DataFrame(li)\n",
        "    df.to_excel(writer, sheet_name='PF Close')\n",
        "#    mypf.to_excel(writer, sheet_name='My PF')\n",
        "    pystats_df.to_excel(writer, sheet_name = 'PF STATS')\n",
        "    IDEALPF.to_excel(writer, sheet_name = 'Ideal PF')\n",
        "    # if FW_TEST_PERIOD > FW_TEST_LIMIT :\n",
        "    #     ShoppingList.to_excel(writer, sheet_name = 'Shopping List')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "460bbee5-f632-4f6b-83b9-90bff8e6dc39",
      "metadata": {
        "id": "460bbee5-f632-4f6b-83b9-90bff8e6dc39"
      },
      "outputs": [],
      "source": [
        "\n",
        "li"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "243b8f8c-3cdd-40d5-84db-ff27e9dd0cd1",
      "metadata": {
        "id": "243b8f8c-3cdd-40d5-84db-ff27e9dd0cd1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd7413a0-817f-4aa6-9733-692978361ddc",
      "metadata": {
        "id": "bd7413a0-817f-4aa6-9733-692978361ddc"
      },
      "outputs": [],
      "source": [
        "# '''\n",
        "# UTILITY U=022 : COMPARE_TWO_PORTFOLIOS_AND_CREATE_SHOPPING_LIST\n",
        "# ----------------------------------------------------------------\n",
        "# - READS TWO PORTFOLIOS as DICTIONARY\n",
        "# - CREATES SHOPPING_LIST dictionary for as difference\n",
        "# '''\n",
        "\n",
        "# #WAS = pd.DataFrame(totals)\n",
        "\n",
        "# WAS.T\n",
        "\n",
        "# WAS_DICT = np.round(WAS.T.iloc[-1],2).to_dict()\n",
        "# WAS_DICT = { k.replace('.IS', ''): v for k, v in WAS_DICT.items() }\n",
        "# WAS_DICT\n",
        "\n",
        "# #sum = sum(WAS_DICT.values())\n",
        "# #WILL = np.round(Portfolio_Weights*CURRENT_T2,2)\n",
        "# WILL = pd.DataFrame(totals)\n",
        "\n",
        "# WILL_DICT = { k.replace('.IS', ''): v for k, v in WILL.items() }\n",
        "# WILL_DICT\n",
        "\n",
        "# SHOPPING_LIST = {}\n",
        "# for key in WAS_DICT.keys():\n",
        "#     if key in WILL_DICT:\n",
        "#         SHOPPING_LIST[key] = np.round(WILL_DICT[key] - WAS_DICT[key],2)\n",
        "\n",
        "# for key in WAS_DICT.keys():\n",
        "#     if key in WAS_DICT and not key in WILL_DICT:\n",
        "#         SHOPPING_LIST[key] = -np.round(WAS_DICT[key],2)\n",
        "\n",
        "# for key in WILL_DICT.keys():\n",
        "#     if not key in WAS_DICT and key in WILL_DICT:\n",
        "#         SHOPPING_LIST[key] = np.round(WILL_DICT[key],2)\n",
        "\n",
        "# SHOPPING_LIST\n",
        "\n",
        "# ShoppingList = pd.DataFrame([SHOPPING_LIST]).T\n",
        "\n",
        "# ShoppingList.to_csv('ShoppingList.csv')\n",
        "# ShoppingList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb385810-23a2-4131-be16-9ed1cc528d9a",
      "metadata": {
        "id": "cb385810-23a2-4131-be16-9ed1cc528d9a"
      },
      "outputs": [],
      "source": [
        "print(70*'-')\n",
        "print(70*'-')\n",
        "print(70*'-')\n",
        "print(70*'-')\n",
        "#input(\"Any key to continue\")\n",
        "CORR_FILTER"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5b978fb-9d1b-487d-bd76-2ced02e81d62",
      "metadata": {
        "id": "c5b978fb-9d1b-487d-bd76-2ced02e81d62"
      },
      "source": [
        "### MYPF.csv PORTFOLIO PERFORMANCE <a name=\"mypf.csv_perf\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7af27c1-0cc9-4737-aed0-f684382abc2c",
      "metadata": {
        "id": "a7af27c1-0cc9-4737-aed0-f684382abc2c"
      },
      "outputs": [],
      "source": [
        "#PF = pd.DataFrame(pd.read_csv(f\"EXPORT_{exchange}_MPT_v520D_BK100D-FW200D-SH17.86-ST2022-01-04.csv\"))\n",
        "os.chdir(root)\n",
        "pf = pd.DataFrame(pd.read_csv(\"MYPF.csv\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baffc2b6-1598-40d2-98ae-1e72b655772c",
      "metadata": {
        "tags": [],
        "id": "baffc2b6-1598-40d2-98ae-1e72b655772c"
      },
      "outputs": [],
      "source": [
        "pf['Purchased Value'] = pf['Purchase Price'] * pf['Quantity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e221e832-9162-4cd7-8f41-19a394f14304",
      "metadata": {
        "id": "e221e832-9162-4cd7-8f41-19a394f14304"
      },
      "outputs": [],
      "source": [
        "pf['Market Value'] = pf['Current Price'] * pf['Quantity']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44e0b617-867e-4a73-8dab-e42cdcaa472f",
      "metadata": {
        "id": "44e0b617-867e-4a73-8dab-e42cdcaa472f"
      },
      "outputs": [],
      "source": [
        "pf['PnL %'] = (pf['Market Value'] - pf['Purchased Value']) / pf['Purchased Value'] *100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0db500c-4db9-445d-b81d-d8d913422a18",
      "metadata": {
        "id": "e0db500c-4db9-445d-b81d-d8d913422a18"
      },
      "outputs": [],
      "source": [
        "pf.index = pf.Symbol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecaae049-e655-400f-b944-52b3e4aa3209",
      "metadata": {
        "id": "ecaae049-e655-400f-b944-52b3e4aa3209"
      },
      "outputs": [],
      "source": [
        "pf['Start PF %'] = np.round((pf['Purchased Value'] / pf['Purchased Value'].sum()) *100, 5)\n",
        "pf['End PF %'] = np.round((pf['Market Value'] / pf['Market Value'].sum()) *100, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d20b7de-3174-4a79-b97f-529f26b9354f",
      "metadata": {
        "id": "2d20b7de-3174-4a79-b97f-529f26b9354f"
      },
      "outputs": [],
      "source": [
        "pf.sort_values( by=[\"Start PF %\"], ascending=[False], inplace = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a769baa-02bb-4651-afd5-33c8a3b06275",
      "metadata": {
        "id": "4a769baa-02bb-4651-afd5-33c8a3b06275"
      },
      "outputs": [],
      "source": [
        "MYPF = pf[['Quantity','Purchase Price','Purchased Value','Current Price','Market Value',  'Start PF %', 'End PF %', 'PnL %']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "093580c2-47a5-410b-a498-eb42d5ee3234",
      "metadata": {
        "id": "093580c2-47a5-410b-a498-eb42d5ee3234"
      },
      "outputs": [],
      "source": [
        "MYPF['Market Value'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc2a1fd6-d051-4fdb-8042-76e6a01c7601",
      "metadata": {
        "id": "fc2a1fd6-d051-4fdb-8042-76e6a01c7601"
      },
      "outputs": [],
      "source": [
        "PV = MYPF['Purchased Value'].sum()\n",
        "FV = MYPF['Market Value'].sum()\n",
        "\n",
        "MYPF['Purchase Amount'] = np.trunc(MYPF['End PF %']*CURRENT_T2/100)\n",
        "MYPF['End Quantity'] = np.trunc(MYPF['Purchase Amount'] / MYPF['Current Price'])\n",
        "MYPF\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07e97756-5398-4732-ab51-7a4c980eacbe",
      "metadata": {
        "id": "07e97756-5398-4732-ab51-7a4c980eacbe"
      },
      "outputs": [],
      "source": [
        "MYPF['End PF %']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "504012bd-7301-4d6b-b49a-6f258a3d85b2",
      "metadata": {
        "id": "504012bd-7301-4d6b-b49a-6f258a3d85b2"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=022 : COMPARE_TWO_PORTFOLIOS_AND_CREATE_SHOPPING_LIST\n",
        "----------------------------------------------------------------\n",
        "- READS TWO PORTFOLIOS as DICTIONARY\n",
        "- CREATES SHOPPING_LIST dictionary for as difference\n",
        "'''\n",
        "#if FW_TEST_PERIOD > FW_TEST_LIMIT:\n",
        "WAS = np.round(MYPF['End PF %']/100*CURRENT_T2,2)\n",
        "\n",
        "# WAS_DICT = np.round(WAS.T.iloc[-1],2).to_dict()\n",
        "WAS_DICT = { k.replace('.IS', ''): v for k, v in WAS.items() }\n",
        "WAS_DICT\n",
        "\n",
        "#sum = sum(WAS_DICT.values())\n",
        "WILL = np.round(Ideal_PF_Weights*CURRENT_T2,2)\n",
        "WILL_DICT = { k.replace('.IS', ''): v for k, v in WILL.items() }\n",
        "WILL_DICT\n",
        "\n",
        "SHOPPING_LIST = {}\n",
        "for key in WAS_DICT.keys():\n",
        "    if key in WILL_DICT:\n",
        "        SHOPPING_LIST[key] = np.round(WILL_DICT[key] - WAS_DICT[key],2)\n",
        "\n",
        "for key in WAS_DICT.keys():\n",
        "    if key in WAS_DICT and not key in WILL_DICT:\n",
        "        SHOPPING_LIST[key] = -np.round(WAS_DICT[key],2)\n",
        "\n",
        "for key in WILL_DICT.keys():\n",
        "    if not key in WAS_DICT and key in WILL_DICT:\n",
        "        SHOPPING_LIST[key] = np.round(WILL_DICT[key],2)\n",
        "\n",
        "SHOPPING_LIST\n",
        "\n",
        "ShoppingList = pd.DataFrame([SHOPPING_LIST]).T\n",
        "ShoppingList.to_csv('ShoppingList.csv')\n",
        "ShoppingList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c9416be-c436-412d-92ad-858684dfb6a5",
      "metadata": {
        "id": "3c9416be-c436-412d-92ad-858684dfb6a5"
      },
      "outputs": [],
      "source": [
        "plot_sector_counts(MYPF['End PF %'].dropna())\n",
        "\n",
        "print(f\"Start PF value = {PV:.2f}\")\n",
        "print(f\"Total PF value = {FV:.2f}\")\n",
        "print(f\"Total Revenue =  {FV-PV:.2f}\")\n",
        "print(f\"Total Revenue =  %{(FV-PV)/PV*100:.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ea252d9-c15c-4366-b41d-34aa1b629ade",
      "metadata": {
        "id": "3ea252d9-c15c-4366-b41d-34aa1b629ade"
      },
      "outputs": [],
      "source": [
        "MYPF[['Current Price','End PF %','Purchase Amount','End Quantity']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c467f562-331e-412f-9320-1e207c4c5c42",
      "metadata": {
        "id": "c467f562-331e-412f-9320-1e207c4c5c42"
      },
      "outputs": [],
      "source": [
        "TOTAL_PURCHASED = MYPF['Purchase Amount'].sum()\n",
        "print(f\"TO BE PURCHASED =  {TOTAL_PURCHASED:.2f} TL\")\n",
        "print(f\"CASH REMAINING =  {CURRENT_T2 - TOTAL_PURCHASED:.2f} TL\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1523571-1e0e-48bd-bf1d-59ca812d737f",
      "metadata": {
        "id": "a1523571-1e0e-48bd-bf1d-59ca812d737f"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=003 : SET_CURRENT_PORTFOLIO_PROPERTIES of MY MANUAL PF\n",
        "-----------------------------------------------------------------\n",
        "- SETS desired assets names\n",
        "- SETS number of shares for each asset\n",
        "- SETS extra cash value\n",
        "- PRINTS these as a table\n",
        "'''\n",
        "\n",
        "import pandas as pd    #TI3 mimic as for 29 April 2022\n",
        "\n",
        "\n",
        "Portfolio_Assets = MYPF.index\n",
        "Portfolio_Shares = MYPF['Quantity']\n",
        "Cash_Plus_MFs = 0 # cash + fon + temettü\n",
        "\n",
        "Current_PF = pd.Series(Portfolio_Shares, Portfolio_Assets)\n",
        "print(Current_PF)\n",
        "print('Number of stocks =',len(Current_PF))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e3ff0b2-6ae2-4d42-8df9-8cbec5f918c7",
      "metadata": {
        "id": "7e3ff0b2-6ae2-4d42-8df9-8cbec5f918c7"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=020 : DOWNLOAD_ASSETS_&_WRITE_DF_FOR_FW_TESTING FOR MY MANUAL PF\n",
        "--------------------------------------------\n",
        "- CHANGES WORKING DIRECTORY\n",
        "- SET FLAG TO NEW_DOWNLOAD\n",
        "- GETS DATA FOR ALL ASSETS IN stock_list FROM YAHOO FINANCE\n",
        "- WRITES DATA IN df and price_list\n",
        "- WRITES DATA IN CSV FILES\n",
        "\n",
        "'''\n",
        "\n",
        "LENGTH = 64\n",
        "#os.chdir(wd)\n",
        "\n",
        "new_download = True\n",
        "\n",
        "price_list = []\n",
        "if FW_TEST_PERIOD > FW_TEST_LIMIT:\n",
        "    if new_download:\n",
        "        print(LENGTH*\"*\")\n",
        "        print(\"Starting Download ...\")\n",
        "        print(LENGTH*\"*\")\n",
        "        for tick in Portfolio_Assets:\n",
        "            try:\n",
        "                print(f\"Downloading {tick}\")\n",
        "                yf_tick = yf.Ticker(tick)\n",
        "                df = yf_tick.history(interval='1d', auto_adjust=True, start=T1_START, end=T1_END, back_adjust = True, rounding=True)\n",
        "                df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "                df.dropna(how='all', inplace=True)\n",
        "                price_list.append(df)\n",
        "            except Exception as e:    # added 1/07/22\n",
        "                print(e, tick)        # added 1/07/22\n",
        "\n",
        "        print(LENGTH*\"*\")\n",
        "        if \"GC=F\" in Portfolio_Assets: # added 3/07/22\n",
        "            tick = \"TRY=X\"\n",
        "            try:\n",
        "                print(f\"Downloading {tick}\")\n",
        "                yf_tick = yf.Ticker(tick)\n",
        "                df = yf_tick.history(interval='1d', auto_adjust=True, start=T1_START, end=T1_END, back_adjust = True, rounding=True)\n",
        "                df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "                df.dropna(how='all', inplace=True)\n",
        "                price_list.append(df)\n",
        "            except Exception as e:    # added 1/07/22\n",
        "                print(e, tick)        # added 1/07/22\n",
        "        print(LENGTH*\"*\")\n",
        "        print(LENGTH*\"*\")\n",
        "\n",
        "    ## Save datafiles to disk\n",
        "\n",
        "        for i,df in enumerate(price_list):\n",
        "            df.to_csv(f\"{Portfolio_Assets[i]}.csv\")\n",
        "else:\n",
        "    if new_download:\n",
        "        print(LENGTH*\"*\")\n",
        "        print(\"Starting Download ...\")\n",
        "        print(LENGTH*\"*\")\n",
        "        for tick in Portfolio_Assets:\n",
        "            try:\n",
        "                print(f\"Downloading {tick}\")\n",
        "                yf_tick = yf.Ticker(tick)\n",
        "                df = yf_tick.history(interval='1d', auto_adjust=True, start=T0_START, end=T0_END, back_adjust = True, rounding=True)\n",
        "                df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "                df.dropna(how='all', inplace=True)\n",
        "                price_list.append(df)\n",
        "            except Exception as e:    # added 1/07/22\n",
        "                print(e, tick)        # added 1/07/22\n",
        "        print(LENGTH*\"*\")\n",
        "        if \"GC=F\" in Portfolio_Assets: # added 3/07/22\n",
        "            tick = \"TRY=X\"\n",
        "            try:\n",
        "                print(f\"Downloading {tick}\")\n",
        "                yf_tick = yf.Ticker(tick)\n",
        "                df = yf_tick.history(interval='1d', auto_adjust=True, start=T0_START, end=T0_END, back_adjust = True, rounding=True)\n",
        "                df['Close'] = df['Close'].mask( (tick == \"XU100.IS\" or tick == \"XU030.IS\") & (df['Close'] > 10000), other = df['Close'] / 100.0)\n",
        "                df.dropna(how='all', inplace=True)\n",
        "                price_list.append(df)\n",
        "            except Exception as e:    # added 1/07/22\n",
        "                print(e, tick)        # added 1/07/22\n",
        "        print(LENGTH*\"*\")\n",
        "        print(LENGTH*\"*\")\n",
        "\n",
        "    ## Save datafiles to disk\n",
        "\n",
        "        for i,df in enumerate(price_list):\n",
        "            df.to_csv(f\"{Portfolio_Assets[i]}.csv\")\n",
        "\n",
        "    #\n",
        "    # UTILITY U=021 : FETCH_ASSETS_FROM_CSV_FILES_&_WRITE_DF\n",
        "    # --------------------------------------------\n",
        "    # - CHANGES WORKING DIRECTORY\n",
        "    # - SET FLAG TO NEW_DOWNLOAD\n",
        "    # - GETS DATA FOR ALL ASSETS IN stock_list FROM CSV FILES\n",
        "# - PUTS DATA in df\n",
        "#\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bd66bdd-74d8-4777-9836-83ebea112fc7",
      "metadata": {
        "id": "0bd66bdd-74d8-4777-9836-83ebea112fc7"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=001 : MY MANUAL PF CSV_MERGER_FOR_FW_TESTING\n",
        "--------------------------------------------\n",
        "- READS desired assets from csv files\n",
        "- APPENDS the 'close' columns required in a single df name `li`\n",
        "- DROPS NA rows\n",
        "'''\n",
        "# Portfolio_Assets = names\n",
        "\n",
        "mypf = pd.DataFrame() # my real portfolio dataframe\n",
        "\n",
        "rets = pd.DataFrame()\n",
        "\n",
        "names = []\n",
        "\n",
        "count = len(Portfolio_Assets)\n",
        "import os\n",
        "#os.chdir(wd)\n",
        "#for file in sorted2.Stock:\n",
        "for file in Portfolio_Assets:\n",
        "    df = pd.read_csv(f\"{file}.csv\", index_col='Date', parse_dates=True, infer_datetime_format=True)\n",
        "    mypf = pd.concat([mypf,df['Close']],axis=1, ignore_index=False)\n",
        "    st_name = file.split('.',maxsplit = 1)\n",
        "    names.append(st_name[0])\n",
        "\n",
        "mypf.columns = names\n",
        "#mypf = mypf.dropna(inplace=True)\n",
        "mypf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e961530b-64bf-481a-87c8-94553077c966",
      "metadata": {
        "tags": [],
        "id": "e961530b-64bf-481a-87c8-94553077c966"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "UTILITY U=002 : MY MANUAL PORTFOLIO_CALCULATOR (li. ==> mypf.)\n",
        "--------------------------------------------\n",
        "- READS column of individual assets\n",
        "- CALCULATES the portfolio value as `li[Portfolio]` appended to df `li`\n",
        "- CALCULATES daily log returns for every column of li and writes to `rets`\n",
        "- CALCULATES daily PF Index and writes to `li[Portfolio_Index] and normal daily returns and writes to `li[PF_Returns]`\n",
        "- PRINTS the tear sheet of varios statistics\n",
        "'''\n",
        "import matplotlib.pyplot as plt\n",
        "import pyfolio as pf\n",
        "import numpy as np\n",
        "\n",
        "totals = []\n",
        "ADD = 0\n",
        "for i in np.arange(0,count):\n",
        "    if names[i] == \"GC=F\":\n",
        "        ADD +=  mypf[f\"{names[i]}\"] * mypf[\"TRY=X\"] * Portfolio_Shares[i]\n",
        "    else:\n",
        "        ADD +=  mypf[f\"{names[i]}\"] * Portfolio_Shares[i]\n",
        "        totals.append(mypf[f\"{names[i]}\"] * Portfolio_Shares[i])\n",
        "\n",
        "ADD += Cash_Plus_MFs # FONLARI EKLEDIK\n",
        "#li = pd.concat([li, ADD], axis=1, ignore_index=False)\n",
        "mypf['My Portfolio'] = ADD\n",
        "print(f\"Stocks selected = {names}\")\n",
        "print(f\"Number of stocks selected = {len(names)}\")\n",
        "\n",
        "\n",
        "\n",
        "# for file in li.columns:\n",
        "#     a = np.log(li[f\"{file}\"] / (li[f\"{file}\"].shift(1)))\n",
        "#     rets[f\"{file}\"]= a\n",
        "\n",
        "for file in mypf.columns:\n",
        "    a = np.log(mypf[f\"{file}\"] / (mypf[f\"{file}\"].shift(1)))\n",
        "    rets[f\"{file}\"]= a\n",
        "\n",
        "print(\" My Portfolio\", mypf.round(2).tail(195))\n",
        "\n",
        "print(\" Returns\", rets.round(5).tail(195))\n",
        "\n",
        "plt.plot(mypf['My Portfolio'])\n",
        "\n",
        "# li['Portfolio'] = ADD # cash added\n",
        "mypf['Index'] = mypf['My Portfolio'] / mypf['My Portfolio'].iloc[0]\n",
        "mypf['PF_Returns'] = ((mypf['My Portfolio']-mypf['My Portfolio'].shift(1)) / mypf['My Portfolio'].shift(1)).fillna(method=\"ffill\").round(6)\n",
        "\n",
        "\n",
        "print(f\"\\n======= PF Weights======================\")\n",
        "print(f\"********* PORTFOLIO TEARSHEET *************** \")\n",
        "pf.create_simple_tear_sheet(mypf['PF_Returns'].dropna())\n",
        "#pf.create_returns_tear_sheet(li['PF_Returns'].dropna())\n",
        "print(\"********* end of TEARSHEET **************\\n\")\n",
        "mypf.index = pd.DatetimeIndex(mypf.index)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d87eacd2-fe88-4584-b3be-d61b78cfc72c",
      "metadata": {
        "id": "d87eacd2-fe88-4584-b3be-d61b78cfc72c"
      },
      "source": [
        "### ALPHA BETA CALCULATIONS FOR MYPF.csv <a name=\"alphabeta\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc2b11a4-0676-4d7d-9623-18c5a315f6c9",
      "metadata": {
        "id": "dc2b11a4-0676-4d7d-9623-18c5a315f6c9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "\n",
        "from data import get_stock_data\n",
        "\n",
        "start_date = T1_START\n",
        "end_date = T1_END\n",
        "\n",
        "data = pd.DataFrame()\n",
        "data['XU100'] = mypf.XU100\n",
        "data['PORTFOLIO'] = mypf['My Portfolio']\n",
        "\n",
        "data\n",
        "\n",
        "data_pc = data.pct_change().dropna()*100\n",
        "data_pc.columns = ([\"%XU100\", \"%PF\"])\n",
        "data_pc.tail(30)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(data_pc[\"%XU100\"], data_pc[\"%PF\"],color='b')\n",
        "plt.ylabel(\"%PF\")\n",
        "plt.xlabel(\"%XU100\")\n",
        "plt.show()\n",
        "import statsmodels.api as sm\n",
        "model = sm.OLS( data_pc[\"%PF\"], data_pc[\"%XU100\"])\n",
        "line = model.fit()\n",
        "beta = line.params[0]\n",
        "print(\"BETA =\", line.params)\n",
        "#print(line.t_test([1]))\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.scatter(data_pc['%XU100'], data_pc['%PF'],color='b')\n",
        "x = data_pc['%XU100']\n",
        "y = data_pc['%PF']\n",
        "plt.plot(x, beta*x, color='r')\n",
        "plt.ylabel('%PF')\n",
        "plt.xlabel('%XU100')\n",
        "plt.show()\n",
        "m_x = x.mean()\n",
        "m_y = y.mean()\n",
        "s_x = x.std()\n",
        "s_y = y.std()\n",
        "\n",
        "Mean = pd.DataFrame([m_x,m_y])\n",
        "StDev = pd.DataFrame([s_x,s_y])\n",
        "\n",
        "# print(Mean.T)\n",
        "# print(StDev.T)\n",
        "\n",
        "# Zscore calc\n",
        "# z_x = (x - m_x) / s_x\n",
        "# print(z_x)\n",
        "# z_y = (y - m_y) / s_y\n",
        "# print(z_y)\n",
        "\n",
        "Z = pd.DataFrame([x,y])\n",
        "print(Z)\n",
        "\n",
        "r_xy = data_pc.corr()\n",
        "\n",
        "r_xy\n",
        "r_xy.iloc[1,0]\n",
        "#beta = r_xy.iloc[1,0] * s_y / s_x\n",
        "alpha = m_y - beta * m_x\n",
        "\n",
        "MYPF['Alpha'] = alpha\n",
        "MYPF['Beta'] = beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4911918f-a2c8-4cb1-9269-3b4b6de5c097",
      "metadata": {
        "id": "4911918f-a2c8-4cb1-9269-3b4b6de5c097"
      },
      "outputs": [],
      "source": [
        "beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "171d9db7-a755-47d6-a20a-914a7eae75d9",
      "metadata": {
        "id": "171d9db7-a755-47d6-a20a-914a7eae75d9"
      },
      "outputs": [],
      "source": [
        "alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e298b21a-b887-4ed7-8e1d-c2a535550dd7",
      "metadata": {
        "id": "e298b21a-b887-4ed7-8e1d-c2a535550dd7"
      },
      "outputs": [],
      "source": [
        "data[-17:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e88c2c5-bba8-44b7-82ee-13958435933c",
      "metadata": {
        "id": "7e88c2c5-bba8-44b7-82ee-13958435933c"
      },
      "outputs": [],
      "source": [
        "os.chdir(out)\n",
        "# Move last 4 columns to first\n",
        "\n",
        "temp_cols=mypf.columns.tolist()\n",
        "new_cols=temp_cols[-4:] + temp_cols[:-4]\n",
        "mypf=mypf[new_cols]\n",
        "print(mypf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "516c90da-8479-45a3-9997-4035c90d797d",
      "metadata": {
        "id": "516c90da-8479-45a3-9997-4035c90d797d"
      },
      "outputs": [],
      "source": [
        "\n",
        "mypf['Index'] = mypf['My Portfolio'] / mypf['My Portfolio'].iloc[0]\n",
        "mypf['PF_Returns'] = ((mypf['My Portfolio']-mypf['My Portfolio'].shift(1)) / mypf['My Portfolio'].shift(1)).fillna(method=\"ffill\").round(6)\n",
        "MDD = (1.0-mypf['My Portfolio']/mypf['My Portfolio'].cummax()).max()\n",
        "mypf['Max Drawdown'] = MDD\n",
        "\n",
        "pystats_df = pf.timeseries.perf_stats(mypf['PF_Returns'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8914e637-dddd-4807-b316-68475068ec3f",
      "metadata": {
        "id": "8914e637-dddd-4807-b316-68475068ec3f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eddd0cbb-64ca-4e81-88b5-7c2b00095ae0",
      "metadata": {
        "id": "eddd0cbb-64ca-4e81-88b5-7c2b00095ae0"
      },
      "outputs": [],
      "source": [
        "filename = \"DashBoard_MyPF.xlsx\"\n",
        "MYPF['Filename'] = filename_statement\n",
        "with pd.ExcelWriter(filename) as writer:  # doctest: +SKIP\n",
        "#    df = pd.DataFrame(Current_PF)\n",
        "#    df.to_excel(writer, sheet_name='Mevcut PF')\n",
        "    df = pd.DataFrame(mypf)\n",
        "    df.to_excel(writer, sheet_name='MYPF Close')\n",
        "#    mypf.to_excel(writer, sheet_name='My PF')\n",
        "    pystats_df.to_excel(writer, sheet_name = 'MYPF STATS')\n",
        "    MYPF.to_excel(writer, sheet_name = 'MYPF')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f28886a-cab0-4b76-86d1-9ced1789531a",
      "metadata": {
        "id": "4f28886a-cab0-4b76-86d1-9ced1789531a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "19fed29a-081c-431a-88a4-262b790e32d3",
      "metadata": {
        "id": "19fed29a-081c-431a-88a4-262b790e32d3"
      },
      "source": [
        "CHATGPT: Act like an accountant who knows Python and works for Markov Markowitz company. Write a python code that takes inputs: Account Name, Account No, Entry PF value, Entry Date, Last Date,\tTotal Workdays,\tLatest PF Value,\tTotal % Return, Average Daily % return,\tPF Revenue, PF Comission and generates the excel worksheet form that will be used as a proforma invoice. Columns widths on the excel worksheet should be 20. Date cells should be in short date format. PF cells should be in Turkish currency format. % cells should be in percentage format. All cells should be right aligned. Leave an empty row at beginning of the excel file. The bitmap at the root directory named MARKOVMAR5.1.jpg should be added to the worksheet at the start of F column. Add graphics at C16 so that y-axis values are between B16 and B114 and x-axis values are between A16 to A114. Cells from A16 to A114 should be in short date format. Cells from B16 to B114 should be in Turkish currency format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ac5337-6ebc-4143-8184-80ed79176ffe",
      "metadata": {
        "id": "20ac5337-6ebc-4143-8184-80ed79176ffe"
      },
      "outputs": [],
      "source": [
        "import openpyxl\n",
        "from PIL import Image\n",
        "\n",
        "def Proforma_Invoice(Cash, Account_No, Entry_PF_Value, Entry_Date, Last_Date,\n",
        "                     Total_Workdays, Latest_PF_Value, Total_Percent_Return,\n",
        "                     Average_Daily_Percent_Return, PF_Revenue, PF_Commission, data, shortdate):\n",
        "\n",
        "    wb = openpyxl.load_workbook('proforma_invoice_TEMPLATE.xlsx')\n",
        "    ws = wb.active\n",
        "\n",
        "    ws['A2'] = 'Account Name'\n",
        "    ws['B2'] = Account_Name\n",
        "    ws['A3'] = 'Account No'\n",
        "    ws['B3'] = Account_No\n",
        "    ws['A4'] = 'Entry PF Value'\n",
        "    ws['B4'] = Entry_PF_Value\n",
        "    ws['A5'] = 'Entry Date'\n",
        "    ws['B5'] = Entry_Date\n",
        "    ws['A6'] = 'Last Date'\n",
        "    ws['B6'] = Last_Date\n",
        "    ws['A7'] = 'Total Workdays'\n",
        "    ws['B7'] = Total_Workdays\n",
        "    ws['A8'] = 'Latest PF Value'\n",
        "    ws['B8'] = Latest_PF_Value + Cash\n",
        "    ws['A9'] = 'Total % Return'\n",
        "    ws['B9'] = Total_Percent_Return\n",
        "    ws['A10'] = 'Average Daily % return'\n",
        "    ws['B10'] = Average_Daily_Percent_Return\n",
        "    ws['A11'] = 'PF Revenue'\n",
        "    ws['B11'] = PF_Revenue\n",
        "    ws['A12'] = 'PF Commission'\n",
        "    ws['B12'] = PF_Commission\n",
        "    ws['A15'] = 'Date'\n",
        "    ws['B15'] = 'Portfolio Daily Value'\n",
        "\n",
        "    # Set coumn widths\n",
        "    ws.column_dimensions['A'].width = 20\n",
        "    ws.column_dimensions['B'].width = 20\n",
        "\n",
        "    # Set date cells to short date format\n",
        "    date_cells = ['B5', 'B6']\n",
        "    for cell in date_cells:\n",
        "        ws[cell].number_format = 'DD/MM/YYYY'\n",
        "\n",
        "    # Set PF cells to Turkish currency format\n",
        "    pf_cells = ['B4', 'B8', 'B11', 'B12']\n",
        "    for cell in pf_cells:\n",
        "        ws[cell].number_format = '\\₺#,##0.00'\n",
        "\n",
        "    # Set % cells to percentage format\n",
        "    percent_cells = ['B9', 'B10']\n",
        "    for cell in percent_cells:\n",
        "        ws[cell].number_format = '0.00%'\n",
        "\n",
        "    # Right align all cells\n",
        "    for cell in ws['A2:B12']:\n",
        "        for c in cell:\n",
        "            c.alignment = openpyxl.styles.Alignment(horizontal='right')\n",
        "\n",
        "    # Insert image\n",
        "    img = openpyxl.drawing.image.Image('../MARKOVMAR5.1.png')\n",
        "    ws.add_image(img, 'D1')\n",
        "\n",
        "\n",
        "    # Insert data and dates\n",
        "    for i in range(0,Total_Workdays):\n",
        "        ws[f\"B{i+16}\"] = data.iloc[i]\n",
        "\n",
        "    for i in range(0,Total_Workdays):\n",
        "        ws[f\"A{i+16}\"] = shortdate[i]\n",
        "\n",
        "    # Add graphics at C16\n",
        "    chart = openpyxl.chart.LineChart()\n",
        "    chart.title = f\"{Account_No} Portfolio Performance\"\n",
        "    chart.style = 13\n",
        "    chart.y_axis.title = 'PF Value'\n",
        "    chart.x_axis.title = 'Date'\n",
        "    # Set y-axis values between B16 and B114\n",
        "    data = openpyxl.chart.Reference(ws, min_col=2, min_row=16, max_row=16 + Total_Workdays + 1)\n",
        "    chart.add_data(data, titles_from_data=True)\n",
        "\n",
        "    # Set x-axis values between A16 to A114\n",
        "    dates = openpyxl.chart.Reference(ws, min_col=1, min_row=16, max_row=16 + Total_Workdays + 1)\n",
        "    chart.set_categories(dates)\n",
        "\n",
        "    # chart.y_axis.majorGridlines = openpyxl.chart.gridlines.Crosses(isAutomatic=True)\n",
        "    # chart.x_axis.majorGridlines = openpyxl.chart.gridlines.Crosses(isAutomatic=True)\n",
        "\n",
        "    ws.add_chart(chart, \"D16\")\n",
        "\n",
        "    for row in range(16, 115):\n",
        "        ws['B' + str(row)].number_format = '\\₺#,##0.00'\n",
        "\n",
        "    wb.save(f\"Proforma_Invoice_{Account_No}.xlsx\")\n",
        "\n",
        "    return ws"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6a278ae-4c40-4cc9-9054-1da00a7d1acd",
      "metadata": {
        "id": "b6a278ae-4c40-4cc9-9054-1da00a7d1acd"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6ad5da6-49b8-4055-9957-5e6c3f7335eb",
      "metadata": {
        "id": "d6ad5da6-49b8-4055-9957-5e6c3f7335eb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4d802634-4091-47a7-b5b9-6f4b6d0b4896",
      "metadata": {
        "id": "4d802634-4091-47a7-b5b9-6f4b6d0b4896"
      },
      "source": [
        "### CREATE REPORT FOR PROFORMA INVOICE (BORA) <a name=\"bora_invoice\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45c38f16-8465-46ca-97f8-52fca3a9b3cf",
      "metadata": {
        "id": "45c38f16-8465-46ca-97f8-52fca3a9b3cf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e52a584-2deb-444a-bdc9-1907b94fd1b2",
      "metadata": {
        "id": "5e52a584-2deb-444a-bdc9-1907b94fd1b2"
      },
      "outputs": [],
      "source": [
        "import openpyxl\n",
        "\n",
        "Account_Name = \"Bora Dikmen\"\n",
        "Account_No = 921685\n",
        "Total_Workdays =  6\n",
        "Entry_PF_Value = data.PORTFOLIO[-Total_Workdays]\n",
        "Entry_Date = \"26/12/2022\"\n",
        "Last_Date = \"30/12/2022\"\n",
        "Cash = 1500.53\n",
        "Latest_PF_Value = data.PORTFOLIO[-1] + Cash\n",
        "PF_Revenue = Latest_PF_Value - Entry_PF_Value\n",
        "Total_Percent_Return = PF_Revenue / Entry_PF_Value\n",
        "Average_Daily_Percent_Return = Total_Percent_Return / Total_Workdays\n",
        "PF_Commission= PF_Revenue / 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09522f8e-e82f-486b-9f11-24d2143bb7da",
      "metadata": {
        "id": "09522f8e-e82f-486b-9f11-24d2143bb7da"
      },
      "outputs": [],
      "source": [
        "proforma = Proforma_Invoice(Cash, Account_No, Entry_PF_Value, Entry_Date, Last_Date, Total_Workdays, Latest_PF_Value,\n",
        "                            Total_Percent_Return, Average_Daily_Percent_Return, PF_Revenue, PF_Commission,\n",
        "                            data.PORTFOLIO[-Total_Workdays:], data.index[-Total_Workdays:] )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d0e125e-5605-41b0-86cf-ad3a7caf3934",
      "metadata": {
        "id": "6d0e125e-5605-41b0-86cf-ad3a7caf3934"
      },
      "source": [
        "### CREATE REPORT FOR PROFORMA INVOICE (COŞKUN) <a name=\"coskun_invoice\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99279bc7-1900-43a0-85b3-9150b4659427",
      "metadata": {
        "tags": [],
        "id": "99279bc7-1900-43a0-85b3-9150b4659427"
      },
      "outputs": [],
      "source": [
        "Account_Name = \"Coşkun Erşahin\"\n",
        "Account_No = 922162\n",
        "Entry_PF_Value = 170000\n",
        "Entry_Date = \"09/12/2022\"\n",
        "Last_Date = \"10/01/2023\"\n",
        "Total_Workdays =  10\n",
        "Cash = -18.37\n",
        "Latest_PF_Value = data.PORTFOLIO[-1] + Cash\n",
        "PF_Revenue = Latest_PF_Value - Entry_PF_Value\n",
        "Total_Percent_Return = PF_Revenue / Entry_PF_Value\n",
        "Average_Daily_Percent_Return = Total_Percent_Return / Total_Workdays\n",
        "PF_Commission= PF_Revenue / 20\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee8a3d57-1512-4e84-956d-dc41463a3fd7",
      "metadata": {
        "tags": [],
        "id": "ee8a3d57-1512-4e84-956d-dc41463a3fd7"
      },
      "outputs": [],
      "source": [
        "proforma = Proforma_Invoice(Cash, Account_No, Entry_PF_Value, Entry_Date, Last_Date, Total_Workdays, Latest_PF_Value, Total_Percent_Return,\n",
        "                            Average_Daily_Percent_Return, PF_Revenue, PF_Commission, data.PORTFOLIO[-Total_Workdays:], data.index[-Total_Workdays:] )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "539368c6-9765-475a-b620-e469105af6c2",
      "metadata": {
        "tags": [],
        "id": "539368c6-9765-475a-b620-e469105af6c2"
      },
      "source": [
        "### CREATE REPORT FOR PROFORMA INVOICE (MURAT)<a name=\"murat_invoice\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a24339ec-b25b-4942-aec7-340be38e629c",
      "metadata": {
        "id": "a24339ec-b25b-4942-aec7-340be38e629c"
      },
      "outputs": [],
      "source": [
        "Account_Name = \"Murat Özbayoğlu\"\n",
        "Account_No = 920302\n",
        "Entry_PF_Value = 75000\n",
        "Entry_Date = \"16/12/2022\"\n",
        "Last_Date = \"01/01/2023\"\n",
        "Total_Workdays =  12\n",
        "Cash = 83.89\n",
        "Latest_PF_Value = data.PORTFOLIO[-1] + Cash\n",
        "PF_Revenue = Latest_PF_Value - Entry_PF_Value\n",
        "Total_Percent_Return = PF_Revenue / Entry_PF_Value\n",
        "Average_Daily_Percent_Return = Total_Percent_Return / Total_Workdays\n",
        "PF_Commission= PF_Revenue / 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f630be69-bfa5-4a8a-bd79-5f3fbbad647e",
      "metadata": {
        "tags": [],
        "id": "f630be69-bfa5-4a8a-bd79-5f3fbbad647e"
      },
      "outputs": [],
      "source": [
        "proforma = Proforma_Invoice(Cash, Account_No, Entry_PF_Value, Entry_Date, Last_Date, Total_Workdays, Latest_PF_Value, Total_Percent_Return,\n",
        "                            Average_Daily_Percent_Return, PF_Revenue, PF_Commission, data.PORTFOLIO[-Total_Workdays:], data.index[-Total_Workdays:] )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfa5d598-4695-49d3-a225-98d5f8a26227",
      "metadata": {
        "id": "bfa5d598-4695-49d3-a225-98d5f8a26227"
      },
      "source": [
        "### CREATE REPORT FOR PROFORMA INVOICE (ALPER)<a name=\"alper_invoice\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6367e84-0e93-470e-be77-33599f695e67",
      "metadata": {
        "id": "f6367e84-0e93-470e-be77-33599f695e67"
      },
      "outputs": [],
      "source": [
        "Account_Name = \"Alper Ülkü\"\n",
        "Account_No = 9098005\n",
        "Total_Workdays = 3\n",
        "Entry_PF_Value = data.PORTFOLIO[-Total_Workdays]\n",
        "Entry_Date = \"29/12/2022\"\n",
        "Last_Date = \"02/01/2023\"\n",
        "Cash = 1402\n",
        "\n",
        "Latest_PF_Value = data.PORTFOLIO[-1] + Cash\n",
        "PF_Revenue = Latest_PF_Value - Entry_PF_Value\n",
        "Total_Percent_Return = PF_Revenue / Entry_PF_Value\n",
        "Average_Daily_Percent_Return = Total_Percent_Return / Total_Workdays\n",
        "PF_Commission= PF_Revenue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccca1a16-c946-40a6-942d-fb259f03c2e4",
      "metadata": {
        "id": "ccca1a16-c946-40a6-942d-fb259f03c2e4"
      },
      "outputs": [],
      "source": [
        "proforma = Proforma_Invoice(Cash, Account_No, Entry_PF_Value, Entry_Date, Last_Date, Total_Workdays, Latest_PF_Value, Total_Percent_Return,\n",
        "                            Average_Daily_Percent_Return, PF_Revenue, PF_Commission, data.PORTFOLIO[-Total_Workdays:], data.index[-Total_Workdays:] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a6a406b-2ad4-4eb6-a3c1-e4b61e399b73",
      "metadata": {
        "id": "9a6a406b-2ad4-4eb6-a3c1-e4b61e399b73"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "63699ce6-6d85-4bee-b711-6c81eca99aad",
      "metadata": {
        "tags": [],
        "id": "63699ce6-6d85-4bee-b711-6c81eca99aad"
      },
      "source": [
        "### Send Ideal PF by Gmail  <a name=\"send_gmail\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c35b0d11-1e04-4564-9508-c28da5a239d7",
      "metadata": {
        "id": "c35b0d11-1e04-4564-9508-c28da5a239d7"
      },
      "outputs": [],
      "source": [
        "# '''\n",
        "\n",
        "# UTILITY U=019 : SEND_EMAIL_THRU_GMAIL\n",
        "# --------------------------------------------\n",
        "# - SETS variables for mail server\n",
        "# - SETS database to be emailed\n",
        "# - SETS filename to be attached\n",
        "# - CHANGES directory for writing the excel file\n",
        "# - FORMS the excel file\n",
        "# - SETS params for mail and its content with smtp lib\n",
        "# - ATTACHES file with mimetypes\n",
        "# - SENDS mail to my own gmail address with ssl library\n",
        "\n",
        "# '''\n",
        "\n",
        "# gmail_pass = \"rgszqketyguqkivb\"  #uwyuympejcjvaikg\n",
        "# user = \"alperulku1970@gmail.com\"\n",
        "# subscribers = \"alperulku1970@gmail.com\"\n",
        "# SERVER_ADDRESS = \"smtp.gmail.com\"\n",
        "# SERVER_PORT = 587\n",
        "\n",
        "# #now = datetime.now()\n",
        "# Final_TEFAS_PF['Max Drawdown %'] = np.round(MaxDrawdown, 4)\n",
        "# IDEALPF['Max Drawdown'] = np.round(MaxDrawdown, 4)\n",
        "# Final_TEFAS_PF.to_csv(filename_statement + \".csv\")\n",
        "# filename = filename_statement + \".xlsx\"\n",
        "# shopping_list_file = 'ShoppingList.csv'\n",
        "# os.chdir(out)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # with pd.ExcelWriter(filename) as writer:  # doctest: +SKIP\n",
        "# #     #Final_TEFAS_PF.to_excel(writer, sheet_name = 'Yeni Portföy')\n",
        "# #     #df = pd.DataFrame(Kurallar)\n",
        "# #     #df.to_excel(writer, sheet_name='Kurallar')\n",
        "# #     df = pd.DataFrame(Performance)\n",
        "# #     df.to_excel(writer, sheet_name='İdeal PF Performans')\n",
        "# #     df = pd.DataFrame(Current_PF)\n",
        "# #     df.to_excel(writer, sheet_name='Mevcut PF')\n",
        "# #     IDEALPF.to_excel(writer, sheet_name = 'Ideal PF')\n",
        "# #     if FW_TEST_PERIOD !=0:\n",
        "# #         ShoppingList.to_excel(writer, sheet_name='Fark Alış-Satış Listesi')\n",
        "\n",
        "\n",
        "# with pd.ExcelWriter(filename) as writer:  # doctest: +SKIP\n",
        "#     #Final_TEFAS_PF.to_excel(writer, sheet_name = 'Yeni Portföy')\n",
        "#     #df = pd.DataFrame(Kurallar)\n",
        "#     #df.to_excel(writer, sheet_name='Kurallar')\n",
        "#     df = pd.DataFrame(Performance)\n",
        "#     df.to_excel(writer, sheet_name='İdeal PF Performans')\n",
        "#     df = pd.DataFrame(Current_PF)\n",
        "#     df.to_excel(writer, sheet_name='Mevcut PF')\n",
        "#     IDEALPF.to_excel(writer, sheet_name = 'Ideal PF')\n",
        "#     Final_TEFAS_PF.to_excel(writer, sheet_name = 'YF_Ideal PF')\n",
        "#     if FW_TEST_PERIOD !=0:\n",
        "#         ShoppingList.to_excel(writer, sheet_name='Fark Alış-Satış Listesi')\n",
        "\n",
        "\n",
        "#     # worksheet = writer.sheets['Ideal PF']\n",
        "#     # worksheet.insert_image('C2','RR_Plot_BIST.png')\n",
        "#     # writer.save()\n",
        "\n",
        "\n",
        "\n",
        "# import smtplib\n",
        "# from email.message import EmailMessage\n",
        "\n",
        "# msg = EmailMessage()\n",
        "\n",
        "# msg['Subject'] = filename\n",
        "# msg['From'] = user\n",
        "# msg['To'] = subscribers\n",
        "\n",
        "# text = f\"Merhaba, bugünün {exchange} piyasası için en iyi Sharpe Oranı'na sahip Portföyü ektedir: {filename} \\r\\n\"\n",
        "# text+= f\"Forward Test süresi = {FW_TEST_PERIOD} gün \\r\\n\"\n",
        "# text+= f\"Backtest Test süresi = {BACKTEST_PERIOD} gün \\r\\n\"\n",
        "# text+= \"Markov Markowitz, Çankaya, Ankara, Türkiye.\\r\\n\"\n",
        "# text+= \"Her hakkı saklıdır. @ Markov Markowitz 2022.\"\n",
        "\n",
        "# msg.set_content(text)\n",
        "\n",
        "# import mimetypes\n",
        "\n",
        "# #path = f\"/Users/alperulku/Desktop/Masaüstü - Alper’s Mac mini/MY BEST PORTFOLIOS/{filename}\"\n",
        "# path = out + \"/\" + filename\n",
        "\n",
        "# # Guess the content type based on the file's extension.\n",
        "# ctype, encoding = mimetypes.guess_type(path)\n",
        "# if ctype is None or encoding is not None:\n",
        "#     ctype = 'application/octet-stream'\n",
        "# maintype, subtype = ctype.split('/', 1)\n",
        "\n",
        "# with open(path, 'rb') as fp:\n",
        "#     msg.add_attachment(fp.read(), maintype=maintype, subtype=subtype,\n",
        "#                        filename=filename)\n",
        "\n",
        "# path = out + \"/\" + \"YF_IDEAL.csv\"\n",
        "# with open(path, 'rb') as fp:\n",
        "#     msg.add_attachment(fp.read(), maintype=maintype, subtype=subtype,\n",
        "#                        filename=\"YF_IDEAL.csv\")\n",
        "\n",
        "\n",
        "# path = out + \"/\" + \"MPT_v547_PROFORMA_OK.pdf\"\n",
        "# with open(path, 'rb') as fp:\n",
        "#     msg.add_attachment(fp.read(), maintype=maintype, subtype=subtype,\n",
        "#                        filename=\"MPT_v547_PROFORMA_OK.pdf\")\n",
        "\n",
        "\n",
        "\n",
        "# import ssl\n",
        "\n",
        "# # Create a SSLContext object with default settings.\n",
        "# context = ssl.create_default_context()\n",
        "\n",
        "# with smtplib.SMTP(SERVER_ADDRESS, SERVER_PORT) as smtp:\n",
        "#     smtp.ehlo()  # Say EHLO to server\n",
        "#     smtp.starttls(context=context)  # Puts the connection in TLS mode.\n",
        "#     smtp.ehlo()\n",
        "#     smtp.login(user, gmail_pass)\n",
        "#     smtp.send_message(msg)  # Auto detects the sender and recipient from header\n",
        "\n",
        "# print(\"mail sent with success with attachment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27e1a213-1818-4859-8103-20b2b4c60c87",
      "metadata": {
        "id": "27e1a213-1818-4859-8103-20b2b4c60c87"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29e880cd-59e9-4c22-a89b-49a2d9b8c816",
      "metadata": {
        "id": "29e880cd-59e9-4c22-a89b-49a2d9b8c816"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1757e7f4-ab92-45b9-9fc5-b2f2ad4ea7e4",
      "metadata": {
        "id": "1757e7f4-ab92-45b9-9fc5-b2f2ad4ea7e4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "27f07e1c-bf97-4779-a1bc-e121e030a39c",
      "metadata": {
        "id": "27f07e1c-bf97-4779-a1bc-e121e030a39c"
      },
      "source": [
        "## NOW APPLICATION OF WQU LESSONS ONWARDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd10c9d5-41d4-44f1-83c9-24dd09146c15",
      "metadata": {
        "id": "cd10c9d5-41d4-44f1-83c9-24dd09146c15"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import kurtosis, skewnorm\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (16, 9)  # Figure size and width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5f28da3-90e6-4d67-823c-29950c9aaf88",
      "metadata": {
        "id": "a5f28da3-90e6-4d67-823c-29950c9aaf88"
      },
      "outputs": [],
      "source": [
        "# Three distributions with different tail shapes\n",
        "x = np.arange(0,len(mypf['PF_Returns']))\n",
        "\n",
        "# Plot each distribution\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "plt.plot(mypf['PF_Returns'], lw=2, c=\"b\", label=\"Returns\")\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "# plt.hist(mypf['PF_Returns'], bins=30, label=\"PDF\", density=True, alpha=1)  # Histogram\n",
        "# plt.show()\n",
        "mypf['PF_Returns'].skew()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0a46b1d-0e84-400d-ad24-3c7efea87217",
      "metadata": {
        "id": "f0a46b1d-0e84-400d-ad24-3c7efea87217"
      },
      "outputs": [],
      "source": [
        "mypf['PF_Returns'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3459eba4-f775-48e9-8f2e-3514f5bfe3e3",
      "metadata": {
        "id": "3459eba4-f775-48e9-8f2e-3514f5bfe3e3"
      },
      "outputs": [],
      "source": [
        "# Histogram and Normal QQ Plot for Google Stock Returns\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
        "mypf_returns = mypf['PF_Returns'].dropna()\n",
        "\n",
        "# Histogram with density\n",
        "x = np.linspace(min(mypf_returns), max(mypf_returns), len(mypf_returns))\n",
        "(mu, sigma) = stats.norm.fit(mypf_returns)\n",
        "values, bins, _ = ax1.hist(mypf_returns, bins=30)  # Histogram\n",
        "ax1.plot(x, stats.norm.pdf(x, mu, sigma) * sum(values * np.diff(bins)), \"r\")  # Density\n",
        "ax1.set(title=\"MYPF Returns Histogram\")\n",
        "\n",
        "# Normal QQ plot\n",
        "sm.qqplot(mypf_returns, stats.norm, fit=True, line=\"q\", ax=ax2)\n",
        "ax2.set(title=\"Normal QQ Plot for MYPF Returns\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd5ef9fb-cd98-4b7b-ac8b-764467d8a6f1",
      "metadata": {
        "id": "bd5ef9fb-cd98-4b7b-ac8b-764467d8a6f1"
      },
      "source": [
        "### SHAPIRO-WILK test for NORMALITY<a name=\"shapiro\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79399f56-7448-4094-a1a4-150a7d1a06e0",
      "metadata": {
        "id": "79399f56-7448-4094-a1a4-150a7d1a06e0"
      },
      "outputs": [],
      "source": [
        "# Shapiro Wilk normality test\n",
        "shapiro_test = stats.shapiro(mypf_returns)\n",
        "# print(\n",
        "#     \"Shapiro W: {0} \\nShapiro p-value {1}\".format(\n",
        "#         shapiro_test.statistic, shapiro_test.pvalue\n",
        "#     )\n",
        "# )\n",
        "\n",
        "if shapiro_test.pvalue > 0.05:\n",
        "    print(\"Distribution is Normal by %\", 100*shapiro_test.statistic)\n",
        "else:\n",
        "    print(\"Distribution is Non-Normal\")\n",
        "print(f\"skew = {mypf_returns.skew()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4d9375e-5773-4642-9d25-cc30cc781cdd",
      "metadata": {
        "id": "e4d9375e-5773-4642-9d25-cc30cc781cdd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from arch.univariate import ARCH, ConstantMean, Normal\n",
        "from scipy import stats\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (16, 9)  # Figure size and width\n",
        "#ARCH(1) Simulation n=1000, alpha_0=5 and alpha_1=0.5\n",
        "\n",
        "# simulated process parameters\n",
        "rs = np.random.RandomState([12345, 77777])\n",
        "\n",
        "dist = Normal(seed=rs)\n",
        "vol = ARCH(p=1)\n",
        "repro_mod = ConstantMean(None, volatility=vol, distribution=dist)\n",
        "\n",
        "\n",
        "params = pd.Series({\"mu\": 0.0, \"omega\": 5, \"alpha[1]\": 0.5, \"beta[1]\": 0.0})\n",
        "\n",
        "# model simulation\n",
        "arch1_sim = repro_mod.simulate(params, nobs=1000)\n",
        "params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1571abc-3efa-4a80-a504-cb159199bd22",
      "metadata": {
        "id": "f1571abc-3efa-4a80-a504-cb159199bd22"
      },
      "source": [
        "### ACF and PACF tests for Stationarity<a name=\"acf_pacf\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce046748-6606-43d8-b267-28990f4c953f",
      "metadata": {
        "id": "ce046748-6606-43d8-b267-28990f4c953f"
      },
      "outputs": [],
      "source": [
        "# ACF and PACF of ARCH(1) Simulated Time Series\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
        "sm.graphics.tsa.plot_acf(mypf_returns, lags=9, ax=ax1)\n",
        "ax1.set(title=\"ACF of ARCH(1) MYPF Return Series\")\n",
        "ax1.set_ylim([-0.5, 0.5])\n",
        "\n",
        "sm.graphics.tsa.plot_pacf(mypf_returns, lags=9, ax=ax2)\n",
        "ax2.set(title=\"PACF of ARCH(1) MYPF Return Series\")\n",
        "ax2.set_ylim([-0.5, 0.5])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d57c38a-1954-4040-84bd-5aca8fbe869a",
      "metadata": {
        "id": "6d57c38a-1954-4040-84bd-5aca8fbe869a"
      },
      "outputs": [],
      "source": [
        "mypf_returns.tail(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6af04f89-0837-4842-96c3-84e8a66f680d",
      "metadata": {
        "id": "6af04f89-0837-4842-96c3-84e8a66f680d"
      },
      "outputs": [],
      "source": [
        "# ACF and PACF of Squared ARCH(1) Simulated Time Series\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
        "sm.graphics.tsa.plot_acf(mypf_returns ** 2, lags=9, ax=ax1)\n",
        "ax1.set(title=\"ACF of Squared ARCH(1) MYPF Return Series\")\n",
        "ax1.set_ylim([-1, 1])\n",
        "\n",
        "sm.graphics.tsa.plot_pacf(mypf_returns ** 2, lags=9, ax=ax2)\n",
        "ax2.set(title=\"PACF of Squared ARCH(1) MYPF ReturnSeries\")\n",
        "ax2.set_ylim([-1, 1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "604018d6-cf32-4019-b57f-512b86a235e1",
      "metadata": {
        "id": "604018d6-cf32-4019-b57f-512b86a235e1"
      },
      "source": [
        "### TREND DETECTION AND BUY-SELL SIGNAL GENERATION FOR MYPF <a name=\"trend_detect\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b4c0883-f84d-4bf0-b2f1-b75457de71dc",
      "metadata": {
        "id": "8b4c0883-f84d-4bf0-b2f1-b75457de71dc"
      },
      "outputs": [],
      "source": [
        "#TREND DETECTION AND TREND SIGNAL GENERATION FOR MOST VOLATILE ASSET (MVA)\n",
        "\n",
        "SM = 3\n",
        "LM = 10\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 22))\n",
        "\n",
        "\n",
        "mypf['Pct_change'] = mypf['My Portfolio'].pct_change()\n",
        "# mypf[f'Skew{SM}'] = mypf['Pct_change'].rolling(window=SM).skew()\n",
        "# mypf[f'Skew{LM}'] = mypf['Pct_change'].rolling(window=LM).skew()\n",
        "mypf[f'MA{SM}'] = mypf['My Portfolio'].rolling(window=SM).mean()\n",
        "mypf[f'MA{LM}'] = mypf['My Portfolio'].rolling(window=LM).mean()\n",
        "\n",
        "mypf['My_PF_lag']   = mypf['My Portfolio'].shift(1)\n",
        "mypf[f'lag_MA{SM}'] = mypf[f'MA{SM}'].shift(1)\n",
        "mypf[f'lag_MA{LM}'] = mypf[f'MA{LM}'].shift(1)\n",
        "\n",
        "buy_mask =    (mypf['My Portfolio'] > mypf[f'MA{LM}'])     & \\\n",
        "              (mypf['My_PF_lag']    < mypf[f'lag_MA{LM}'])\n",
        "\n",
        "# buy_mask =    ( mypf[f'MA{SM}']       > mypf[f'MA{LM}'])     & \\\n",
        "#               ( mypf[f'lag_MA{SM}']   < mypf[f'lag_MA{LM}'])\n",
        "\n",
        "sell_mask =   (mypf['My Portfolio'] < mypf[f'MA{LM}'])     & \\\n",
        "              (mypf['My_PF_lag']    > mypf[f'lag_MA{LM}'])\n",
        "\n",
        "\n",
        "# sell_mask =   ( mypf[f'MA{SM}']       < mypf[f'MA{LM}'])     & \\\n",
        "#               ( mypf[f'lag_MA{SM}']   > mypf[f'lag_MA{LM}'])\n",
        "\n",
        "mypf['uptrend'] = np.nan\n",
        "mypf.loc[buy_mask,'uptrend'] = +1\n",
        "mypf.loc[sell_mask,'uptrend'] = -1\n",
        "mypf.uptrend = mypf.uptrend.fillna(method=\"ffill\") * 150000\n",
        "\n",
        "ax1.set(title=\"Portfolio Trend detector\")\n",
        "ax1.set_ylim([np.min(mypf['My Portfolio']), np.max(mypf['My Portfolio'])])\n",
        "mypf[['My Portfolio','uptrend',f'MA{SM}', f'MA{LM}']].plot(ax=ax1)\n",
        "\n",
        "# ax2.set(title=\"Return Skewness with moving windows\")\n",
        "# ax2.set_ylim([np.min(mypf[f'Skew{LM}']), np.max(mypf[f'Skew{LM}'])])\n",
        "# mypf[[f'Skew{SM}',f'Skew{LM}']].plot(figsize = (16,22), ax=ax2, grid=True)\n",
        "\n",
        "# ax2.set(title=\"BUY-SELL SIGNAL FOR CANTE.IS ASSET\")\n",
        "# ax2.set_ylim([-1,1])\n",
        "# mypf.signal.plot( ax=ax2)\n",
        "\n",
        "ax2.set(title=\"Portfolio Percentage change\")\n",
        "ax2.set_ylim([np.min(mypf['Pct_change']), np.max(mypf['Pct_change'])])\n",
        "mypf['Pct_change'].plot(figsize = (16,22), ax=ax2, grid=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f858a4b-c8ec-4dd6-9158-33310e0709f0",
      "metadata": {
        "id": "7f858a4b-c8ec-4dd6-9158-33310e0709f0"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "766a75d2-8d5f-4ce0-b6b3-ff10c9405843",
      "metadata": {
        "id": "766a75d2-8d5f-4ce0-b6b3-ff10c9405843"
      },
      "source": [
        "### TIME SERIES STATISTICAL MODELS <a name=\"time_series\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc72d1e3-a1a1-423a-a326-f90e87e03aab",
      "metadata": {
        "id": "cc72d1e3-a1a1-423a-a326-f90e87e03aab"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "192a1dfa-88ab-4462-a757-55e8cb13c434",
      "metadata": {
        "id": "192a1dfa-88ab-4462-a757-55e8cb13c434"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.arima_process import arma_generate_sample\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (16, 9)  # Figure size and width\n",
        "# Detrend\n",
        "timeTrend = np.linspace(1, len(mypf['My Portfolio']), len(mypf['My Portfolio']))\n",
        "timeTrend = sm.add_constant(timeTrend)\n",
        "\n",
        "# Fit OLS\n",
        "model = sm.OLS(mypf['My Portfolio'], timeTrend)\n",
        "fit_g = model.fit()\n",
        "fit_g.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f337af4-e9e7-4040-a1de-064064110f66",
      "metadata": {
        "id": "8f337af4-e9e7-4040-a1de-064064110f66"
      },
      "outputs": [],
      "source": [
        "# # Plot residuals\n",
        "# mypf_res = fit_g.resid\n",
        "# mypf_res.plot(linewidth=1.3, xlabel=\"Year\", ylabel=\"Residuals\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f54e1a5d-dce7-4ad4-8f13-458de24553ee",
      "metadata": {
        "id": "f54e1a5d-dce7-4ad4-8f13-458de24553ee"
      },
      "outputs": [],
      "source": [
        "# # Plot First Difference of Google Stock Price\n",
        "# mypf['My Portfolio'].diff().plot(\n",
        "#     linewidth=1.3, xlabel=\"Year\", ylabel=\"First difference of My Portfolio value\")\n",
        "# plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27a95845-8aa5-4795-a600-4015b0d6339d",
      "metadata": {
        "id": "27a95845-8aa5-4795-a600-4015b0d6339d"
      },
      "outputs": [],
      "source": [
        "# ACF of First Difference of Google Stock Price\n",
        "# (Note: [1:] as we need to skip first element since the model lost one data point)\n",
        "fig, ax = plt.subplots(figsize=(12, 9))\n",
        "sm.graphics.tsa.plot_acf(\n",
        "    mypf['My Portfolio'].diff()[1:],\n",
        "    title=\"ACF of First Difference of My Portfolio\",\n",
        "    lags=12,\n",
        "    ax=ax,\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be8a67ef-28f5-44b4-a406-2227264528fd",
      "metadata": {
        "id": "be8a67ef-28f5-44b4-a406-2227264528fd"
      },
      "outputs": [],
      "source": [
        "# # Normal white noise ts example\n",
        "# plt.plot(np.random.normal(0, 3, 300))\n",
        "# plt.title(\"Normal White Noise with Mean=0 and Variance=9\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b3a6313-9cb0-4ea2-ad1a-2be8b865b995",
      "metadata": {
        "id": "1b3a6313-9cb0-4ea2-ad1a-2be8b865b995"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9233f59-d855-433e-9628-8e1e553ab534",
      "metadata": {
        "id": "b9233f59-d855-433e-9628-8e1e553ab534"
      },
      "outputs": [],
      "source": [
        "# MA(1) for Google stock\n",
        "mypf_ma1 = statsmodels.tsa.arima.model.ARIMA(mypf['My Portfolio'], order=(0, 0, 10)).fit()\n",
        "print(mypf_ma1.params)\n",
        "#Plot Google vs fitted Google stock prices\n",
        "mypf_ma1_res = mypf_ma1.resid\n",
        "mypf_ma1_fit = mypf['My Portfolio'] - mypf_ma1_res\n",
        "\n",
        "mypf['My Portfolio'].plot(linewidth=0.8, label=\"Original Portfolio\")\n",
        "mypf_ma1_fit.plot(linewidth=0.8, label=\"Fitted Portfolio\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a570417-be0b-49f2-a496-758794b5c36e",
      "metadata": {
        "id": "2a570417-be0b-49f2-a496-758794b5c36e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84bb621e-554c-41f0-b72f-d7f6a0c08ae5",
      "metadata": {
        "id": "84bb621e-554c-41f0-b72f-d7f6a0c08ae5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "67009121-3082-4568-8e03-4bf1c6bf3a05",
      "metadata": {
        "tags": [],
        "id": "67009121-3082-4568-8e03-4bf1c6bf3a05"
      },
      "source": [
        "### AUTOREGRESSIVE MODEL OPS <a name=\"autoregressive\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bd8eb18-27f2-44d9-a1e6-3422808b64b4",
      "metadata": {
        "id": "2bd8eb18-27f2-44d9-a1e6-3422808b64b4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7450c746-28f6-48a7-ab39-d3de9b4e94df",
      "metadata": {
        "tags": [],
        "id": "7450c746-28f6-48a7-ab39-d3de9b4e94df"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from pmdarima.arima import auto_arima\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (16, 9)  # Figure size and width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29da08e6-da60-4455-a66e-61bc7ae425ef",
      "metadata": {
        "id": "29da08e6-da60-4455-a66e-61bc7ae425ef"
      },
      "outputs": [],
      "source": [
        "# Time Series plot of Google stock price with ACF and PACF\n",
        "mypf['Pct_change'] = mypf['My Portfolio'].pct_change()\n",
        "\n",
        "# Plot of Google stock price\n",
        "plt.plot(mypf['My Portfolio'])\n",
        "plt.title(\"My PF\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\" Stock Price\")\n",
        "plt.show()\n",
        "\n",
        "# plot ACF and PACF\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
        "sm.graphics.tsa.plot_acf(mypf['My Portfolio'], title=\"My PF ACF\", lags=20, ax=ax1)\n",
        "sm.graphics.tsa.plot_pacf(mypf['My Portfolio'], title=\"My PF PACF\", lags=20, ax=ax2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ae12fbd-7370-4daf-9586-7727b536fc2c",
      "metadata": {
        "id": "6ae12fbd-7370-4daf-9586-7727b536fc2c"
      },
      "outputs": [],
      "source": [
        "# Plot of First Differencing of Google Stock Price\n",
        "# plt.plot(mypf['My Portfolio'].diff().dropna())\n",
        "# plt.ylabel(\"First Difference of My PF\")\n",
        "# plt.show()\n",
        "\n",
        "# Plot First Differencing of Log of Google Stock Price\n",
        "plt.plot(np.log(mypf['My Portfolio']).diff().dropna())\n",
        "plt.ylabel(\"First Difference of Log of My PF\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06d006f0-3e22-4314-b6c6-c726b024d72d",
      "metadata": {
        "id": "06d006f0-3e22-4314-b6c6-c726b024d72d"
      },
      "outputs": [],
      "source": [
        "# ACF and PACF Plots for First Difference of Logged Google Stock Price\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
        "sm.graphics.tsa.plot_acf(\n",
        "    np.log(mypf['My Portfolio']).diff().dropna(),\n",
        "    title=\"ACF of First Difference of Logged My PF\",\n",
        "    lags=9,\n",
        "    ax=ax1,\n",
        ")\n",
        "sm.graphics.tsa.plot_pacf(\n",
        "    np.log(mypf['My Portfolio']).diff().dropna(),\n",
        "    title=\"PACF of First Difference of Logged My PF\",\n",
        "    lags=9,\n",
        "    ax=ax2,\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6fe1328-b1ac-42a1-acff-30aedd50f5ae",
      "metadata": {
        "id": "e6fe1328-b1ac-42a1-acff-30aedd50f5ae"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34b6d145-210c-480b-913b-287637513b56",
      "metadata": {
        "id": "34b6d145-210c-480b-913b-287637513b56"
      },
      "outputs": [],
      "source": [
        "# Best ARIMA Model for Google stock price\n",
        "mod_can_a = ARIMA(\n",
        "    np.log(mypf['My Portfolio']), order=(0, 1, 1), trend=\"n\"\n",
        ").fit()  # This is the best model in Python implementation\n",
        "print(mod_can_a.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "606691f1-f814-4a6c-9ebc-e16b6083aafb",
      "metadata": {
        "id": "606691f1-f814-4a6c-9ebc-e16b6083aafb"
      },
      "outputs": [],
      "source": [
        "# Diagnostic Report for ARIMA(1,1,0) Model\n",
        "mod_can_a.plot_diagnostics()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f25995da-3e7c-4fc4-bbee-98a40afba8e7",
      "metadata": {
        "id": "f25995da-3e7c-4fc4-bbee-98a40afba8e7"
      },
      "outputs": [],
      "source": [
        "# Ljung-Box test for no serial correlation of standardized residuals\n",
        "lb_test = mod_can_a.test_serial_correlation(\n",
        "    method=\"ljungbox\", df_adjust=True, lags=None\n",
        ")\n",
        "\n",
        "# plot Ljung-Box test p-values and 0.05 significance line\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(lb_test[0][1], linestyle=\"\", marker=\"o\")\n",
        "plt.axhline(y=0.05, color=\"blue\", linestyle=\"--\")\n",
        "plt.title(\"p-values for Ljung-Box statistic\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2181e85e-cc41-4370-9f2a-8826b4a2db87",
      "metadata": {
        "id": "2181e85e-cc41-4370-9f2a-8826b4a2db87"
      },
      "source": [
        "In the ACF plot for the residuals, the ACFs with p-values above 0.05 are not significant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ca79d3d-8da2-427c-841a-587c4eca962e",
      "metadata": {
        "tags": [],
        "id": "0ca79d3d-8da2-427c-841a-587c4eca962e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from pmdarima.arima import auto_arima\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "#Efficient ARIMA model Selection\n",
        "mod_can_auto = auto_arima(\n",
        "    np.log(mypf['My Portfolio']).dropna(),  # stepwise=False,\n",
        "    start_p=0,\n",
        "    start_d=0,\n",
        "    start_q=0,\n",
        "    max_p=5,\n",
        "    max_d=2,\n",
        "    max_q=5,\n",
        "    trace=True,\n",
        "    return_valid_fits=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0df84afe-f755-4a59-a906-1c47b1660107",
      "metadata": {
        "id": "0df84afe-f755-4a59-a906-1c47b1660107"
      },
      "outputs": [],
      "source": [
        "#input(\"Check ARIMA parameters below value and continue\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1edf92be-f6d1-4a05-9e1f-392e8fa2187f",
      "metadata": {
        "id": "1edf92be-f6d1-4a05-9e1f-392e8fa2187f"
      },
      "source": [
        "\n",
        "\n",
        "## TIME SERIES ARIMA (p,r,q) MODEL FOR MY PORTFOLIO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c42f7a7a-4d1e-44dd-a8da-ccebd7f73f04",
      "metadata": {
        "id": "c42f7a7a-4d1e-44dd-a8da-ccebd7f73f04"
      },
      "outputs": [],
      "source": [
        "# MA(1) for first difference of Google stock price\n",
        "\n",
        "# mypf_ma2 = statsmodels.tsa.arima.model.ARIMA(mypf['My Portfolio'],\n",
        "#                                              order=(0, 2, 1)).fit()\n",
        "\n",
        "# mypf_ma2 = statsmodels.tsa.arima.model.ARIMA(mypf['My Portfolio'],\n",
        "#                                              order=(1, 1, 0)).fit(method= 'statespace')\n",
        "mypf_ma2 = statsmodels.tsa.arima.model.ARIMA(mypf['My Portfolio'],\n",
        "                                             order=(0, 1, 0)).fit(method='statespace')\n",
        "\n",
        "# mypf_ma2 = statsmodels.tsa.arima.model.ARIMA(mypf['My Portfolio'],\n",
        "#                                              order=(1, 0, 0)).fit(method= 'innovations_mle')\n",
        "# mypf_ma2 = statsmodels.tsa.arima.model.ARIMA(mypf['My Portfolio'],\n",
        "#                                              order=(0, 1, 1)).fit(method= 'innovations')\n",
        "\n",
        "\n",
        "\n",
        "print(mypf_ma2.params)\n",
        "\n",
        "# Plotting Google vs fitted Google stock prices using first differencing\n",
        "mypf_ma2_res = mypf_ma2.resid\n",
        "mypf_ma2_fit = mypf['My Portfolio'] - mypf_ma2_res\n",
        "mypf_ma2_fit_full = mypf_ma2_fit\n",
        "mypf_ma2_res = mypf_ma2_res[\n",
        "    1:\n",
        "]  # need to skip first element since the model lost one data point\n",
        "mypf_ma2_fit = mypf_ma2_fit[\n",
        "    1:\n",
        "]  # need to skip first element since the model lost one data point\n",
        "\n",
        "mypf_ma2_fit_full_lag = mypf_ma2_fit_full.shift(1)\n",
        "\n",
        "# buy_mask =    (mypf['My Portfolio'] > mypf[f'MA{LM}'])     & \\\n",
        "#               (mypf['My_PF_lag']    < mypf[f'lag_MA{LM}'])\n",
        "\n",
        "buy_mask =    ( mypf['My Portfolio'] > mypf_ma2_fit_full     )    & \\\n",
        "              ( mypf['My_PF_lag']    < mypf_ma2_fit_full_lag )\n",
        "\n",
        "# sell_mask =   (mypf['My Portfolio'] < mypf[f'MA{LM}'])     & \\\n",
        "#               (mypf['My_PF_lag']    > mypf[f'lag_MA{LM}'])\n",
        "\n",
        "\n",
        "sell_mask =   ( mypf['My Portfolio'] < mypf_ma2_fit_full     )     & \\\n",
        "              ( mypf['My_PF_lag']    > mypf_ma2_fit_full_lag )\n",
        "\n",
        "\n",
        "mypf['AR_Uptrend'] = np.nan\n",
        "mypf.loc[buy_mask,'AR_Uptrend'] = +1\n",
        "mypf.loc[sell_mask,'AR_Uptrend'] = -1\n",
        "mypf.AR_Uptrend = mypf.AR_Uptrend.fillna(method=\"ffill\") *np.max(mypf['My Portfolio'])\n",
        "\n",
        "# ax1.set(title=\"Portfolio Trend detector\")\n",
        "# ax1.set_ylim([np.min(mypf['My Portfolio']), np.max(mypf['My Portfolio'])])\n",
        "# mypf[['My Portfolio','AR_Uptrend']].plot(ax=ax1)\n",
        "\n",
        "mypf['My Portfolio'].tail(90).plot(linewidth=0.8, label=\"Original My Portfolio\")\n",
        "mypf_ma2_fit.tail(90).plot(\n",
        "    linewidth=1, label=\"Fitted My Portfolio using ARIMA(0,1,1) statespace Method\"\n",
        ")\n",
        "mypf['AR_Uptrend'].tail(90).plot(\n",
        "    linewidth=1, label=\"Uptrend\")\n",
        "\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.ylim(np.min(mypf['My Portfolio']), np.max(mypf['My Portfolio']))\n",
        "\n",
        "os.chdir(root)\n",
        "plt.savefig(\"Fig_007_StateSpaceTrend.jpg\", format='jpg', dpi=300)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce88ddc7-26b0-4da1-b6ad-18e8b2b9b7ac",
      "metadata": {
        "id": "ce88ddc7-26b0-4da1-b6ad-18e8b2b9b7ac"
      },
      "source": [
        "\n",
        "ARCH and GARCH\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b733cce-e341-4f06-a9aa-7159b29aa202",
      "metadata": {
        "id": "7b733cce-e341-4f06-a9aa-7159b29aa202"
      },
      "outputs": [],
      "source": [
        "#input(\"have a look at the trend\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5efac149-2444-4130-9117-a4c311e06c3c",
      "metadata": {
        "id": "5efac149-2444-4130-9117-a4c311e06c3c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from arch.univariate import ARCH, ConstantMean, Normal\n",
        "from scipy import stats\n",
        "from arch import arch_model\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (16, 9)  # Figure size and width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44c9e849-ed29-4f66-9875-2a35eb60b60c",
      "metadata": {
        "id": "44c9e849-ed29-4f66-9875-2a35eb60b60c"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "\n",
        "# Convert date variable to date format and set index\n",
        "#goog = mypf['PF_Returns']\n",
        "\n",
        "goog = np.log(mypf['My Portfolio']).diff().dropna()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3756ad1-1f6c-44fe-b7a2-fe5f16222679",
      "metadata": {
        "id": "c3756ad1-1f6c-44fe-b7a2-fe5f16222679"
      },
      "outputs": [],
      "source": [
        "# Histogram and Normal QQ Plot for Google Stock Returns\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
        "goog_r = goog.dropna()\n",
        "\n",
        "# Histogram with density\n",
        "x = np.linspace(min(goog_r), max(goog_r), len(goog_r))\n",
        "(mu, sigma) = stats.norm.fit(goog_r)\n",
        "values, bins, _ = ax1.hist(goog_r, bins=25)  # Histogram\n",
        "ax1.plot(x, stats.norm.pdf(x, mu, sigma) * sum(values * np.diff(bins)), \"r\")  # Density\n",
        "ax1.set(title=\"My PF  Return Histogram\")\n",
        "\n",
        "# Normal QQ plot\n",
        "sm.qqplot(goog_r, stats.norm, fit=True, line=\"q\", ax=ax2)\n",
        "ax2.set(title=\"Normal QQ Plot for My PF Returns\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a94bc9af-ab1b-4901-bfac-f4513006dac5",
      "metadata": {
        "id": "a94bc9af-ab1b-4901-bfac-f4513006dac5"
      },
      "outputs": [],
      "source": [
        "# Google Stock Squared Returns\n",
        "plt.plot(goog ** 2)\n",
        "plt.ylabel(\"square of stock price return\")\n",
        "plt.title(\"Plot of 2016-2021 daily Google stock squared return\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bff45986-8e3a-4838-9877-f9e373dcd265",
      "metadata": {
        "id": "bff45986-8e3a-4838-9877-f9e373dcd265"
      },
      "outputs": [],
      "source": [
        "# ARCH(1) Simulation n=1000, alpha_0=5 and alpha_1=0.5\n",
        "\n",
        "# simulated process parameters\n",
        "rs = np.random.RandomState([12345, 77777])\n",
        "dist = Normal(seed=rs)\n",
        "vol = ARCH(p=1)\n",
        "repro_mod = ConstantMean(None, volatility=vol, distribution=dist)\n",
        "params = pd.Series({\"mu\": 0.0, \"omega\": 5, \"alpha[1]\": 0.5, \"beta[1]\": 0.0})\n",
        "\n",
        "# model simulation\n",
        "arch1_sim = repro_mod.simulate(params, nobs=1000)\n",
        "plt.plot(arch1_sim.data)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3330dc30-16dc-43a8-b90d-747e63f4bce8",
      "metadata": {
        "id": "3330dc30-16dc-43a8-b90d-747e63f4bce8"
      },
      "outputs": [],
      "source": [
        "# ACF and PACF of ARCH(1) Simulated Time Series\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
        "sm.graphics.tsa.plot_acf(arch1_sim.data.dropna(), lags=20, ax=ax1)\n",
        "ax1.set(title=\"ACF of ARCH(1) Simulated Time Series\")\n",
        "ax1.set_ylim([-0.2, 0.2])\n",
        "\n",
        "sm.graphics.tsa.plot_pacf(arch1_sim.data.dropna(), lags=20, ax=ax2)\n",
        "ax2.set(title=\"PACF of ARCH(1) Simulated Time Series\")\n",
        "ax2.set_ylim([-0.2, 0.2])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e9ead0b-1942-42ce-9aa7-3ebc58abc9e7",
      "metadata": {
        "id": "7e9ead0b-1942-42ce-9aa7-3ebc58abc9e7"
      },
      "outputs": [],
      "source": [
        "# ACF and PACF of Squared ARCH(1) Simulated Time Series\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
        "sm.graphics.tsa.plot_acf(arch1_sim.data.dropna() ** 2, lags=20, ax=ax1)\n",
        "ax1.set(title=\"ACF of Squared ARCH(1) Simulated Time Series\")\n",
        "ax1.set_ylim([-0, 1])\n",
        "\n",
        "sm.graphics.tsa.plot_pacf(arch1_sim.data.dropna() ** 2, lags=20, ax=ax2)\n",
        "ax2.set(title=\"PACF of Squared ARCH(1) Simulated Time Series\")\n",
        "ax2.set_ylim([-0, 1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f9c5763-c23a-4a5d-919a-c96c3f7c90ee",
      "metadata": {
        "id": "1f9c5763-c23a-4a5d-919a-c96c3f7c90ee"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "422181ed-c64a-4421-b797-a41690d4b610",
      "metadata": {
        "id": "422181ed-c64a-4421-b797-a41690d4b610"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69f31209-28ec-4dcf-8603-16c086e59cd1",
      "metadata": {
        "id": "69f31209-28ec-4dcf-8603-16c086e59cd1"
      },
      "outputs": [],
      "source": [
        "# ACF and PACF Plots for Google Stock Returns and Squared Returns\n",
        "fig, ax = plt.subplots(2, 2)\n",
        "\n",
        "sm.graphics.tsa.plot_acf(goog_r, lags=9, ax=ax[0, 0])\n",
        "ax[0, 0].set(title=\"ACF plot of Google stock return\")\n",
        "ax[0, 0].set_ylim([-0.5, 0.5])\n",
        "\n",
        "sm.graphics.tsa.plot_pacf(goog_r, lags=9, ax=ax[0, 1])\n",
        "ax[0, 1].set(title=\"PACF plot of Google stock return\")\n",
        "ax[0, 1].set_ylim([-0.5, 0.5])\n",
        "\n",
        "sm.graphics.tsa.plot_acf(goog_r ** 2, lags=9, ax=ax[1, 0])\n",
        "ax[1, 0].set(title=\"ACF plot of Google stock squared return\")\n",
        "ax[1, 0].set_ylim([-0.5, 0.5])\n",
        "\n",
        "sm.graphics.tsa.plot_pacf(goog_r ** 2, lags=9, ax=ax[1, 1])\n",
        "ax[1, 1].set(title=\"PACF plot of Google stock squared return\")\n",
        "ax[1, 1].set_ylim([-0.5, 0.5])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e5f72a6-9e6b-43dc-bf68-7b4121da5885",
      "metadata": {
        "id": "8e5f72a6-9e6b-43dc-bf68-7b4121da5885"
      },
      "outputs": [],
      "source": [
        "garch11_spec = arch_model(\n",
        "    goog_r,\n",
        "    vol=\"GARCH\",\n",
        "    p=1,\n",
        "    q=1,\n",
        "    mean=\"AR\",\n",
        "    dist=\"Normal\",\n",
        "    rescale=True,\n",
        ")\n",
        "garch11_fit = garch11_spec.fit()\n",
        "garch11_fit.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f43be66b-d362-4a42-86eb-cbe93023baec",
      "metadata": {
        "id": "f43be66b-d362-4a42-86eb-cbe93023baec"
      },
      "outputs": [],
      "source": [
        "# Diagnostic tests for GARCH(1,1) Model with Normal White Noise\n",
        "print(\"GARCH(1,1) Model with Normal White Noise\\n\")\n",
        "\n",
        "# Ljung-Box test and the Box-Pierce test\n",
        "print(\"Ljung-Box and Box-Pierce tests on stanrdized residuals\")\n",
        "print(acorr_ljungbox(garch11_fit.std_resid, boxpierce=True))\n",
        "\n",
        "print(\"\\nLjung-Box and Box-Pierce tests on stanrdized squared residuals\")\n",
        "print(acorr_ljungbox(garch11_fit.std_resid ** 2, boxpierce=True))\n",
        "\n",
        "# ARCH LM test for conditional heteroskedasticity\n",
        "print(\"\\nARCH LM test for conditional heteroskedasticity\")\n",
        "print(garch11_fit.arch_lm_test(standardized=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efe58b13-81ff-470d-9f1b-219992049e7c",
      "metadata": {
        "id": "efe58b13-81ff-470d-9f1b-219992049e7c"
      },
      "outputs": [],
      "source": [
        "# Model Diagnostic Plots for the GARCH(1,1) Model with Normal White Noise\n",
        "fig, ax = plt.subplots(4, 3, figsize=(16, 12))\n",
        "\n",
        "# Figure Row 1 Column 1\n",
        "ax[0, 0].plot(goog_r)\n",
        "ax[0, 0].plot(2.0 * garch11_fit.conditional_volatility / 100.0, c=\"r\")\n",
        "ax[0, 0].plot(-2.0 * garch11_fit.conditional_volatility / 100.0, c=\"r\")\n",
        "ax[0, 0].tick_params(labelrotation=45)\n",
        "ax[0, 0].set_title(\"Series with 2 conditional SD\")\n",
        "ax[0, 0].set_ylabel(\"Return\")\n",
        "\n",
        "# Figure Row 1 Column 2\n",
        "VaR_1 = stats.norm.ppf(0.99)\n",
        "ax[0, 1].plot(goog_r)\n",
        "ax[0, 1].plot(VaR_1 * garch11_fit.conditional_volatility / 100.0, c=\"r\")\n",
        "ax[0, 1].plot(-VaR_1 * garch11_fit.conditional_volatility / 100.0, c=\"r\")\n",
        "ax[0, 1].tick_params(labelrotation=45)\n",
        "ax[0, 1].set_title(\"Series with 1% VaR Limits\")\n",
        "ax[0, 1].set_ylabel(\"Return\")\n",
        "\n",
        "# Figure Row 1 Column 3\n",
        "ax[0, 2].plot(garch11_fit.conditional_volatility / 100.0)\n",
        "ax[0, 2].set_title(\"Conditional SD\")\n",
        "ax[0, 2].tick_params(labelrotation=45)\n",
        "\n",
        "# Figure Row 2 Column 1\n",
        "sm.graphics.tsa.plot_acf(garch11_fit.resid / 100.0, lags=9, ax=ax[1, 0])\n",
        "ax[1, 0].set_title(\"ACF of Observations\")\n",
        "ax[1, 0].set_ylim([-0.3, 0.3])\n",
        "\n",
        "# Figure Row 2 Column 2\n",
        "sm.graphics.tsa.plot_acf(garch11_fit.resid ** 2, lags=9, ax=ax[1, 1])\n",
        "ax[1, 1].set_title(\"ACF of Squared Observations\")\n",
        "ax[1, 1].set_ylim([-0.3, 0.3])\n",
        "\n",
        "# Figure Row 2 Column 3\n",
        "sm.graphics.tsa.plot_acf(np.abs(garch11_fit.resid), lags=9, ax=ax[1, 2])\n",
        "ax[1, 2].set_title(\"ACF of Absolute Observations\")\n",
        "ax[1, 2].set_ylim([-0.3, 0.3])\n",
        "\n",
        "# Figure Row 3 Column 1\n",
        "ax[2, 0].xcorr(\n",
        "    garch11_fit.resid ** 2,\n",
        "    garch11_fit.resid,\n",
        "    usevlines=True,\n",
        "    maxlags=10,\n",
        "    normed=True,\n",
        "    lw=2,\n",
        ")\n",
        "ax[2, 0].set_title(\"Cross-Correlation of Squared Observations \\n vs Actual Observation\")\n",
        "\n",
        "# Figure Row 3 Column 2\n",
        "standaraized_residuals = garch11_fit.resid.dropna() / garch11_fit.resid.dropna().std()\n",
        "min_val = np.min(standaraized_residuals)\n",
        "max_val = np.max(standaraized_residuals)\n",
        "empirical_density = np.linspace(min_val, max_val, len(standaraized_residuals))\n",
        "ax[2, 1].plot(empirical_density, stats.norm.pdf(empirical_density), lw=1)\n",
        "ax[2, 1].set_title(\"Empirical density of \\n standarized residuals\")\n",
        "\n",
        "# Figure Row 3 Column 3\n",
        "sm.qqplot(garch11_fit.resid, stats.norm, fit=True, line=\"q\", ax=ax[2, 2])\n",
        "ax[2, 2].set_title(\"Normal QQ-plot\")\n",
        "\n",
        "# Figure Row 4 Column 1\n",
        "sm.graphics.tsa.plot_acf(\n",
        "    garch11_fit.resid / garch11_fit.resid.std(), lags=9, ax=ax[3, 0]\n",
        ")\n",
        "ax[3, 0].set_title(\"ACF of Standarized Residuals\")\n",
        "ax[3, 0].set_ylim([-0.3, 0.3])\n",
        "\n",
        "# Figure Row 4 Column 2\n",
        "sm.graphics.tsa.plot_acf(\n",
        "    (garch11_fit.resid / garch11_fit.resid.std()) ** 2, lags=9, ax=ax[3, 1]\n",
        ")\n",
        "ax[3, 1].set_title(\"ACF of Squared Standarized Residuals\")\n",
        "ax[3, 1].set_ylim([-0.3, 0.3])\n",
        "\n",
        "ax[3, 2].axis(\"off\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c26c4b4b-3d46-4264-8e63-193f567a044d",
      "metadata": {
        "id": "c26c4b4b-3d46-4264-8e63-193f567a044d"
      },
      "outputs": [],
      "source": [
        "# GARCH(1,1) Model with Student's t White Noise\n",
        "garch11_t_spec = arch_model(\n",
        "    goog_r,\n",
        "    vol=\"GARCH\",\n",
        "    p=1,\n",
        "    q=1,\n",
        "    mean=\"AR\",\n",
        "    dist=\"StudentsT\",  # power=2.0,\n",
        "    rescale=True,\n",
        ")\n",
        "garch11_t_fit = garch11_t_spec.fit()\n",
        "garch11_t_fit.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83128c35-6f7a-4ab7-bf60-65de9a0e2b9a",
      "metadata": {
        "id": "83128c35-6f7a-4ab7-bf60-65de9a0e2b9a"
      },
      "outputs": [],
      "source": [
        "# Diagnostic tests for GARCH(1,1) Model with Student's t White Noise\n",
        "print(\"GARCH(1,1) Model with StudentsT White Noise\\n\")\n",
        "\n",
        "# Ljung-Box test and the Box-Pierce test\n",
        "print(\"Ljung-Box and Box-Pierce tests on stanrdized residuals\")\n",
        "print(acorr_ljungbox(garch11_t_fit.std_resid, boxpierce=True))\n",
        "\n",
        "print(\"\\nLjung-Box and Box-Pierce tests on stanrdized squared residuals\")\n",
        "print(acorr_ljungbox(garch11_t_fit.std_resid ** 2, boxpierce=True))\n",
        "\n",
        "# ARCH LM test for conditional heteroskedasticity\n",
        "print(\"\\nARCH LM test for conditional heteroskedasticity for\")\n",
        "print(garch11_t_fit.arch_lm_test(standardized=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5622a829-7055-4ea1-8511-c1e4c237a623",
      "metadata": {
        "id": "5622a829-7055-4ea1-8511-c1e4c237a623"
      },
      "outputs": [],
      "source": [
        "# Model Diagnostic Plots for the GARCH(1,1) Model with Student's t White Noise\n",
        "fig, ax = plt.subplots(4, 3, figsize=(16, 12))\n",
        "\n",
        "# Figure Row 1 Column 1\n",
        "ax[0, 0].plot(goog_r)\n",
        "ax[0, 0].plot(2.0 * garch11_t_fit.conditional_volatility / 100.0, c=\"r\")\n",
        "ax[0, 0].plot(-2.0 * garch11_t_fit.conditional_volatility / 100.0, c=\"r\")\n",
        "ax[0, 0].tick_params(labelrotation=45)\n",
        "ax[0, 0].set_title(\"Series with 2 conditional SD\")\n",
        "ax[0, 0].set_ylabel(\"Return\")\n",
        "\n",
        "# Figure Row 1 Column 2\n",
        "VaR_1 = stats.t(df=len(goog_r) - 1).ppf(0.99)\n",
        "# VaR_1 = stats.norm.ppf(0.99)\n",
        "ax[0, 1].plot(goog_r)\n",
        "ax[0, 1].plot(VaR_1 * garch11_t_fit.conditional_volatility / 100.0, c=\"r\")\n",
        "ax[0, 1].plot(-VaR_1 * garch11_t_fit.conditional_volatility / 100.0, c=\"r\")\n",
        "ax[0, 1].tick_params(labelrotation=45)\n",
        "ax[0, 1].set_title(\"Series with 1% VaR Limits\")\n",
        "ax[0, 1].set_ylabel(\"Return\")\n",
        "\n",
        "# Figure Row 1 Column 3\n",
        "ax[0, 2].plot(garch11_t_fit.conditional_volatility / 100.0)\n",
        "ax[0, 2].set_title(\"Conditional SD\")\n",
        "ax[0, 2].tick_params(labelrotation=45)\n",
        "\n",
        "# Figure Row 2 Column 1\n",
        "sm.graphics.tsa.plot_acf(garch11_t_fit.resid / 100.0, lags=9, ax=ax[1, 0])\n",
        "ax[1, 0].set_title(\"ACF of Observations\")\n",
        "ax[1, 0].set_ylim([-0.3, 0.3])\n",
        "\n",
        "# Figure Row 2 Column 2\n",
        "sm.graphics.tsa.plot_acf(garch11_t_fit.resid ** 2, lags=9, ax=ax[1, 1])\n",
        "ax[1, 1].set_title(\"ACF of Squared Observations\")\n",
        "ax[1, 1].set_ylim([-0.3, 0.3])\n",
        "\n",
        "# Figure Row 2 Column 3\n",
        "sm.graphics.tsa.plot_acf(np.abs(garch11_t_fit.resid), lags=9, ax=ax[1, 2])\n",
        "ax[1, 2].set_title(\"ACF of Absolute Observations\")\n",
        "ax[1, 2].set_ylim([-0.3, 0.3])\n",
        "\n",
        "# Figure Row 3 Column 1\n",
        "ax[2, 0].xcorr(\n",
        "    garch11_t_fit.resid ** 2,\n",
        "    garch11_t_fit.resid,\n",
        "    usevlines=True,\n",
        "    maxlags=10,\n",
        "    normed=True,\n",
        "    lw=2,\n",
        ")\n",
        "ax[2, 0].set_title(\"Cross-Correlation of Squared Observations \\n vs Actual Observation\")\n",
        "\n",
        "# Figure Row 3 Column 2\n",
        "standaraized_residuals = (\n",
        "    garch11_t_fit.resid.dropna() / garch11_t_fit.resid.dropna().std()\n",
        ")\n",
        "min_val = np.min(standaraized_residuals)\n",
        "max_val = np.max(standaraized_residuals)\n",
        "empirical_density = np.linspace(min_val, max_val, len(standaraized_residuals))\n",
        "ax[2, 1].plot(empirical_density, stats.norm.pdf(empirical_density), lw=1)\n",
        "ax[2, 1].set_title(\"Empirical density of \\n standarized residuals\")\n",
        "\n",
        "# Figure Row 3 Column 3\n",
        "sm.qqplot(garch11_t_fit.resid, stats.t, fit=True, line=\"q\", ax=ax[2, 2])\n",
        "ax[2, 2].set_title(\"StudentsT QQ-plot\")\n",
        "\n",
        "# Figure Row 4 Column 1\n",
        "sm.graphics.tsa.plot_acf(\n",
        "    garch11_t_fit.resid / garch11_t_fit.resid.std(), lags=9, ax=ax[3, 0]\n",
        ")\n",
        "ax[3, 0].set_title(\"ACF of Standarized Residuals\")\n",
        "ax[3, 0].set_ylim([-0.3, 0.3])\n",
        "\n",
        "# Figure Row 4 Column 2\n",
        "sm.graphics.tsa.plot_acf(\n",
        "    (garch11_t_fit.resid / garch11_t_fit.resid.std()) ** 2, lags=9, ax=ax[3, 1]\n",
        ")\n",
        "ax[3, 1].set_title(\"ACF of Squared Standarized Residuals\")\n",
        "ax[3, 1].set_ylim([-0.3, 0.3])\n",
        "\n",
        "ax[3, 2].axis(\"off\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31078865-a3bd-46e2-b1a8-36eddee81604",
      "metadata": {
        "id": "31078865-a3bd-46e2-b1a8-36eddee81604"
      },
      "outputs": [],
      "source": [
        "# Diagnostic tests for GARCH(1,1) Model with Student's t White Noise\n",
        "print(\"GARCH(1,1) Model with StudentsT White Noise\\n\")\n",
        "\n",
        "# Ljung-Box test and the Box-Pierce test\n",
        "print(\"Ljung-Box and Box-Pierce tests on stanrdized residuals\")\n",
        "print(acorr_ljungbox(garch11_t_fit.std_resid, boxpierce=True))\n",
        "\n",
        "print(\"\\nLjung-Box and Box-Pierce tests on stanrdized squared residuals\")\n",
        "print(acorr_ljungbox(garch11_t_fit.std_resid ** 2, boxpierce=True))\n",
        "\n",
        "# ARCH LM test for conditional heteroskedasticity\n",
        "print(\"\\nARCH LM test for conditional heteroskedasticity for\")\n",
        "print(garch11_t_fit.arch_lm_test(standardized=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c422396-a0eb-45b8-a63a-51577a41479b",
      "metadata": {
        "id": "4c422396-a0eb-45b8-a63a-51577a41479b"
      },
      "outputs": [],
      "source": [
        "# # Model Diagnostic Plots for the GARCH(1,1) Model with Student's t White Noise\n",
        "# fig, ax = plt.subplots(4, 3, figsize=(16, 12))\n",
        "\n",
        "# # Figure Row 1 Column 1\n",
        "# ax[0, 0].plot(goog_r)\n",
        "# ax[0, 0].plot(2.0 * garch11_t_fit.conditional_volatility / 100.0, c=\"r\")\n",
        "# ax[0, 0].plot(-2.0 * garch11_t_fit.conditional_volatility / 100.0, c=\"r\")\n",
        "# ax[0, 0].tick_params(labelrotation=45)\n",
        "# ax[0, 0].set_title(\"Series with 2 conditional SD\")\n",
        "# ax[0, 0].set_ylabel(\"Return\")\n",
        "\n",
        "# # Figure Row 1 Column 2\n",
        "# VaR_1 = stats.t(df=len(goog_r) - 1).ppf(0.99)\n",
        "# # VaR_1 = stats.norm.ppf(0.99)\n",
        "# ax[0, 1].plot(goog_r)\n",
        "# ax[0, 1].plot(VaR_1 * garch11_t_fit.conditional_volatility / 100.0, c=\"r\")\n",
        "# ax[0, 1].plot(-VaR_1 * garch11_t_fit.conditional_volatility / 100.0, c=\"r\")\n",
        "# ax[0, 1].tick_params(labelrotation=45)\n",
        "# ax[0, 1].set_title(\"Series with 1% VaR Limits\")\n",
        "# ax[0, 1].set_ylabel(\"Return\")\n",
        "\n",
        "# # Figure Row 1 Column 3\n",
        "# ax[0, 2].plot(garch11_t_fit.conditional_volatility / 100.0)\n",
        "# ax[0, 2].set_title(\"Conditional SD\")\n",
        "# ax[0, 2].tick_params(labelrotation=45)\n",
        "\n",
        "# # Figure Row 2 Column 1\n",
        "# sm.graphics.tsa.plot_acf(garch11_t_fit.resid / 100.0, lags=20, ax=ax[1, 0])\n",
        "# ax[1, 0].set_title(\"ACF of Observations\")\n",
        "# ax[1, 0].set_ylim([-0.3, 0.3])\n",
        "\n",
        "# # Figure Row 2 Column 2\n",
        "# sm.graphics.tsa.plot_acf(garch11_t_fit.resid ** 2, lags=20, ax=ax[1, 1])\n",
        "# ax[1, 1].set_title(\"ACF of Squared Observations\")\n",
        "# ax[1, 1].set_ylim([-0.3, 0.3])\n",
        "\n",
        "# # Figure Row 2 Column 3\n",
        "# sm.graphics.tsa.plot_acf(np.abs(garch11_t_fit.resid), lags=20, ax=ax[1, 2])\n",
        "# ax[1, 2].set_title(\"ACF of Absolute Observations\")\n",
        "# ax[1, 2].set_ylim([-0.3, 0.3])\n",
        "\n",
        "# # Figure Row 3 Column 1\n",
        "# ax[2, 0].xcorr(\n",
        "#     garch11_t_fit.resid ** 2,\n",
        "#     garch11_t_fit.resid,\n",
        "#     usevlines=True,\n",
        "#     maxlags=30,\n",
        "#     normed=True,\n",
        "#     lw=2,\n",
        "# )\n",
        "# ax[2, 0].set_title(\"Cross-Correlation of Squared Observations \\n vs Actual Observation\")\n",
        "\n",
        "# # Figure Row 3 Column 2\n",
        "# standaraized_residuals = (\n",
        "#     garch11_t_fit.resid.dropna() / garch11_t_fit.resid.dropna().std()\n",
        "# )\n",
        "# min_val = np.min(standaraized_residuals)\n",
        "# max_val = np.max(standaraized_residuals)\n",
        "# empirical_density = np.linspace(min_val, max_val, len(standaraized_residuals))\n",
        "# ax[2, 1].plot(empirical_density, stats.norm.pdf(empirical_density), lw=1)\n",
        "# ax[2, 1].set_title(\"Empirical density of \\n standarized residuals\")\n",
        "\n",
        "# # Figure Row 3 Column 3\n",
        "# sm.qqplot(garch11_t_fit.resid, stats.t, fit=True, line=\"q\", ax=ax[2, 2])\n",
        "# ax[2, 2].set_title(\"StudentsT QQ-plot\")\n",
        "\n",
        "# # Figure Row 4 Column 1\n",
        "# sm.graphics.tsa.plot_acf(\n",
        "#     garch11_t_fit.resid / garch11_t_fit.resid.std(), lags=20, ax=ax[3, 0]\n",
        "# )\n",
        "# ax[3, 0].set_title(\"ACF of Standarized Residuals\")\n",
        "# ax[3, 0].set_ylim([-0.3, 0.3])\n",
        "\n",
        "# # Figure Row 4 Column 2\n",
        "# sm.graphics.tsa.plot_acf(\n",
        "#     (garch11_t_fit.resid / garch11_t_fit.resid.std()) ** 2, lags=20, ax=ax[3, 1]\n",
        "# )\n",
        "# ax[3, 1].set_title(\"ACF of Squared Standarized Residuals\")\n",
        "# ax[3, 1].set_ylim([-0.3, 0.3])\n",
        "\n",
        "# ax[3, 2].axis(\"off\")\n",
        "# fig.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25ed8e3c-5a95-44c2-ad89-a4de8c0bef78",
      "metadata": {
        "id": "25ed8e3c-5a95-44c2-ad89-a4de8c0bef78"
      },
      "outputs": [],
      "source": [
        "# # 20 Steps Ahead Forecast for GARCH(1,1) Model with Student's t White Noise\n",
        "\n",
        "# # set horizon and forecast\n",
        "# horizon = 20\n",
        "# garch_forecast = garch11_t_fit.forecast(\n",
        "#     reindex=False, horizon=horizon, method=\"simulation\"\n",
        "# )\n",
        "\n",
        "# # reindex data\n",
        "# googr = goog_r.copy()\n",
        "# googr.index = list(range(len(goog_r) + 1))\n",
        "\n",
        "# # forecast mean\n",
        "# forc_mean = pd.Series(garch_forecast.mean.dropna().squeeze())\n",
        "# forc_mean.index = list(range(len(googr), len(googr) + horizon))\n",
        "\n",
        "# # volatility forecast\n",
        "# variance_fct = pd.DataFrame(data={\"Forecast\": garch_forecast.variance.values[0]})\n",
        "# variance_fct.index = list(range(len(googr), len(googr) + horizon))\n",
        "# std_fct = [(variance_fct.values[i] * (i + 1)) ** 0.5 for i in range(len(variance_fct))]\n",
        "# volatility_fct = pd.DataFrame(np.sqrt(std_fct))\n",
        "\n",
        "# # upper/lower bands\n",
        "# upper_band = googr.values[-1] * (1.0 + 2 * volatility_fct)\n",
        "# upper_band.index = variance_fct.index\n",
        "# lower_band = googr.values[-1] * (1.0 - 2 * volatility_fct)\n",
        "# lower_band.index = variance_fct.index\n",
        "\n",
        "# # Plot\n",
        "# plt.figure(figsize=(16, 7))\n",
        "# plt.xlim(1400, len(googr) + 21)\n",
        "# plt.ylim(-0.05, 0.05)\n",
        "# googr.plot(ylabel=\"Google Log Return\", title=\"Forecast Volatility\")\n",
        "# plt.plot((upper_band + lower_band) / 2, \"r--\")\n",
        "# plt.fill_between(\n",
        "#     upper_band.index.tolist(),\n",
        "#     upper_band.values.T[0],\n",
        "#     lower_band.values.T[0],\n",
        "#     color=\"orange\",\n",
        "#     alpha=0.5,\n",
        "# )\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df44e2db-dfad-49f8-b48d-bb696a0ab106",
      "metadata": {
        "id": "df44e2db-dfad-49f8-b48d-bb696a0ab106"
      },
      "outputs": [],
      "source": [
        "!pip install arch\n",
        "from arch import arch_model\n",
        "def realized_volatility_daily(series_log_return):\n",
        "    \"\"\"\n",
        "    Get the daily realized volatility which is calculated as the square root\n",
        "    of sum of squares of log returns within a specific window interval\n",
        "    \"\"\"\n",
        "    n = len(series_log_return)\n",
        "    return np.sqrt(np.sum(series_log_return**2)/(n - 1))\n",
        "\n",
        "def realized_mean_daily(series_log_return):\n",
        "    \"\"\"\n",
        "    Get the daily realized volatility which is calculated as the square root\n",
        "    of sum of squares of log returns within a specific window interval\n",
        "    \"\"\"\n",
        "    return series_log_return.mean()\n",
        "\n",
        "\n",
        "\n",
        "INTERVAL_WINDOW = 30\n",
        "n_future = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4183f972-76d0-412e-9e86-cd27510abce0",
      "metadata": {
        "id": "4183f972-76d0-412e-9e86-cd27510abce0"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()\n",
        "mypf['logreturns'] = np.log(mypf['My Portfolio']) - np.log(mypf['My Portfolio'].shift(1))\n",
        "\n",
        "df.index = mypf['logreturns'].index\n",
        "\n",
        "\n",
        "df['TSLA'] = mypf['logreturns']\n",
        "\n",
        "\n",
        "df['vol_current'] = df['TSLA'].rolling(window=INTERVAL_WINDOW)\\\n",
        "                                   .apply(realized_volatility_daily)\n",
        "\n",
        "\n",
        "df['mean_current'] = df['TSLA'].rolling(window=INTERVAL_WINDOW)\\\n",
        "                                   .apply(realized_mean_daily)\n",
        "\n",
        "# GET FORWARD LOOKING REALIZED VOLATILITY\n",
        "df['vol_future'] = df['TSLA'].shift(-n_future)\\\n",
        "                                 .rolling(window=INTERVAL_WINDOW)\\\n",
        "                                 .apply(realized_volatility_daily)\n",
        "\n",
        "\n",
        "df['mean_future'] = df['TSLA'].shift(-n_future)\\\n",
        "                                 .rolling(window=INTERVAL_WINDOW)\\\n",
        "                                 .apply(realized_mean_daily)\n",
        "\n",
        "\n",
        "# PRE-DETERMINE DESIRED TEST & VALIDATION SIZES\n",
        "train_size = np.int(len(mypf['logreturns']) * 0.5)\n",
        "val_size = np.int(len(mypf['logreturns']) * 0.25)\n",
        "test_size = len(mypf['logreturns']) - train_size - val_size\n",
        "\n",
        "split_time_1 = train_size\n",
        "split_time_2 = train_size + val_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9dfc5e2-b859-4ecc-a068-7be894bf6681",
      "metadata": {
        "id": "c9dfc5e2-b859-4ecc-a068-7be894bf6681"
      },
      "outputs": [],
      "source": [
        "val_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2558217-2ee5-413a-af90-09f041c9873e",
      "metadata": {
        "id": "a2558217-2ee5-413a-af90-09f041c9873e"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# GET CORRESPONDING DATETIME INDICES FOR EACH SET\n",
        "train_idx = df.index[:split_time_1]\n",
        "val_idx = df.index[split_time_1:split_time_2]\n",
        "test_idx = df.index[split_time_2:]\n",
        "\n",
        "print(f'TRAINING \\tFrom: {train_idx[0]} \\tto: {train_idx[-1]} \\t{len(train_idx)} days')\n",
        "print(f'VALIDATION \\tFrom: {val_idx[0]} \\tto: {val_idx[-1]} \\t{len(val_idx)} days')\n",
        "print(f'TEST \\t\\tFrom: {test_idx[0]} \\tto: {test_idx[-1]} \\t{len(test_idx)} days')\n",
        "\n",
        "# SPLIT FORWARD VOLATILITY INTO 3 PARTS\n",
        "# (this would be the target)\n",
        "y_train = df.vol_future[train_idx]\n",
        "y_val = df.vol_future[val_idx]\n",
        "y_test = df.vol_future[test_idx]\n",
        "\n",
        "x_train = df.vol_current[train_idx]\n",
        "x_val = df.vol_current[val_idx]\n",
        "x_test = df.vol_current[test_idx]\n",
        "\n",
        "r_train = df['TSLA'][train_idx]\n",
        "r_val = df['TSLA'] [val_idx].dropna(inplace=True, axis=0)\n",
        "r_test = df['TSLA'] [test_idx].dropna(inplace=True, axis=0)\n",
        "\n",
        "print(r_train)\n",
        "\n",
        "np.random.seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "242dcd6b-0a18-4fb8-b838-69e0d940123a",
      "metadata": {
        "id": "242dcd6b-0a18-4fb8-b838-69e0d940123a"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "# GET BACKWARD LOOKING REALIZED VOLATILITY\n",
        "#df['vol_current'] = df.log_returns.rolling(window=INTERVAL_WINDOW)\\\n",
        "#                                   .apply(realized_volatility_daily)\n",
        "\n",
        "\n",
        "# CONVERT TO INDICES\n",
        "\n",
        "\n",
        "gm_1 = arch_model(r_train.dropna(), vol='GARCH', p=1, q=1)\n",
        "result_1 = gm_1.fit(disp='on')\n",
        "print()\n",
        "print(result_1.summary())\n",
        "\n",
        "def scale_tf_cond_vol(model_result):\n",
        "    '''\n",
        "    Scale & Transform Conditional Volatility\n",
        "    Estimated by GARCH Models\n",
        "    '''\n",
        "    # OBTAIN ESTIMATED CONDITIONAL VOLATILITY FROM MODEL RESULT\n",
        "    cond_vol = model_result.conditional_volatility\n",
        "\n",
        "    # INITIATE SCALER\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    # FIT SCALER TO MODEL'S ESTIMATED CONDITIONAL VOLATILITY\n",
        "    scaler = scaler.fit(cond_vol.values.reshape(-1,1))\n",
        "\n",
        "    scaled_cond_vol = transform_volatility_to_scaler(scaler, cond_vol)\n",
        "    return scaler, scaled_cond_vol\n",
        "\n",
        "def transform_volatility_to_scaler(scaler, tf_series):\n",
        "    '''\n",
        "    Transform a series to a fitted scaler\n",
        "    '''\n",
        "    idx = tf_series.index\n",
        "    output = pd.Series(scaler.transform(tf_series.values.reshape(-1,1))[:,0],\n",
        "                       index=idx)\n",
        "    return output\n",
        "\n",
        "# GET VOLATILITY SCALER & SCALED CONDITIONAL VOLATILITY FROM MODEL RESULT\n",
        "scaler_garch, scaled_cond_vol = scale_tf_cond_vol(result_1)\n",
        "\n",
        "# INITIATE SCALER\n",
        "scaler_vol = MinMaxScaler()\n",
        "\n",
        "# FIT SCALER TO CURRENT VOLATILITY IN TRAINING SET\n",
        "scaler_vol = scaler_vol.fit(x_train.values.reshape(-1,1))\n",
        "x_train_scaled = transform_volatility_to_scaler(scaler_vol, x_train)\n",
        "y_train_scaled = transform_volatility_to_scaler(scaler_vol, y_train)\n",
        "\n",
        "# VISUALIZE MODEL'S ESTIMATED CONDITIONAL VOLATILITY\n",
        "# WITH SCALED vol_current CALCULATED ABOVE\n",
        "def viz_cond_vol(cond_vol_series, model_name):\n",
        "    with sns.axes_style(\"darkgrid\"):\n",
        "        fig, ax = plt.subplots(figsize=(18,7))\n",
        "\n",
        "        ax.plot(x_train_scaled, color='blue', lw=2,\n",
        "                label=f'Scaled {INTERVAL_WINDOW}-Day Interval Daily Realized Volatility')\n",
        "        ax.plot(cond_vol_series, color='orange', lw=2,\n",
        "                label=f'Scaled {model_name} Estimated Conditional Volatility')\n",
        "        ax.set_title('Training Set')\n",
        "        plt.legend()\n",
        "        plt.show();\n",
        "\n",
        "viz_cond_vol(scaled_cond_vol, 'GARCH(1,1)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde88eba-7725-488e-85b4-4b166e470d1e",
      "metadata": {
        "id": "bde88eba-7725-488e-85b4-4b166e470d1e"
      },
      "outputs": [],
      "source": [
        "mypf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b87dad0d-328c-49ec-baaa-94b38676cf1b",
      "metadata": {
        "id": "b87dad0d-328c-49ec-baaa-94b38676cf1b"
      },
      "outputs": [],
      "source": [
        "def pct_max_drawdown(df, window=252):\n",
        "    Roll_Max = df.rolling(window, min_periods=1).max()\n",
        "    Daily_Drawdown = df/Roll_Max - 1\n",
        "    Max_Daily_Drawdown = Daily_Drawdown.rolling(window, min_periods=1).min()\n",
        "    return np.min(Max_Daily_Drawdown)*100\n",
        "\n",
        "\n",
        "\n",
        "def OptimizationForAMaxDrawDown(DF):\n",
        "\n",
        "    res = minimize(\n",
        "      max_drawdown(DF),\n",
        "      RandWeights(length),\n",
        "      method = 'SLSQP',\n",
        "      constraints=[{'type':'eq','fun': lambda x: np.sum(x)-1}],\n",
        "      bounds=[(P_BOUND_LO, P_BOUND_HI) for i in range(length)]\n",
        "    )\n",
        "\n",
        "    return res\n",
        "\n",
        "print('Percentage Max Drawdown =', pct_max_drawdown(mypf['My Portfolio']))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d2f2e00-7628-4804-83b2-fb0b0f501eff",
      "metadata": {
        "id": "5d2f2e00-7628-4804-83b2-fb0b0f501eff"
      },
      "outputs": [],
      "source": [
        "# !pip install python-docx\n",
        "\n",
        "# import python-docx\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9ca7138-3eb7-4c37-9753-73478d8bfc3a",
      "metadata": {
        "id": "f9ca7138-3eb7-4c37-9753-73478d8bfc3a"
      },
      "outputs": [],
      "source": [
        "# doc = docx.Document()\n",
        "\n",
        "# mydoc.add_paragraph(\"This is first paragraph of a MS Word file.\")\n",
        "# mydoc.save(\"./MM_Report.docx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93a42a53-3b15-47b8-9c26-311624697148",
      "metadata": {
        "id": "93a42a53-3b15-47b8-9c26-311624697148"
      },
      "source": [
        "### MICROALPHAS TRAINING <a name=\"microalphas\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e456f0e-83b5-4db9-aa38-345ef968deea",
      "metadata": {
        "id": "3e456f0e-83b5-4db9-aa38-345ef968deea"
      },
      "outputs": [],
      "source": [
        "returns = mypf['logreturns']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8450214-5ec8-4198-b00a-c354c697e83e",
      "metadata": {
        "id": "e8450214-5ec8-4198-b00a-c354c697e83e"
      },
      "outputs": [],
      "source": [
        "plt.plot(returns[0:-1], returns[1:], 'o')\n",
        "\n",
        "# Set the title and labels and their sizes\n",
        "plt.title('Current Returns vs Lagged Returns', fontsize=16)\n",
        "plt.axis('equal')\n",
        "plt.xlabel('Current Returns', fontsize=15)\n",
        "plt.ylabel('Lag 1 Returns', fontsize=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "542518f7-25d1-4e1a-a476-5c2966288256",
      "metadata": {
        "id": "542518f7-25d1-4e1a-a476-5c2966288256"
      },
      "outputs": [],
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "# Using the SPY price data from earlier, calculate the returns\n",
        "# Fill invalid data points with zeros\n",
        "a = returns.fillna(0)\n",
        "b = a.shift(-1)\n",
        "plt.plot(a, b, 'o')\n",
        "\n",
        "# Linear regression\n",
        "m = np.polyfit(a.values[:-1], b.values[:-1], 1)\n",
        "xx = a\n",
        "yy = np.polyval(m, xx)\n",
        "plt.plot(xx, yy)\n",
        "plt.grid()\n",
        "\n",
        "# Set the title and labels and their sizes\n",
        "plt.title(f'y = {m[1]:.3f} + {m[0]:.3f}*x', fontsize=16)\n",
        "plt.xlabel('Previous Day Returns', fontsize=14)\n",
        "plt.ylabel('Current Day Returns', fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "print(f\"alpha =\",m[1])\n",
        "print(f\"beta =\",m[0])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "919c8b64-21d1-4573-9ea1-87fce7c9eaa0",
      "metadata": {
        "id": "919c8b64-21d1-4573-9ea1-87fce7c9eaa0"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "# Backtest of autocorrelated strategy\n",
        "# in Pandas. Returns are shifted left to overlap current returns\n",
        "# with past return's direction.\n",
        "(np.sign(a)*a.shift(-1)).cumsum().plot()\n",
        "\n",
        "# Set the title and labels and their sizes\n",
        "plt.title('Strategy Returns', fontsize=16)\n",
        "plt.xlabel('Date', fontsize=14)\n",
        "plt.ylabel('Cumulative Returns', fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "917448b3-4d7a-4b31-99f4-d3ef64c29b34",
      "metadata": {
        "id": "917448b3-4d7a-4b31-99f4-d3ef64c29b34"
      },
      "outputs": [],
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "# Plotting backtest returns\n",
        "plt.plot(a, np.sign(a)*a.shift(-1), 'o')\n",
        "\n",
        "# Correlating backtest returns with market returns\n",
        "m = np.polyfit(a.shift(-1).fillna(0), np.sign(a.fillna(0))\n",
        "               * a.shift(-1).fillna(0), 1)\n",
        "xx = a\n",
        "yy = np.polyval(m, xx)\n",
        "plt.plot(xx, yy)\n",
        "plt.grid()\n",
        "\n",
        "# Set the title and labels and their sizes\n",
        "# Print the regression equation\n",
        "plt.title(f'y = {m[1]:.2f} + {m[0]:.2f}*x', fontsize=16)\n",
        "plt.xlabel('Benchmark Returns', fontsize=14)\n",
        "plt.ylabel('Strategy Returns', fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c66a8db-7471-4491-9b14-c043745103e9",
      "metadata": {
        "id": "4c66a8db-7471-4491-9b14-c043745103e9"
      },
      "outputs": [],
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "# Adding benchmark returns and strategy. Division by 2\n",
        "# because we are dividing the resources\n",
        "strategy = ((a.shift(-1)+np.sign(a)*a.shift(-1)).fillna(0))/2\n",
        "\n",
        "# Plotting the combined strategy\n",
        "(strategy).cumsum().plot(lw=5, label='strategy', legend=True)\n",
        "\n",
        "# Plotting the benchmark (SPY)\n",
        "a.cumsum().plot(label='benchmark', legend=True)\n",
        "\n",
        "# Set the title and labels and their sizes\n",
        "plt.title('Strategy and Benchmark Returns', fontsize=16)\n",
        "plt.xlabel('Date', fontsize=14)\n",
        "plt.ylabel('Returns', fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58ed8f18-423a-405e-8d11-8a8220b75e13",
      "metadata": {
        "id": "58ed8f18-423a-405e-8d11-8a8220b75e13"
      },
      "outputs": [],
      "source": [
        "# Backtesting the autocorrelated data\n",
        "# by multiplying the direction (sign) of returns\n",
        "# from the previous day with today's returns\n",
        "# \"If yesterday's returns are up (down), we expect today's returns to be up (down)\"\n",
        "strategy_returns = np.sign(a[0:-1])*np.array(a[1:])\n",
        "\n",
        "# Set figure size\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "# Plotting the PnL cumulative sum of the returns\n",
        "plt.plot(np.cumsum(strategy_returns))\n",
        "\n",
        "# Set the title and labels and their sizes\n",
        "plt.title('Strategy Returns', fontsize=16)\n",
        "plt.xlabel('Day', fontsize=14)\n",
        "plt.ylabel('Returns', fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d245bac-fda3-4c6f-b1c9-6389aaf0bb3c",
      "metadata": {
        "id": "6d245bac-fda3-4c6f-b1c9-6389aaf0bb3c"
      },
      "outputs": [],
      "source": [
        "\n",
        "rar_strat = np.mean(strategy)/np.std(strategy)*2\n",
        "\n",
        "# Calculating the risk-adjusted return of the benchmark\n",
        "rar_bm = np.mean(a)/np.std(a)*2\n",
        "\n",
        "# Printing the results\n",
        "print(f'Risk Adj Ret Strategy: {rar_strat:.3f}, Benchmark: {rar_bm:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c51b3522-9b88-43d4-bc31-83cb6988a0ec",
      "metadata": {
        "id": "c51b3522-9b88-43d4-bc31-83cb6988a0ec"
      },
      "outputs": [],
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(15, 7))\n",
        "\n",
        "# Enter the weight in the variable \"strategy_weight\"\n",
        "strategy_weight = 0.5\n",
        "buy_hold_weight = 1 - strategy_weight\n",
        "\n",
        "# Adding benchmark returns and strategy. Division by 2\n",
        "# because we are dividing the resources\n",
        "strategy = ((a.shift(-1)*buy_hold_weight+np.sign(a)*a.shift(-1)*strategy_weight).fillna(0))\n",
        "\n",
        "# Plotting the combined strategy\n",
        "(strategy).cumsum().plot(lw=5,label='strategy',legend=True)\n",
        "\n",
        "# Plotting the benchmark (SPY)\n",
        "a.cumsum().plot(label='benchmark',legend=True)\n",
        "\n",
        "# Set the title and labels and their sizes\n",
        "plt.title('Strategy and Benchmark Returns', fontsize=16)\n",
        "plt.xlabel('Date', fontsize=14)\n",
        "plt.ylabel('Returns', fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43cf6f54-62ec-40f1-9876-6d99859fa9a2",
      "metadata": {
        "id": "43cf6f54-62ec-40f1-9876-6d99859fa9a2"
      },
      "source": [
        "### TA-LIB OPERATIONS <a name=\"talib_ops\"></a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a28981f7-5689-4c25-a7f5-25c0aeb260c5",
      "metadata": {
        "id": "a28981f7-5689-4c25-a7f5-25c0aeb260c5"
      },
      "outputs": [],
      "source": [
        "import talib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26863c5c-2923-4849-8cf5-d6232782c518",
      "metadata": {
        "id": "26863c5c-2923-4849-8cf5-d6232782c518"
      },
      "outputs": [],
      "source": [
        "# spy = pd.read_csv(\n",
        "#     '../data_modules/spy_daily_1993_2022.csv', index_col=0)\n",
        "\n",
        "yf_tick = yf.Ticker(\"CANTE.IS\")\n",
        "spy = yf_tick.history(interval='1d', auto_adjust=True, start=T0_START, end=T0_END, back_adjust = True, rounding=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6f6de0b-da68-431c-8ec7-bfb4a9d0cef9",
      "metadata": {
        "id": "a6f6de0b-da68-431c-8ec7-bfb4a9d0cef9"
      },
      "outputs": [],
      "source": [
        "dir(talib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c59b90f9-3064-404f-a099-be291b0e7cb4",
      "metadata": {
        "id": "c59b90f9-3064-404f-a099-be291b0e7cb4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('seaborn-darkgrid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74192831-c58d-43b0-a732-d45b16e32d9a",
      "metadata": {
        "id": "74192831-c58d-43b0-a732-d45b16e32d9a"
      },
      "outputs": [],
      "source": [
        "signals = {}\n",
        "\n",
        "# Looping through all TA-Lib functions\n",
        "for attr in dir(talib):\n",
        "\n",
        "    # Extraction of chart-pattern functions\n",
        "    if attr[:3] == 'CDL':\n",
        "\n",
        "        # Calculation of signals for each chart pattern\n",
        "        res = getattr(talib, attr)(spy.Open, spy.High, spy.Low, spy.Close)\n",
        "\n",
        "        # Appending each signal vector to the signals dict\n",
        "        signals[attr] = res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f88cae1-1269-4b25-a233-6310f71ffe3e",
      "metadata": {
        "id": "2f88cae1-1269-4b25-a233-6310f71ffe3e"
      },
      "outputs": [],
      "source": [
        "# Starting the runtime clock\n",
        "start = datetime.now()\n",
        "\n",
        "# Looping through the signals for each chart pattern\n",
        "for pattern in signals:\n",
        "\n",
        "    # Running the backtest for each chart pattern\n",
        "    # Signals are -100 and +100, normalise with factor 0.01\n",
        "    backtest = (0.01*signals[pattern] *\n",
        "                spy.Close.pct_change().shift(-1)).cumsum()\n",
        "\n",
        "    # Plotting the backtest for chart pattern\n",
        "    ax = backtest.plot(figsize=[15, 15], fontsize=15, legend=False)\n",
        "\n",
        "    # Set the title and labels\n",
        "    ax.set_ylabel('Returns', fontdict={'fontsize': 15})\n",
        "    ax.set_xlabel('Date', fontdict={'fontsize': 15})\n",
        "    ax.set_title('Chart Pattern Returns', fontdict={'fontsize': 15})\n",
        "    ax.legend(pattern)\n",
        "    # ax.plot(lw=5, label='strategy', legend=True)\n",
        "\n",
        "# Print the runtime\n",
        "print(datetime.now()-start)\n",
        "\n",
        "pattern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54fe0376-96c2-4b5f-8716-e357999c92ce",
      "metadata": {
        "id": "54fe0376-96c2-4b5f-8716-e357999c92ce"
      },
      "outputs": [],
      "source": [
        "# Pre-factor is negative because the signal needs to be inverted to be profitable\n",
        "backtest = (-0.01*(signals['CDL3OUTSIDE'])*spy.Close.pct_change().shift(-1))\n",
        "\n",
        "\n",
        "# Plot the backtest for an individual chart pattern\n",
        "ax = backtest.cumsum().plot(figsize=[15, 7], fontsize=15, legend=False)\n",
        "\n",
        "# Set the title and labels\n",
        "ax.set_ylabel('Returns', fontdict={'fontsize': 15})\n",
        "ax.set_xlabel('Date', fontdict={'fontsize': 15})\n",
        "ax.set_title('Chart Pattern Returns', fontdict={'fontsize': 15})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0fa383b-fc54-4aa1-a610-38c126ba5cab",
      "metadata": {
        "id": "a0fa383b-fc54-4aa1-a610-38c126ba5cab"
      },
      "outputs": [],
      "source": [
        "# Pre-factor is negative because the signal needs to be inverted to be profitable\n",
        "backtest = (-0.01*(signals['CDL3OUTSIDE'])*spy.Close.pct_change().shift(-1))\n",
        "\n",
        "# Plot the backtest for an individual chart pattern against the benchmark\n",
        "ax = backtest.cumsum().plot(figsize=[15, 7], title='Chart Pattern Returns vs Benchmark Returns',\n",
        "                            xlabel='Date', ylabel='Returns', fontsize=15, legend=False)\n",
        "((((spy.Close.pct_change()+1).cumprod())-1)/16).plot()\n",
        "\n",
        "# Set the title and labels\n",
        "ax.set_ylabel('Returns', fontdict={'fontsize': 15})\n",
        "ax.set_xlabel('Date', fontdict={'fontsize': 15})\n",
        "ax.set_title('Chart Pattern Returns vs Benchmark Returns',\n",
        "             fontdict={'fontsize': 15})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af15c4c7-a163-4af7-9003-c7a44f875304",
      "metadata": {
        "id": "af15c4c7-a163-4af7-9003-c7a44f875304"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1c435b8a-5768-464d-b354-2d57bea8a796",
      "metadata": {
        "id": "1c435b8a-5768-464d-b354-2d57bea8a796"
      },
      "source": [
        "### SQL OPERATIONS <a name=\"sql_ops\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "784bcd17-1e56-44d4-8e83-6c4ce1a378c8",
      "metadata": {
        "id": "784bcd17-1e56-44d4-8e83-6c4ce1a378c8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "783d88e2-285d-4ab0-9ccb-5e8c67344f5c",
      "metadata": {
        "id": "783d88e2-285d-4ab0-9ccb-5e8c67344f5c"
      },
      "outputs": [],
      "source": [
        "!pip install sqlalchemy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9766389-be4f-40a0-a90c-bb64195b49a3",
      "metadata": {
        "id": "f9766389-be4f-40a0-a90c-bb64195b49a3"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine\n",
        "\n",
        "# create a reference\n",
        "# for sql library\n",
        "engine = create_engine('sqlite://', echo = False)\n",
        "\n",
        "df = pd.DataFrame(SELECTED_EXCHANGE)\n",
        "df.to_sql('SELECTED_EXCHANGE', con = engine)\n",
        "\n",
        "df = pd.DataFrame(stock_list)\n",
        "df.to_sql('stock_list', con = engine)\n",
        "\n",
        "df = pd.DataFrame(MYPF)\n",
        "df.to_sql('MYPF', con = engine)\n",
        "\n",
        "df = pd.DataFrame(IDEALPF)\n",
        "df.to_sql('IDEALPF', con = engine)\n",
        "\n",
        "\n",
        "# show the complete data\n",
        "# from Employee_Data table\n",
        "print(engine.execute(\"SELECT * FROM IDEALPF\").fetchall())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d747d6c-8497-4625-9b90-3369a3f724c2",
      "metadata": {
        "id": "1d747d6c-8497-4625-9b90-3369a3f724c2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffb9beb2-b561-4ab5-871d-6cef2ce7ab91",
      "metadata": {
        "id": "ffb9beb2-b561-4ab5-871d-6cef2ce7ab91"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2f40c26b-cd9f-4f97-a94b-0ab5f5050ae0",
      "metadata": {
        "id": "2f40c26b-cd9f-4f97-a94b-0ab5f5050ae0"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7a97429-d220-4357-bdb8-2b4d75e16f6b",
      "metadata": {
        "id": "e7a97429-d220-4357-bdb8-2b4d75e16f6b"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd8c9726-fdf8-47ab-80f3-0235c7dea24f",
      "metadata": {
        "id": "dd8c9726-fdf8-47ab-80f3-0235c7dea24f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccc0ec13-d916-4345-bdf9-3f127af3c2cd",
      "metadata": {
        "id": "ccc0ec13-d916-4345-bdf9-3f127af3c2cd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cff2ab73-76cd-4730-9654-20b5736b0fb9",
      "metadata": {
        "id": "cff2ab73-76cd-4730-9654-20b5736b0fb9"
      },
      "outputs": [],
      "source": [
        "log_returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2f555f5-0e7d-4118-8407-a062b0eb31aa",
      "metadata": {
        "id": "c2f555f5-0e7d-4118-8407-a062b0eb31aa"
      },
      "outputs": [],
      "source": [
        "# import requests\n",
        "# from bs4 import BeautifulSoup\n",
        "\n",
        "# # Yahoo login URL\n",
        "# login_url = \"https://login.yahoo.com/\"\n",
        "\n",
        "# # Yahoo finance page URL\n",
        "# finance_url = \"https://finance.yahoo.com/portfolios\"\n",
        "\n",
        "# # Your Yahoo login credentials\n",
        "# username = \"alperulku@yahoo.com\"\n",
        "# password = \"khcmukzrsikoccep\"\n",
        "\n",
        "# selector = \"#Col1-0-Portfolios-Proxy > main > table\"\n",
        "\n",
        "# # Create a session to maintain cookies and login information\n",
        "# session = requests.Session()\n",
        "\n",
        "# # Send a POST request to the login URL with your credentials\n",
        "# response = session.post(finance_url, data={'username': username, 'password': password})\n",
        "\n",
        "# # If the login was successful, the server should redirect you to the finance page\n",
        "# if response.url == finance_url:\n",
        "#     print(\"Login successful!\")\n",
        "\n",
        "#     # Now that you are logged in, you can access the finance page\n",
        "#     response = session.get(finance_url)\n",
        "\n",
        "#     # Parse the HTML of the page with Beautiful Soup\n",
        "#     soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "#     # Find the table using the specified selector\n",
        "#     table = soup.select_one('#Col1-0-Portfolios-Proxy > main > table')\n",
        "\n",
        "#     # Print the table HTML\n",
        "#     print(table)\n",
        "\n",
        "# else:\n",
        "#     print(\"Login failed :(\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb87d283-04ea-46e9-bf6d-079e6ca6eb79",
      "metadata": {
        "id": "eb87d283-04ea-46e9-bf6d-079e6ca6eb79"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e69b9902-93da-42d0-ae8b-13cf9a4fc40e",
      "metadata": {
        "id": "e69b9902-93da-42d0-ae8b-13cf9a4fc40e"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aec6db2-a0f5-4bb4-8d7d-0c1724dc96ab",
      "metadata": {
        "id": "7aec6db2-a0f5-4bb4-8d7d-0c1724dc96ab"
      },
      "outputs": [],
      "source": [
        "# import requests\n",
        "# import pandas as pd\n",
        "# from lxml import html\n",
        "# import time\n",
        "\n",
        "# # Yahoo login URL\n",
        "# login_url = \"https://login.yahoo.com/\"\n",
        "\n",
        "# # Yahoo finance page URL\n",
        "# finance_url = \"https://finance.yahoo.com/portfolios\"\n",
        "# # Your Yahoo login credentials\n",
        "# username = \"alperulku@yahoo.com\"\n",
        "# password = \"khcmukzrsikoccep\"\n",
        "\n",
        "# # Create a session to maintain cookies and login information\n",
        "# session = requests.Session()\n",
        "\n",
        "# # Send a POST request to the login URL with your credentials\n",
        "# response = session.post(finance_url, data={'username': username, 'password': password})\n",
        "\n",
        "# # with requests.Session() as s:\n",
        "# #       ...     s.get('https://httpbin.org/get')\n",
        "\n",
        "\n",
        "# # If the login was successful, the server should redirect you to the finance page\n",
        "# if response.url == finance_url:\n",
        "#     print(\"Login successful!\")\n",
        "\n",
        "#     # Now that you are logged in, you can access the finance page\n",
        "#     response = session.get(finance_url)\n",
        "\n",
        "#     # Wait for the page to fully load\n",
        "#     time.sleep(5)\n",
        "\n",
        "#     # Parse the HTML of the page with lxml\n",
        "#     doc = html.fromstring(response.text)\n",
        "\n",
        "#     # Find the table using the specified Xpath\n",
        "#     table_html = doc.xpath('//*[@id=\"Col1-0-Portfolios-Proxy\"]/main/table')\n",
        "\n",
        "#     # If the table was found, convert it to a Pandas dataframe\n",
        "#     if table_html:\n",
        "#         df = pd.read_html(html.tostring(table_html[0]))[0]\n",
        "\n",
        "#         # Display the dataframe\n",
        "#         print(df)\n",
        "\n",
        "#         # Save the dataframe as a CSV file\n",
        "#         df.to_csv('yahoo_portfolio.csv', index=False)\n",
        "#     else:\n",
        "#         print(\"Table not found :(\")\n",
        "\n",
        "# else:\n",
        "#     print(\"Login failed :(\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "618f7d31-f538-479a-9750-8d8ce3ad08f2",
      "metadata": {
        "id": "618f7d31-f538-479a-9750-8d8ce3ad08f2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9afc084c-f7d3-401b-9846-5005f4f321a1",
      "metadata": {
        "id": "9afc084c-f7d3-401b-9846-5005f4f321a1"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fcf38ead-f730-4dd1-b6e7-336b2a36bfdd",
      "metadata": {
        "id": "fcf38ead-f730-4dd1-b6e7-336b2a36bfdd"
      },
      "source": [
        "CHATGPT: info@markovmarkowitz.com\n",
        "13 / 1\n",
        "\n",
        "Act like a expert Python programmer. Write a new python program to: go to page https://finance.yahoo.com/portfolios, press Sign In, type username, press next, type password, press next, wait until the page data is fully refreshed then read the table with CSS Selector = table.W\\(100\\%\\) on the web page \"https://finance.yahoo.com/portfolios\", including the complete data as Portfolio Name, Symbols, Market Value, Day Chg, Day Chg %, Total Chg and Total Chg % columns. Move these data to single dataframe, ignore and delete empty rows, reset the index in the dataframe and save this dataframe as a csv file. Show me comments in your program; show me the most efficient code.\n",
        "\n",
        "(IMPLICIT WAIT COMMANDS ADDED BY ME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b30983bf-3334-4ce1-ab3e-1c0796fe14c9",
      "metadata": {
        "id": "b30983bf-3334-4ce1-ab3e-1c0796fe14c9"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b94a322-5f2f-4e32-9c0d-c0f723c33dca",
      "metadata": {
        "id": "3b94a322-5f2f-4e32-9c0d-c0f723c33dca"
      },
      "outputs": [],
      "source": [
        "# Convert numeric entries to floating point type\n",
        "for i in df.columns:\n",
        "    df[i] = pd.to_numeric(df[i], errors='coerce')\n",
        "\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1a1467b-005a-49a5-8f41-449ea5d66761",
      "metadata": {
        "id": "e1a1467b-005a-49a5-8f41-449ea5d66761"
      },
      "source": [
        "### READ CUSTOMER INFOS FROM EXCEL FILE <a name=\"read_customers\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fd8077f-a300-43af-a285-54c0a49ed6d3",
      "metadata": {
        "tags": [],
        "id": "7fd8077f-a300-43af-a285-54c0a49ed6d3"
      },
      "outputs": [],
      "source": [
        "def generate_dataframe(file):\n",
        "# Read excel file into dataframe\n",
        "    df = pd.read_excel(file, index_col=None, header=0)\n",
        "    df.rename(columns={'Hesap Adı': 'Accrount Name', 'Hesap No': 'Account No', 'Pass': 'Pass', 'Başlangıç PF': 'Entry PF Value', 'Başlangıç Tarihi': 'Entry Date', 'Bitiş Tarihi': 'Last Date', 'Toplam İş Günü': 'Total Workdays', 'Son PF': 'Last PF Value', 'Nakit': 'Cash', 'Toplam PF': 'Total PF Value', 'Toplam % Return': 'Total Percent Return', 'Ave Daily % Return': 'Ave Daily Percent Return', 'PF Revenue': 'PF Revenue', 'PF Commission': 'PF Commission', 'YF Web Site': 'YF Web Site'}, inplace=True)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1786d2c-dd8f-470f-8b22-85ce6b4355ef",
      "metadata": {
        "tags": [],
        "id": "d1786d2c-dd8f-470f-8b22-85ce6b4355ef"
      },
      "outputs": [],
      "source": [
        "\n",
        "Customers_DF = generate_dataframe(\"Müsteriler_MM.xlsx\")\n",
        "Customers_DF\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e771842f-b819-40ae-afab-1a26cbb9f260",
      "metadata": {
        "tags": [],
        "id": "e771842f-b819-40ae-afab-1a26cbb9f260"
      },
      "outputs": [],
      "source": [
        "#Customers_DF.sort_values(by=[\"Last PF Value\"], ascending=[True], inplace = True)\n",
        "#Customers_DF"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4b31988-521e-4959-a077-65d29edb4d22",
      "metadata": {
        "id": "c4b31988-521e-4959-a077-65d29edb4d22"
      },
      "source": [
        "### CHECK IF BANNED ASSETS ARE INSIDE CURRENT PF <a name=\"BAN_CHECK\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da9a6c1a-7cf1-4d2a-9750-e2dd6b1558fc",
      "metadata": {
        "id": "da9a6c1a-7cf1-4d2a-9750-e2dd6b1558fc"
      },
      "outputs": [],
      "source": [
        "def Find_Yasakli(my_list, yasakli_list):\n",
        "    new_list = []\n",
        "    for i in yasakli_list:\n",
        "        if i in my_list:\n",
        "            new_list.append(i)\n",
        "        else:\n",
        "            continue\n",
        "    return flatten(new_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdbd6d83-7d72-4e9a-846f-c9ce1c44ac1f",
      "metadata": {
        "id": "bdbd6d83-7d72-4e9a-846f-c9ce1c44ac1f"
      },
      "outputs": [],
      "source": [
        "# MYPF_Yasakli_Liste = Find_Yasakli(pd.DataFrame(MYPF.index).values,pd.DataFrame(TEDBIRLI_HISSELER).values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec62a90b-ff3e-4764-90c5-327cd838af88",
      "metadata": {
        "id": "ec62a90b-ff3e-4764-90c5-327cd838af88"
      },
      "outputs": [],
      "source": [
        "# MYPF_Yasakli_Liste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a9caba0-fd8f-41bf-8f1c-159c86a2feb7",
      "metadata": {
        "id": "2a9caba0-fd8f-41bf-8f1c-159c86a2feb7"
      },
      "outputs": [],
      "source": [
        "# TEDBIRLI_DF[TEDBIRLI_DF['TEDBİRLİ HİSSE'] == 'RYSAS.IS']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea89e450-61fc-456a-93b7-ab513179d848",
      "metadata": {
        "id": "ea89e450-61fc-456a-93b7-ab513179d848"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a333098b-a697-4f78-82f0-04b3e3a7eb9a",
      "metadata": {
        "tags": [],
        "id": "a333098b-a697-4f78-82f0-04b3e3a7eb9a"
      },
      "source": [
        "### READ ALL PORTFOLIOS FROM YF PAGE <a name=\"read_portfolios\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71ac6ae2-ecf3-4abc-85ea-b97874c6ed8d",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "71ac6ae2-ecf3-4abc-85ea-b97874c6ed8d"
      },
      "outputs": [],
      "source": [
        "#!pip install html5lib\n",
        "# Your Yahoo login credentials\n",
        "\n",
        "# username = \"alperulku@yahoo.com\"\n",
        "# password = \"Cold45War+2+\"\n",
        "# import time\n",
        "# import requests\n",
        "# import pandas as pd\n",
        "# from bs4 import BeautifulSoup\n",
        "# from selenium import webdriver\n",
        "\n",
        "\n",
        "# # Yahoo finance page URL\n",
        "# finance_url = \"https://finance.yahoo.com/portfolios\"\n",
        "\n",
        "\n",
        "# # Use Selenium to automate a web browser\n",
        "# driver = webdriver.Firefox()\n",
        "\n",
        "# # Navigate to the finance page\n",
        "# driver.get(finance_url)\n",
        "\n",
        "# # Find the \"Sign In\" button and click it\n",
        "# sign_in_button = driver.find_element_by_link_text(\"Sign In\")\n",
        "# sign_in_button.click()\n",
        "# time.sleep(5)\n",
        "\n",
        "# # Find the username field and enter your username\n",
        "# username_field = driver.find_element_by_id(\"login-username\")\n",
        "# username_field.send_keys(username)\n",
        "# time.sleep(5)\n",
        "\n",
        "# # Find the \"Next\" button and click it\n",
        "# next_button = driver.find_element_by_id(\"login-signin\")\n",
        "# next_button.click()\n",
        "# time.sleep(5)\n",
        "\n",
        "# # Find the password field and enter your password\n",
        "# password_field = driver.find_element_by_id(\"login-passwd\")\n",
        "# password_field.send_keys(password)\n",
        "# time.sleep(5)\n",
        "\n",
        "# # Find the \"Next\" button and click it\n",
        "# next_button = driver.find_element_by_id(\"login-signin\")\n",
        "# next_button.click()\n",
        "# time.sleep(15)\n",
        "\n",
        "# # Wait for the page to load\n",
        "\n",
        "\n",
        "# # Get the HTML of the page\n",
        "# html = driver.page_source\n",
        "\n",
        "\n",
        "# # Parse the HTML with Beautiful Soup\n",
        "# soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "# # Find the table using the specified CSS selector\n",
        "# table = soup.select_one('table.W\\(100\\%\\)')\n",
        "# time.sleep(10)\n",
        "\n",
        "\n",
        "# ###table = soup.select_one('table.W(100%)')\n",
        "\n",
        "# # Extract the data from the table\n",
        "# data = []\n",
        "# rows = table.find_all('tr')\n",
        "# for row in rows:\n",
        "#     cols = row.find_all('td')\n",
        "#     cols = [ele.text.strip() for ele in cols]\n",
        "#     data.append([ele for ele in cols if ele])\n",
        "\n",
        "# # Create a Pandas dataframe from the extracted data\n",
        "# df = pd.DataFrame(data, columns=['Portfolio Name', 'Symbols', 'Market Value', 'Day Chg', 'Day Chg %', 'Total Chg', 'Total Chg %'])\n",
        "\n",
        "# #drop spaces and NA\n",
        "\n",
        "\n",
        "# # Save the dataframe as a CSV file\n",
        "# df.to_csv(\"YAHOO_PORTFOLIOS.csv\")\n",
        "\n",
        "# print(\"Done!\")\n",
        "\n",
        "# # Print the dataframe\n",
        "\n",
        "\n",
        "# # Close the web browser\n",
        "# driver.close()\n",
        "\n",
        "# # Convert the last four columns to floating point numbers\n",
        "# #df.iloc[:, -4:] = df.iloc[:, -4:].apply(pd.to_numeric)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4446d592-cfa8-4cc7-9c13-71fca3e4c83d",
      "metadata": {
        "id": "4446d592-cfa8-4cc7-9c13-71fca3e4c83d"
      },
      "outputs": [],
      "source": [
        "# df.dropna(inplace=True)\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c21156cf-a16b-48c3-9e49-ee5c46f64815",
      "metadata": {
        "id": "c21156cf-a16b-48c3-9e49-ee5c46f64815"
      },
      "outputs": [],
      "source": [
        "# type(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60411bef-86df-4406-ace5-195dab1a647a",
      "metadata": {
        "id": "60411bef-86df-4406-ace5-195dab1a647a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cee1a94a-ed71-4291-8f64-d992a80a068c",
      "metadata": {
        "id": "cee1a94a-ed71-4291-8f64-d992a80a068c"
      },
      "source": [
        "### STATISTICAL ARBITRAGE ALGO <a name=\"stat_arb\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58bdf497-600b-443c-8198-e9c01ffb7ae4",
      "metadata": {
        "id": "58bdf497-600b-443c-8198-e9c01ffb7ae4"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.stattools import coint\n",
        "\n",
        "\n",
        "TR_ADDITIONS= [\"THYAO.IS\", \"PGSUS.IS\"]\n",
        "\n",
        "\n",
        "yf_tick = yf.Ticker(\"THYAO.IS\")\n",
        "df = yf_tick.history(interval='1d', auto_adjust=True, start=T1_START, end=T1_END, back_adjust = True, rounding=True)\n",
        "#df.dropna(how='all', inplace=True)\n",
        "asset1 = df.Close\n",
        "\n",
        "yf_tick = yf.Ticker(\"PGSUS.IS\")\n",
        "df = yf_tick.history(interval='1d', auto_adjust=True, start=T1_START, end=T1_END, back_adjust = True, rounding=True)\n",
        "#df.dropna(how='all', inplace=True)\n",
        "asset2 = df.Close\n",
        "\n",
        "# Test for cointegration\n",
        "score, pvalue, _ = coint(asset1, asset2)\n",
        "\n",
        "# Check if assets are cointegrated\n",
        "if pvalue < 0.05:\n",
        "    # Calculate the spread between the assets\n",
        "    spread = asset1 - asset2\n",
        "\n",
        "    # Generate a z-score for the spread\n",
        "    mean_spread = spread.mean()\n",
        "    std_spread = spread.std()\n",
        "    z_score = (spread - mean_spread) / std_spread\n",
        "\n",
        "    # Generate BUY/SELL signals based on z-score\n",
        "    signals = np.where(z_score > 2, \"SELL\", np.where(z_score < -2, \"BUY\", \"HOLD\"))\n",
        "    print(\"Assets are cointegrated.\")\n",
        "    print(signals)\n",
        "else:\n",
        "    print(\"Assets are not cointegrated.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbfbca1c-85e9-452f-968f-19e4dd107689",
      "metadata": {
        "id": "fbfbca1c-85e9-452f-968f-19e4dd107689"
      },
      "source": [
        "### STATISTICAL ARBITRAGE ALGO with MULTIPLE ASSETS <a name=\"stat_arb_multiple\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0fc9854-6a69-41fa-8a04-ab6b32945ea2",
      "metadata": {
        "id": "c0fc9854-6a69-41fa-8a04-ab6b32945ea2"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.tsa.stattools import coint\n",
        "from itertools import combinations\n",
        "\n",
        "# Function to get the data for an asset from an exchange\n",
        "def get_data_for_asset(asset_name):\n",
        "    yf_tick = yf.Ticker(asset_name)\n",
        "    df = yf_tick.history(interval='1d', auto_adjust=True, start=T1_START, end=T1_END, back_adjust = True, rounding=True)\n",
        "    #df.dropna(how='all', inplace=True)\n",
        "    return df.Close\n",
        "\n",
        "# Function to test for cointegration and generate signals\n",
        "def pairs_trading(asset_name, data, other_assets):\n",
        "    base_asset = get_data_for_asset(asset_name)\n",
        "\n",
        "    cointegrated_assets = []\n",
        "    for other_asset in other_assets:\n",
        "        score, pvalue, _ = coint(base_asset, get_data_for_asset(other_asset))\n",
        "        if pvalue < 0.05:\n",
        "            cointegrated_assets.append(other_asset)\n",
        "    if cointegrated_assets:\n",
        "        print(f\"Cointegrated assets with {asset_name} are {cointegrated_assets}\")\n",
        "        for coint_asset in cointegrated_assets:\n",
        "            spread = base_asset - get_data_for_asset(coint_asset)\n",
        "            mean_spread = spread.mean()\n",
        "            std_spread = spread.std()\n",
        "            z_score = (spread - mean_spread) / std_spread\n",
        "            signals = np.where(z_score > 2, \"SELL\", np.where(z_score < -2, \"BUY\", \"HOLD\"))\n",
        "            print(f\"BUY/SELL signal for {asset_name} and {coint_asset} is {signals}\")\n",
        "    else:\n",
        "        print(f\"No cointegrated assets found for {asset_name}\")\n",
        "\n",
        "# Get the data for all assets\n",
        "all_assets = [\"KCHOL.IS\", \"SAHOL.IS\", \"THYAO.IS\", \"ASELS.IS\"]\n",
        "# all_assets = [        \"AEFES.IS\",\n",
        "#                       \"ALARK.IS\",\n",
        "#                       \"BTCIM.IS\",\n",
        "#                       \"CLEBI.IS\",\n",
        "#                       \"DGGYO.IS\",\n",
        "#                       \"ESCOM.IS\",\n",
        "#                       \"FRIGO.IS\",\n",
        "#                       \"MARTI.IS\",\n",
        "#                       \"MEPET.IS\",\n",
        "#                       \"METUR.IS\",\n",
        "#                       \"OZKGY.IS\",\n",
        "#                       \"POLHO.IS\",\n",
        "#                       \"QUAGR.IS\",\n",
        "#                       \"SELEC.IS\",\n",
        "#                       \"SONME.IS\",\n",
        "#                       \"TGSAS.IS\",\n",
        "#                       \"THYAO.IS\",\n",
        "#                       \"VAKKO.IS\",\n",
        "#                       \"YAPRK.IS\",\n",
        "#              ]\n",
        "\n",
        "\n",
        "data = {}\n",
        "for asset in all_assets:\n",
        "    data[asset] = get_data_for_asset(asset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39411d02-b835-437b-b770-0fef6419b18c",
      "metadata": {
        "id": "39411d02-b835-437b-b770-0fef6419b18c"
      },
      "outputs": [],
      "source": [
        "# Get all combinations of assets\n",
        "asset_combinations = list(combinations(all_assets, 2))\n",
        "asset_combinations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6619a23-9e7b-4970-9111-fa1cb0213265",
      "metadata": {
        "id": "d6619a23-9e7b-4970-9111-fa1cb0213265"
      },
      "outputs": [],
      "source": [
        "# Test for cointegration and generate signals for each combination\n",
        "for asset_pair in asset_combinations:\n",
        "    pairs_trading(asset_pair[0], data, [asset_pair[1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3295583-09ad-4f54-991f-63d8ffc0b77f",
      "metadata": {
        "id": "d3295583-09ad-4f54-991f-63d8ffc0b77f"
      },
      "outputs": [],
      "source": [
        "# Backtesting loop\n",
        "# initial_capital = 100000\n",
        "# portfolio_value = []\n",
        "# for i in range(len(data[asset_combinations[0][0]])):\n",
        "#     # Reset portfolio value\n",
        "#     portfolio_value.append(initial_capital)\n",
        "#     for asset_pair in asset_combinations:\n",
        "#         signal = pairs_trading(asset_pair[0], data, [asset_pair[1]])\n",
        "#         base_asset_data = data[asset_pair[0]][:i+1]\n",
        "#         coint_asset_data = data[asset_pair[1]][:i+1]\n",
        "#         spread = base_asset_data - coint_asset_data\n",
        "#         mean_spread = spread.mean()\n",
        "#         std_spread = spread.std()\n",
        "#         z_score = (spread - mean_spread) / std_spread\n",
        "#         signal = np.where(z_score > 2, \"SELL\", np.where(z_score < -2, \"BUY\", \"HOLD\"))\n",
        "\n",
        "#         if signal == \"SELL\":\n",
        "#             # Sell base asset and buy cointegrated asset\n",
        "#             shares_base = portfolio_value[-1] / base_asset_data[-1]\n",
        "#             shares_coint = shares_base\n",
        "#             portfolio_value.append(portfolio_value[-1] + shares_coint * coint_asset_data[-1] - shares_base * base_asset_data[-1])\n",
        "#         elif signal == \"BUY\":\n",
        "#             # Buy base asset and sell cointegrated asset\n",
        "#             shares_coint = portfolio_value[-1] / coint_asset_data[-1]\n",
        "#             shares_base = shares_coint\n",
        "#             portfolio_value.append(portfolio_value[-1] + shares_base * base_asset_data[-1] - shares_coint * coint_asset_data[-1])\n",
        "#         else:\n",
        "#             # Hold\n",
        "#             portfolio_value.append(portfolio_value[-1])\n",
        "\n",
        "# # Print final portfolio value\n",
        "# print(f\"Final portfolio value: {portfolio_value[-1]}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a23a6c3c-f53d-48a4-bccd-51182fbb6597",
      "metadata": {
        "id": "a23a6c3c-f53d-48a4-bccd-51182fbb6597"
      },
      "source": [
        "### MARKOV CHAIN MODELLING OF SELECTED ASSET ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49fcae97-99ed-4883-9360-ba5c8f397bcd",
      "metadata": {
        "id": "49fcae97-99ed-4883-9360-ba5c8f397bcd"
      },
      "outputs": [],
      "source": [
        "#!pip install yfinance\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Download historical market data\n",
        "data = yf.download('BIMAS.IS',T1_START,T1_END)\n",
        "# Compute daily returns\n",
        "BIMAS_return = data['Adj Close'].pct_change()\n",
        "#\n",
        "# Compute MArkov Probabilities of current portfolio\n",
        "#ODAS_return  = mypf['ODAS'].pct_change()\n",
        "#QUAGR_return = mypf['QUAGR'].pct_change()\n",
        "#AKSEN_return = mypf['AKSEN'].pct_change()\n",
        "#HEKTS_return = mypf['HEKTS'].pct_change()\n",
        "PORTFOLIO_return = mypf['My Portfolio'].pct_change()\n",
        "XU100_return = mypf['XU100'].pct_change()\n",
        "\n",
        "\n",
        "# Define the states\n",
        "#state_bins = [-np.inf, -0.035, -0.025, -0.015, -0.005, 0,  0.005, 0.015, 0.025, 0.035, np.inf]\n",
        "\n",
        "# Drop the first row since it has a NaN return\n",
        "\n",
        "def PredictNextState(datareturns):\n",
        "    state_bins = [-np.inf, 0, np.inf]\n",
        "    datastate = pd.cut(datareturns, bins=state_bins)\n",
        "    # Calculate the transition matrix\n",
        "    transition_matrix = pd.crosstab(datastate, datastate.shift(-1), normalize='index')\n",
        "    # Print the transition matrix\n",
        "    #print(transition_matrix)\n",
        "    current_state = datastate.iloc[-1]\n",
        "    #next_state = np.random.choice(transition_matrix.columns, p=transition_matrix.loc[current_state].values)\n",
        "    next_state = transition_matrix.loc[current_state].idxmax()\n",
        "    #print(f'Predicted next state: {next_state}')\n",
        "    # Print the probabilities of all states\n",
        "    state_probabilities = datastate.value_counts(normalize=True)\n",
        "    print(\"State probabilities:\")\n",
        "    print(state_probabilities)\n",
        "\n",
        "    return next_state\n",
        "\n",
        "def PredictNextStateProbability(datareturns):\n",
        "    state_bins = [-np.inf, 0, np.inf]\n",
        "    datastate = pd.cut(datareturns, bins=state_bins)\n",
        "    # Calculate the transition matrix\n",
        "    transition_matrix = pd.crosstab(datastate, datastate.shift(-1), normalize='index')\n",
        "    # Print the transition matrix\n",
        "    #print(transition_matrix)\n",
        "    current_state = datastate.iloc[-1]\n",
        "    #next_state = np.random.choice(transition_matrix.columns, p=transition_matrix.loc[current_state].values)\n",
        "    next_state = transition_matrix.loc[current_state].idxmax()\n",
        "    #print(f'Predicted next state: {next_state}')\n",
        "    # Print the probabilities of all states\n",
        "    state_probabilities = datastate.value_counts(normalize=True)\n",
        "    print(\"State probabilities:\")\n",
        "    print(state_probabilities)\n",
        "    return state_probabilities[0]\n",
        "\n",
        "\n",
        "\n",
        "print(\"-------------------------\")\n",
        "print(f\"Portfolio return will be: {PredictNextState(PORTFOLIO_return)}\")\n",
        "print(\"-------------------------\")\n",
        "print(f\"BIMAS return will be: {PredictNextState(BIMAS_return)}\")\n",
        "print(\"-------------------------\")\n",
        "#print(f\"AKSEN return will be: {PredictNextState(AKSEN_return)}\")\n",
        "#print(f\"QUAGR return will be: {PredictNextState(QUAGR_return)}\")\n",
        "#print(f\"HEKTS return will be: {PredictNextState(HEKTS_return)}\")\n",
        "#print(f\"ODAS return will be:  {PredictNextState(ODAS_return)}\")\n",
        "print(f\"XU100 return will be: {PredictNextState(XU100_return)}\")\n",
        "print(\"-------------------------\")\n",
        "BIMAS_return\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5402d19-5e53-45b6-8d2f-d100c212a822",
      "metadata": {
        "id": "b5402d19-5e53-45b6-8d2f-d100c212a822"
      },
      "outputs": [],
      "source": [
        "Final_TEFAS_PF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f83ac48b-abf1-4a75-bfcc-447ee0e24506",
      "metadata": {
        "id": "f83ac48b-abf1-4a75-bfcc-447ee0e24506"
      },
      "outputs": [],
      "source": [
        "#input(f\"End of MPT_{version}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8843d3b1-7463-405b-9564-a96472466a8c",
      "metadata": {
        "id": "8843d3b1-7463-405b-9564-a96472466a8c"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "90c13b7a-1942-4111-b2f3-c91cff2d8133",
      "metadata": {
        "id": "90c13b7a-1942-4111-b2f3-c91cff2d8133"
      },
      "source": [
        "This backtesting code will loop through all the possible combinations of assets, test for cointegration, and generate signals for pairs trading. It will then simulate the trades based on the signals and calculate the final portfolio value. Please note that the code above is just an example and should be adapted to the specific data and requirements of your use case.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af6ad4df-70a5-4c89-abc3-8148aa45e243",
      "metadata": {
        "id": "af6ad4df-70a5-4c89-abc3-8148aa45e243"
      },
      "source": [
        "### GENERATE REPORT IN  PDF FORMAT ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd9f09cd-4b80-4856-9bf4-5deb06e8b2a1",
      "metadata": {
        "id": "cd9f09cd-4b80-4856-9bf4-5deb06e8b2a1"
      },
      "outputs": [],
      "source": [
        "# import sys\n",
        "# !{sys.executable} -m pip install reportlab\n",
        "# EGER YUKLENEMEYEN BIR KUTUPHANE VARSA BU ŞEKİLDE YÜKLE\n",
        "# GPT-4 komutu:\n",
        "# even if I loaded reportlab library by pip it gives error ModuleNotFoundError: No module named 'reportlab'. why can that be ?\n",
        "os.chdir(root)\n",
        "\n",
        "from reportlab.lib.pagesizes import A4, A3\n",
        "from reportlab.platypus import SimpleDocTemplate, PageBreak, Paragraph, Image, Spacer, Frame, PageTemplate, Table, TableStyle\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from reportlab.lib.units import inch\n",
        "from reportlab.lib.enums import TA_CENTER\n",
        "from reportlab.pdfbase import pdfmetrics\n",
        "from reportlab.pdfbase.ttfonts import TTFont\n",
        "from reportlab.lib import colors\n",
        "from reportlab.lib import utils\n",
        "\n",
        "import csv\n",
        "\n",
        "Final_TEFAS_PF.to_csv(filename_statement + \".csv\")\n",
        "# Data from CSV\n",
        "with open(filename_statement + \".csv\", \"r\") as csvfile:\n",
        "    dataTEFAS = list(csv.reader(csvfile))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "style = getSampleStyleSheet()\n",
        "headingStyle = ParagraphStyle('Heading1',\n",
        "                           fontName=\"Helvetica-Bold\",\n",
        "                           fontSize=16,\n",
        "                           parent=style['Heading2'],\n",
        "                           alignment=1,\n",
        "                           spaceAfter=14)\n",
        "\n",
        "\n",
        "# Register a new font that supports Turkish characters\n",
        "pdfmetrics.registerFont(TTFont('Times New Roman Bold Italic', 'Times New Roman Bold Italic.ttf'))\n",
        "\n",
        "\n",
        "# Create a PDF with 'report.pdf' as its name\n",
        "doc = SimpleDocTemplate(f\"MPT_{version}_REPORTLAB.pdf\", pagesize=A4)\n",
        "\n",
        "# Prepare an empty list to store the elements to be added to the PDF\n",
        "elements = []\n",
        "\n",
        "\n",
        "\n",
        "styles = getSampleStyleSheet()\n",
        "# Define a style\n",
        "style_heading1 = styles['Heading1']\n",
        "style_subtitle = styles['Heading2']\n",
        "style_table = styles['Normal']\n",
        "\n",
        "\n",
        "style_normal = styles['Normal']\n",
        "style_normal.fontName = 'Times-Roman'\n",
        "\n",
        "style_title = ParagraphStyle(name=\"CenteredTitle\",\n",
        "                             parent=styles[\"Title\"],\n",
        "                             fontName='Times-Roman',\n",
        "                             fontSize=24,\n",
        "                             leading=32,\n",
        "                             spaceAfter=6,\n",
        "                             alignment=TA_CENTER)\n",
        "\n",
        "# Title Page\n",
        "im = Image('MARKOVMAR5.1.png', 5 * inch, 2 * inch)\n",
        "\n",
        "elements.append(im)\n",
        "\n",
        "elements.append(Paragraph(\"Financial Data Report\", style_title))\n",
        "\n",
        "elements.append(Paragraph(\"\"\"Dear Investor,\n",
        "                          This report is brought to you by Markov Markowitz company's\n",
        "                          AI Portfolio Manager\"\"\", style_normal))\n",
        "\n",
        "# Add a space\n",
        "elements.append(Spacer(1, 12))\n",
        "\n",
        "# Add table to elements\n",
        "\n",
        "elements.append(Spacer(1, 12))\n",
        "3\n",
        "elements.append(Paragraph(\"Executive Summary\", style_heading1))\n",
        "\n",
        "\n",
        "summary_text = \"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "elements.append(Paragraph(summary_text, style_normal))\n",
        "\n",
        "elements.append(Spacer(1, 12))\n",
        "\n",
        "# Introduction\n",
        "intro_text = f\"\"\"\n",
        "1000Portfolios(TM) V{version} AI Portfolio Management System\n",
        "\n",
        "Artificial Intelligence-Based Portfolio Design & Performance Reporting Software\n",
        "\n",
        "Markov Markowitz Company @2022 - 2023\n",
        "\n",
        "Python and Markdown coding: Alper Ülkü\n",
        "\n",
        "\"\"\"\n",
        "elements.append(Paragraph(intro_text, style_normal))\n",
        "\n",
        "# Add a space\n",
        "elements.append(Spacer(1, 12))\n",
        "\n",
        "# List of your image paths\n",
        "images = [\"Fig_001_BIST30_Selected.jpg\",\n",
        "          \"Fig_002_R-R_Map.jpg\",\n",
        "          \"Fig_003_Montecarlo.jpg\",\n",
        "          \"Fig_004_Coorelations.jpg\",\n",
        "          \"Fig_005_RRMAP.jpg\",\n",
        "          \"Fig_006_Ret_Tear_sheet.jpg\",\n",
        "          \"Fig_007_StateSpaceTrend.jpg\"\n",
        "         ]\n",
        "\n",
        "\n",
        "# get the image\n",
        "\n",
        "# Data from CSV\n",
        "\n",
        "\n",
        "# Title Page\n",
        "elements.append(Paragraph(\"Financial Data Report\", style_title))\n",
        "\n",
        "elements.append(Paragraph(\"Summary\", style_heading1))\n",
        "\n",
        "summary_text = \"\"\"\n",
        "    ...  # Existing summary text\n",
        "\"\"\"\n",
        "elements.append(Paragraph(summary_text, style_normal))\n",
        "\n",
        "elements.append(Paragraph(\"Introduction\", style_heading1))\n",
        "\n",
        "\n",
        "text = f\"Merhaba, bugünün {exchange} piyasası için en iyi Sharpe Oranı'na sahip Portföyü ektedir: {filename} \\r\\n\"\n",
        "\n",
        "text+= f\"Forward Test süresi = {FW_TEST_PERIOD} gün \\r\\n\"\n",
        "text+= f\"Backtest Test süresi = {BACKTEST_PERIOD} gün \\r\\n\"\n",
        "\n",
        "text+=\"==== YARIN ICIN TAHMINLERIMIZ =========\\r\\n\"\n",
        "text+=f\"Portfolio return will be: {PredictNextState(PORTFOLIO_return)}\\r\\n\"\n",
        "text+=f\"BIMAS return will be: {PredictNextState(BIMAS_return)}\\r\\n\"\n",
        "# text+=f\"AKSEN return will be: {PredictNextState(AKSEN_return)}\\r\\n\"\n",
        "# text+=f\"QUAGR return will be: {PredictNextState(QUAGR_return)}\\r\\n\"\n",
        "# text+=f\"HEKTS return will be: {PredictNextState(HEKTS_return)}\\r\\n\"\n",
        "# text+=f\"ODAS return will be:  {PredictNextState(ODAS_return)}\\r\\n\"\n",
        "text+=f\"XU100 return will be: {PredictNextState(XU100_return)}\\r\\n\"\n",
        "\n",
        "text+= \"Markov Markowitz, Çankaya, Ankara, Türkiye.\\r\\n\"\n",
        "text+= \"Her hakkı saklıdır. @ Markov Markowitz 2022.\"\n",
        "\n",
        "\n",
        "\n",
        "elements.append(Paragraph(text, style_normal))\n",
        "\n",
        "elements.append(PageBreak())  # start a new page\n",
        "\n",
        "#Add a table\n",
        "table_data = [\n",
        "    ['Column 1', 'Column 2', 'Column 3'],  # Table header\n",
        "    ['Data 1', 'Data 2', 'Data 3'],  # First row\n",
        "    ['Data 4', 'Data 5', 'Data 6'],  # Second row\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "table = Table(table_data)\n",
        "table.setStyle(TableStyle([('BACKGROUND', (0, 0), (-1, 0), colors.gray),\n",
        "                           ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
        "                           ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
        "                           ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
        "                           ('FONTSIZE', (0, 0), (-1, 0), 10),\n",
        "                           ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
        "                           ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n",
        "                           ('GRID', (0, 0), (-1, -1), 1, colors.black)]))\n",
        "#elements.append(table)\n",
        "\n",
        "table = Table(dataTEFAS)\n",
        "table.setStyle(TableStyle([('BACKGROUND', (0, 0), (-1, 0), colors.gray),\n",
        "                           ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
        "                           ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
        "                           ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
        "                           ('FONTSIZE', (0, 0), (-1, 0), 8),\n",
        "                           ('BOTTOMPADDING', (0, 0), (-1, 0), 8),\n",
        "                           ('BACKGROUND', (0, 1), (-1, -1), colors.beige),\n",
        "                           ('GRID', (0, 0), (-1, -1), 1, colors.black)]))\n",
        "elements.append(table)\n",
        "\n",
        "\n",
        "\n",
        "elements.append(Paragraph(\"Conclusion\", style_heading1))\n",
        "conclusion_text = \"\"\"\n",
        "    ...  # Existing conclusion text\n",
        "\"\"\"\n",
        "elements.append(Paragraph(conclusion_text, style_normal))\n",
        "\n",
        "\n",
        "\n",
        "for i, image in enumerate(images):\n",
        "    # Add an image\n",
        "    elements.append(Image(image, 6*inch, 4.5*inch))\n",
        "\n",
        "    # Add a paragraph (image title or caption)\n",
        "    elements.append(Paragraph(f\"<u>Figure {i+1}: {image}</u>\", style_normal))\n",
        "\n",
        "    # You could add more paragraphs for a description of the image here\n",
        "    elements.append(Paragraph(\"Description for figure {}...\".format(i+1), style_normal))\n",
        "\n",
        "    # Add a space\n",
        "    elements.append(Spacer(1, 12))\n",
        "\n",
        "\n",
        "elements.append(PageBreak())  # start a new page\n",
        "\n",
        "# Register a new page template with an A3 frame\n",
        "# frame = Frame(0, 0, A3[0], A3[1])\n",
        "# template = PageTemplate(frames=[frame])\n",
        "# doc.addPageTemplates([template])\n",
        "\n",
        "# # Add the large figure\n",
        "# elements.append(Image(\"Fig_006_Ret_Tear_sheet.jpg\", width=A3[0]-2*inch, height=A3[1]-2*inch))\n",
        "\n",
        "\n",
        "# Conclusion\n",
        "conclusion_text = \"\"\"<para align=center spaceb=3>This report represents a comprehensive\n",
        "overview of the financial analysis performed based on the available data. Further insights\n",
        "can be derived with additional data.</para>\"\"\"\n",
        "elements.append(Paragraph(conclusion_text, style_normal))\n",
        "\n",
        "# def header(canvas, doc):\n",
        "#     logo = utils.ImageReader('Fig_001_BIST30_Selected.jpg')\n",
        "#     #logo = utils.ImageReader('MARKOVMAR5.1.png')\n",
        "#     canvas.saveState()\n",
        "#     canvas.drawImage(logo, 40, 750, width=120, height=80)\n",
        "#     canvas.restoreState()\n",
        "\n",
        "\n",
        "# lista = [Final_TEFAS_PF.index.values.astype(str).tolist()] + Final_TEFAS_PF.values.tolist()\n",
        "# Final_TEFAS_PF = pd.DataFrame(Final_TEFAS_PF)\n",
        "# lista = Final_TEFAS_PF.values.tolist()\n",
        "# #lista = Final_TEFAS_PF.values.tolist()\n",
        "# ts = [('ALIGN', (1,1), (-1,-1), 'CENTER'),\n",
        "#      ('LINEABOVE', (0,0), (-1,0), 1, colors.purple),\n",
        "#      ('LINEBELOW', (0,0), (-1,0), 1, colors.purple),\n",
        "#      ('FONT', (0,0), (-1,0), 'Times-Bold'),\n",
        "#      ('LINEABOVE', (0,-1), (-1,-1), 1, colors.purple),\n",
        "#      ('LINEBELOW', (0,-1), (-1,-1), 0.5, colors.purple, 1, None, None, 4,1),\n",
        "#      ('LINEBELOW', (0,-1), (-1,-1), 1, colors.red),\n",
        "#      ('FONT', (0,-1), (-1,-1), 'Times-Bold'),\n",
        "#      ('BACKGROUND',(1,1),(-2,-2),colors.green),\n",
        "#      ('TEXTCOLOR',(0,0),(1,-1),colors.red)]\n",
        "\n",
        "# table = Table(lista, style=ts)\n",
        "# #table = Table(lista)\n",
        "\n",
        "# elements.append(table)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Build the PDF\n",
        "#doc.build(elements)\n",
        "doc.build(elements)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f510a381-d016-4668-8281-7844ab11a5ba",
      "metadata": {
        "id": "f510a381-d016-4668-8281-7844ab11a5ba"
      },
      "source": [
        "### SEND_EMAIL_THRU_GMAIL <a name=\"SEND_GMAIL\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5cfc5c6-05de-4f60-9021-8a1dd292cedc",
      "metadata": {
        "id": "c5cfc5c6-05de-4f60-9021-8a1dd292cedc"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "\n",
        "UTILITY U=019 : SEND_EMAIL_THRU_GMAIL\n",
        "--------------------------------------------\n",
        "- SETS variables for mail server\n",
        "- SETS database to be emailed\n",
        "- SETS filename to be attached\n",
        "- CHANGES directory for writing the excel file\n",
        "- FORMS the excel file\n",
        "- SETS params for mail and its content with smtp lib\n",
        "- ATTACHES file with mimetypes\n",
        "- SENDS mail to my own gmail address with ssl library\n",
        "\n",
        "'''\n",
        "\n",
        "gmail_pass = \"owypdnplmjxuofwg\" #\"tinvqeuucaczivic\"  #uwyuympejcjvaikg\n",
        "user = \"alperulku1970@gmail.com\"\n",
        "subscribers = \"alperulku1970@gmail.com\"\n",
        "SERVER_ADDRESS = \"smtp.gmail.com\"\n",
        "SERVER_PORT = 587\n",
        "\n",
        "#now = datetime.now()\n",
        "Final_TEFAS_PF['Max Drawdown %'] = np.round(MaxDrawdown, 4)\n",
        "IDEALPF['Max Drawdown'] = np.round(MaxDrawdown, 4)\n",
        "Final_TEFAS_PF.to_csv(filename_statement + \".csv\")\n",
        "filename = filename_statement + \".xlsx\"\n",
        "shopping_list_file = 'ShoppingList.csv'\n",
        "os.chdir(out)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# with pd.ExcelWriter(filename) as writer:  # doctest: +SKIP\n",
        "#     #Final_TEFAS_PF.to_excel(writer, sheet_name = 'Yeni Portföy')\n",
        "#     #df = pd.DataFrame(Kurallar)\n",
        "#     #df.to_excel(writer, sheet_name='Kurallar')\n",
        "#     df = pd.DataFrame(Performance)\n",
        "#     df.to_excel(writer, sheet_name='İdeal PF Performans')\n",
        "#     df = pd.DataFrame(Current_PF)\n",
        "#     df.to_excel(writer, sheet_name='Mevcut PF')\n",
        "#     IDEALPF.to_excel(writer, sheet_name = 'Ideal PF')\n",
        "#     if FW_TEST_PERIOD !=0:\n",
        "#         ShoppingList.to_excel(writer, sheet_name='Fark Alış-Satış Listesi')\n",
        "\n",
        "\n",
        "with pd.ExcelWriter(filename) as writer:  # doctest: +SKIP\n",
        "    #Final_TEFAS_PF.to_excel(writer, sheet_name = 'Yeni Portföy')\n",
        "    #df = pd.DataFrame(Kurallar)\n",
        "    #df.to_excel(writer, sheet_name='Kurallar')\n",
        "    df = pd.DataFrame(Performance)\n",
        "    df.to_excel(writer, sheet_name='İdeal PF Performans')\n",
        "    df = pd.DataFrame(Current_PF)\n",
        "    df.to_excel(writer, sheet_name='Mevcut PF')\n",
        "    IDEALPF.to_excel(writer, sheet_name = 'Ideal PF')\n",
        "    Final_TEFAS_PF.to_excel(writer, sheet_name = 'YF_Ideal PF')\n",
        "    if FW_TEST_PERIOD !=0:\n",
        "        ShoppingList.to_excel(writer, sheet_name='Fark Alış-Satış Listesi')\n",
        "\n",
        "\n",
        "    # worksheet = writer.sheets['Ideal PF']\n",
        "    # worksheet.insert_image('C2','RR_Plot_BIST.png')\n",
        "    # writer.save()\n",
        "\n",
        "\n",
        "import smtplib\n",
        "from email.message import EmailMessage\n",
        "\n",
        "msg = EmailMessage()\n",
        "\n",
        "msg['Subject'] = filename\n",
        "msg['From'] = user\n",
        "msg['To'] = subscribers\n",
        "\n",
        "text = f\"Merhaba, bugünün {exchange} piyasası için en iyi Sharpe Oranı'na sahip Portföyü ektedir: {filename} \\r\\n\"\n",
        "\n",
        "text+= f\"Forward Test süresi = {FW_TEST_PERIOD} gün \\r\\n\"\n",
        "text+= f\"Backtest Test süresi = {BACKTEST_PERIOD} gün \\r\\n\"\n",
        "\n",
        "text+=\"==== YARIN ICIN TAHMINLERIMIZ =========\\r\\n\"\n",
        "text+=f\"Portfolio return will be: {PredictNextState(PORTFOLIO_return)}\\r\\n\"\n",
        "#text+=f\"CANTE return will be: {PredictNextState(CANTE_return)}\\r\\n\"\n",
        "#text+=f\"AKSEN return will be: {PredictNextState(AKSEN_return)}\\r\\n\"\n",
        "#text+=f\"QUAGR return will be: {PredictNextState(QUAGR_return)}\\r\\n\"\n",
        "#text+=f\"HEKTS return will be: {PredictNextState(HEKTS_return)}\\r\\n\"\n",
        "#text+=f\"ODAS return will be:  {PredictNextState(ODAS_return)}\\r\\n\"\n",
        "text+=f\"XU100 return will be: {PredictNextState(XU100_return)}\\r\\n\"\n",
        "\n",
        "text+= \"Markov Markowitz, Çankaya, Ankara, Türkiye.\\r\\n\"\n",
        "text+= \"Her hakkı saklıdır. @ Markov Markowitz 2022.\"\n",
        "\n",
        "\n",
        "msg.set_content(text)\n",
        "\n",
        "import mimetypes\n",
        "\n",
        "#path = f\"/Users/alperulku/Desktop/Masaüstü - Alper’s Mac mini/MY BEST PORTFOLIOS/{filename}\"\n",
        "path = out + \"/\" + filename\n",
        "\n",
        "# Guess the content type based on the file's extension.\n",
        "ctype, encoding = mimetypes.guess_type(path)\n",
        "if ctype is None or encoding is not None:\n",
        "    ctype = 'application/octet-stream'\n",
        "maintype, subtype = ctype.split('/', 1)\n",
        "\n",
        "with open(path, 'rb') as fp:\n",
        "    msg.add_attachment(fp.read(), maintype=maintype, subtype=subtype,\n",
        "                       filename=filename)\n",
        "\n",
        "path = root + \"/\" + \"YF_IDEAL.csv\"\n",
        "with open(path, 'rb') as fp:\n",
        "    msg.add_attachment(fp.read(), maintype=maintype, subtype=subtype,\n",
        "                       filename=\"YF_IDEAL.csv\")\n",
        "\n",
        "\n",
        "path = root + \"/\" + f\"MPT_{version}_REPORTLAB.pdf\"\n",
        "with open(path, 'rb') as fp:\n",
        "    msg.add_attachment(fp.read(), maintype=maintype, subtype=subtype,\n",
        "                       filename=f\"MPT_{version}_REPORTLAB.pdf\")\n",
        "\n",
        "\n",
        "\n",
        "import ssl\n",
        "\n",
        "# Create a SSLContext object with default settings.\n",
        "context = ssl.create_default_context()\n",
        "\n",
        "with smtplib.SMTP(SERVER_ADDRESS, SERVER_PORT) as smtp:\n",
        "    smtp.ehlo()  # Say EHLO to server\n",
        "    smtp.starttls(context=context)  # Puts the connection in TLS mode.\n",
        "    smtp.ehlo()\n",
        "    smtp.login(user, gmail_pass)\n",
        "    smtp.send_message(msg)  # Auto detects the sender and recipient from header\n",
        "\n",
        "print(\"mail sent with success with attachment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c17a6418-581f-454a-9340-c1cafa16c56b",
      "metadata": {
        "id": "c17a6418-581f-454a-9340-c1cafa16c56b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "508ee0ce-294c-464f-8cae-94a5cb074e19",
      "metadata": {
        "id": "508ee0ce-294c-464f-8cae-94a5cb074e19"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7cbaa5b-d54d-46a8-b93e-f8872a392f21",
      "metadata": {
        "id": "a7cbaa5b-d54d-46a8-b93e-f8872a392f21"
      },
      "outputs": [],
      "source": [
        "exchange = BIST30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97351236-df91-41e9-b035-e20ea1cc282b",
      "metadata": {
        "id": "97351236-df91-41e9-b035-e20ea1cc282b"
      },
      "outputs": [],
      "source": [
        "#SELECTED_EXCHANGE = SelectExchange(exchange)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8feba89-50ab-4490-94e3-5a0e5caa4f99",
      "metadata": {
        "id": "c8feba89-50ab-4490-94e3-5a0e5caa4f99"
      },
      "outputs": [],
      "source": [
        "#stock_list = FilterAssetsForSharpe(SELECTED_EXCHANGE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a576e68e-c57d-489b-a268-b8274eb6ea6b",
      "metadata": {
        "id": "a576e68e-c57d-489b-a268-b8274eb6ea6b"
      },
      "outputs": [],
      "source": [
        "# stock_list = AddTRYXToStockList(stock_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58075dbf-2f58-4537-bc2a-23ccf7392e21",
      "metadata": {
        "id": "58075dbf-2f58-4537-bc2a-23ccf7392e21"
      },
      "outputs": [],
      "source": [
        "# type(stock_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5e07f6f-efc0-4a73-87d2-26ff538bbdd5",
      "metadata": {
        "id": "b5e07f6f-efc0-4a73-87d2-26ff538bbdd5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17009374-a5a6-485e-8ef5-caa57a3d5d1b",
      "metadata": {
        "tags": [],
        "id": "17009374-a5a6-485e-8ef5-caa57a3d5d1b"
      },
      "outputs": [],
      "source": [
        "                      # << 1 disinda bir degere sinirlayinca getiri azaliyo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9de88d39-e75b-426f-9a1e-713d0f3ced07",
      "metadata": {
        "tags": [],
        "id": "9de88d39-e75b-426f-9a1e-713d0f3ced07"
      },
      "outputs": [],
      "source": [
        "os.chdir(root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e43645f4-46c0-4868-a65d-23a1c9d974b1",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "e43645f4-46c0-4868-a65d-23a1c9d974b1"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(\"ignore\")\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "nifty_list = pd.read_csv('ind_nifty50list.csv')\n",
        "nifty_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9200d91-92bc-4064-9163-f6c93318f886",
      "metadata": {
        "tags": [],
        "id": "d9200d91-92bc-4064-9163-f6c93318f886"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c7bffb7-aa1f-4137-8537-46fbcb699f84",
      "metadata": {
        "tags": [],
        "id": "3c7bffb7-aa1f-4137-8537-46fbcb699f84"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('nifty_stocks_prices.csv',index_col=0)\n",
        "data.index = pd.to_datetime(data.index)\n",
        "data.tail(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45614e46-f9e4-4d4a-b2dc-c2e33b56329c",
      "metadata": {
        "id": "45614e46-f9e4-4d4a-b2dc-c2e33b56329c"
      },
      "source": [
        "## Daily percentage change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c32e1d4-9bac-47c8-8d9d-189fe84585aa",
      "metadata": {
        "scrolled": true,
        "id": "0c32e1d4-9bac-47c8-8d9d-189fe84585aa"
      },
      "outputs": [],
      "source": [
        "# Calculate the percentage change for each stock\n",
        "data_pct_change = data.pct_change().dropna()\n",
        "data_pct_change.tail(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1c68e06-aa80-4cf8-937c-7bd43ceeaa21",
      "metadata": {
        "tags": [],
        "id": "f1c68e06-aa80-4cf8-937c-7bd43ceeaa21"
      },
      "source": [
        "---\n",
        "## Calculate Beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80ff90da-f2ce-4f82-a5ca-50bff7ffaa46",
      "metadata": {
        "tags": [],
        "id": "80ff90da-f2ce-4f82-a5ca-50bff7ffaa46"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "def calc_beta(y,x):\n",
        "    model = sm.OLS(y,x)\n",
        "    results = model.fit()\n",
        "    return results.params[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b27ad0d7-60be-4780-84e1-24bc8af8e98c",
      "metadata": {
        "tags": [],
        "id": "b27ad0d7-60be-4780-84e1-24bc8af8e98c"
      },
      "outputs": [],
      "source": [
        "beta = pd.DataFrame(index=[0])\n",
        "for ticker in data_pct_change.columns:\n",
        "    beta[ticker] = calc_beta(data_pct_change.loc[:'2017',ticker],data_pct_change.loc[:'2017','^NSEI'])\n",
        "beta = beta.T\n",
        "beta.columns = ['beta']\n",
        "\n",
        "bar_p = beta.plot.bar(figsize=(18,7))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5574d36-9ebe-43df-8dae-c9921dbe39ca",
      "metadata": {
        "id": "d5574d36-9ebe-43df-8dae-c9921dbe39ca"
      },
      "source": [
        "## Alpha 1: Beta < 0.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1819b88f-16b2-4c16-ad3d-963288c10be8",
      "metadata": {
        "id": "1819b88f-16b2-4c16-ad3d-963288c10be8"
      },
      "outputs": [],
      "source": [
        "low_beta = beta[beta.values < 0.7].index\n",
        "low_beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd35483f-d310-4e1f-81d2-c45845bac039",
      "metadata": {
        "id": "dd35483f-d310-4e1f-81d2-c45845bac039"
      },
      "outputs": [],
      "source": [
        "def plot_performance(stock_list, strategy_name):\n",
        "    stk_returns = data_pct_change.loc['2018':, stock_list]\n",
        "    (stk_returns+1).cumprod().plot(figsize=(15,7),legend=\"left\")\n",
        "    plt.title(strategy_name)\n",
        "    plt.show()\n",
        "\n",
        "    nifty = data_pct_change.loc['2018':, '^NSEI']\n",
        "    portfolio = stk_returns.mean(axis=1)\n",
        "    plt.title(strategy_name + ' Portfolio Performance')\n",
        "    (portfolio+1).cumprod().plot(figsize=(15,7),label=strategy_name, color='purple')\n",
        "    (nifty+1).cumprod().plot(figsize=(15,7),label='Nifty', color='blue')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    return portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf230d9e-8341-443d-aa26-e74ff70ca5eb",
      "metadata": {
        "id": "cf230d9e-8341-443d-aa26-e74ff70ca5eb"
      },
      "outputs": [],
      "source": [
        "p = plot_performance(low_beta, 'Low Beta')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "520a05d4-43a2-4ece-85b9-c9ddf002d926",
      "metadata": {
        "id": "520a05d4-43a2-4ece-85b9-c9ddf002d926"
      },
      "source": [
        "---\n",
        "## Alpha 2: ROE > 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f44d0cf9-67ed-4a71-88c2-6d5d5d34fbf5",
      "metadata": {
        "id": "f44d0cf9-67ed-4a71-88c2-6d5d5d34fbf5"
      },
      "outputs": [],
      "source": [
        "high_roe = nifty_list[nifty_list.ROE>18].Symbol.values\n",
        "high_roe\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7707748-961f-44d2-9442-d552b0670455",
      "metadata": {
        "id": "c7707748-961f-44d2-9442-d552b0670455"
      },
      "outputs": [],
      "source": [
        "filtered_stocks = low_beta & high_roe\n",
        "filtered_stocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98be899b-9539-403b-a9ac-bbe4ba00e73c",
      "metadata": {
        "id": "98be899b-9539-403b-a9ac-bbe4ba00e73c"
      },
      "outputs": [],
      "source": [
        "portfolio = plot_performance(filtered_stocks, 'Low Beta & High ROE')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e2d93c1-052f-4f06-8388-369ff3a3d6ed",
      "metadata": {
        "id": "3e2d93c1-052f-4f06-8388-369ff3a3d6ed"
      },
      "source": [
        "<div class=\"alert alert-block alert-danger\">\n",
        "    <b>Pro Tip</b>: Don't try to over optimize the beta and ROE threshold as it will lead to overfitting and reduce the predictive value of your strategy.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "056b9130-ba29-4535-a953-8db78b8b21bf",
      "metadata": {
        "id": "056b9130-ba29-4535-a953-8db78b8b21bf"
      },
      "source": [
        "---\n",
        "## Detailed Performance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2feff4fe-e2f8-4027-91a2-f5eb021f6bf8",
      "metadata": {
        "id": "2feff4fe-e2f8-4027-91a2-f5eb021f6bf8"
      },
      "outputs": [],
      "source": [
        "import pyfolio as pf\n",
        "pf.create_simple_tear_sheet(portfolio,benchmark_rets=data_pct_change.loc['2018':, '^NSEI'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6db26c93-d54a-4703-9eda-ab8c8dff6807",
      "metadata": {
        "id": "6db26c93-d54a-4703-9eda-ab8c8dff6807"
      },
      "source": [
        "<div class=\"alert alert-block alert-success\">\n",
        "    <h2> Further Improvements </h2><BR>\n",
        "    1. Rebalance the portfolio on monthly or quarterly basis.<BR>\n",
        "    2. Backtest the strategy on different markets such as US equities, local equities, bond markets.<BR>\n",
        "    3. Add more fundamental factors such as ROCE, Debt to Equity to include good quality stocks in your portfolio.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ccd3a00-7586-4ce0-87ab-09a392719ab7",
      "metadata": {
        "id": "4ccd3a00-7586-4ce0-87ab-09a392719ab7"
      },
      "source": [
        "## References\n",
        "1. [Betting Against Beta](https://www.sciencedirect.com/science/article/pii/S0304405X13002675)\n",
        "2. [Quality Minus Junk](https://link.springer.com/article/10.1007/s11142-018-9470-2)\n",
        "2. Nifty50 Historical Constituents Data: [Market cap and Weightage Report](https://www1.nseindia.com/products/content/equities/indices/archieve_indices.htm)\n",
        "3. Screener.in\n",
        "<BR><BR>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a81d42bf-834c-439d-b335-c0dcfcf52552",
      "metadata": {
        "id": "a81d42bf-834c-439d-b335-c0dcfcf52552"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbe91550-897a-4bad-aff4-dc4dca69e5d5",
      "metadata": {
        "id": "fbe91550-897a-4bad-aff4-dc4dca69e5d5"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import lxml\n",
        "from lxml import html\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "symbol = 'BIMAS.IS'\n",
        "\n",
        "url = 'https://finance.yahoo.com/quote/' + symbol + '/balance-sheet?p=' + symbol\n",
        "\n",
        "# Set up the request headers that we're going to use, to simulate\n",
        "# a request by the Chrome browser. Simulating a request from a browser\n",
        "# is generally good practice when building a scraper\n",
        "headers = {\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',\n",
        "    'Accept-Encoding': 'gzip, deflate, br',\n",
        "    'Accept-Language': 'en-US,en;q=0.9',\n",
        "    'Cache-Control': 'max-age=0',\n",
        "    'Connection': 'close',\n",
        "    'DNT': '1', # Do Not Track Request Header\n",
        "    'Pragma': 'no-cache',\n",
        "    'Referrer': 'https://google.com',\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'\n",
        "}\n",
        "\n",
        "# Fetch the page that we're going to parse, using the request headers\n",
        "# defined above\n",
        "page = requests.get(url, headers=headers)\n",
        "\n",
        "# Parse the page with LXML, so that we can start doing some XPATH queries\n",
        "# to extract the data that we want\n",
        "tree = html.fromstring(page.content)\n",
        "\n",
        "# Smoke test that we fetched the page by fetching and displaying the H1 element\n",
        "tree.xpath(\"//h1/text()\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "695bcb8f-ecfb-4071-80c2-724637a286ac",
      "metadata": {
        "id": "695bcb8f-ecfb-4071-80c2-724637a286ac"
      },
      "outputs": [],
      "source": [
        "table_rows = tree.xpath(\"//div[contains(@class, 'D(tbr)')]\")\n",
        "\n",
        "# Ensure that some table rows are found; if none are found, then it's possible\n",
        "# that Yahoo Finance has changed their page layout, or have detected\n",
        "# that you're scraping the page.\n",
        "assert len(table_rows) > 0\n",
        "\n",
        "parsed_rows = []\n",
        "\n",
        "for table_row in table_rows:\n",
        "    parsed_row = []\n",
        "    el = table_row.xpath(\"./div\")\n",
        "\n",
        "    none_count = 0\n",
        "\n",
        "    for rs in el:\n",
        "        try:\n",
        "            (text,) = rs.xpath('.//span/text()[1]')\n",
        "            parsed_row.append(text)\n",
        "        except ValueError:\n",
        "            parsed_row.append(np.NaN)\n",
        "            none_count += 1\n",
        "\n",
        "    if (none_count < 4):\n",
        "        parsed_rows.append(parsed_row)\n",
        "\n",
        "df = pd.DataFrame(parsed_rows)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6f6af2c-0007-4461-905a-e9e6a06f069c",
      "metadata": {
        "id": "e6f6af2c-0007-4461-905a-e9e6a06f069c"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(parsed_rows)\n",
        "df = df.set_index(0) # Set the index to the first column: 'Period Ending'.\n",
        "df = df.transpose() # Transpose the DataFrame, so that our header contains the account names\n",
        "\n",
        "# Rename the \"Breakdown\" column to \"Date\"\n",
        "cols = list(df.columns)\n",
        "cols[0] = 'Date'\n",
        "df = df.set_axis(cols, axis='columns', inplace=False)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07f4bad2-4b40-4e11-a7e8-9ecf6996e9d7",
      "metadata": {
        "id": "07f4bad2-4b40-4e11-a7e8-9ecf6996e9d7"
      },
      "outputs": [],
      "source": [
        "numeric_columns = list(df.columns)[1::] # Take all columns, except the first (which is the 'Date' column)\n",
        "\n",
        "for column_name in numeric_columns:\n",
        "    df[column_name] = df[column_name].str.replace(',', '') # Remove the thousands separator\n",
        "    df[column_name] = df[column_name].astype(np.float64) # Convert the column to float64\n",
        "\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a764f08-94bf-4406-ac10-2878449ffaea",
      "metadata": {
        "id": "3a764f08-94bf-4406-ac10-2878449ffaea"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import lxml\n",
        "from lxml import html\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def get_page(url):\n",
        "    # Set up the request headers that we're going to use, to simulate\n",
        "    # a request by the Chrome browser. Simulating a request from a browser\n",
        "    # is generally good practice when building a scraper\n",
        "    headers = {\n",
        "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3',\n",
        "        'Accept-Encoding': 'gzip, deflate, br',\n",
        "        'Accept-Language': 'en-US,en;q=0.9',\n",
        "        'Cache-Control': 'max-age=0',\n",
        "        'Connection': 'close',\n",
        "        'DNT': '1', # Do Not Track Request Header\n",
        "        'Pragma': 'no-cache',\n",
        "        'Referrer': 'https://google.com',\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'\n",
        "    }\n",
        "\n",
        "    return requests.get(url, headers=headers)\n",
        "\n",
        "def parse_rows(table_rows):\n",
        "    parsed_rows = []\n",
        "\n",
        "    for table_row in table_rows:\n",
        "        parsed_row = []\n",
        "        el = table_row.xpath(\"./div\")\n",
        "\n",
        "        none_count = 0\n",
        "\n",
        "        for rs in el:\n",
        "            try:\n",
        "                (text,) = rs.xpath('.//span/text()[1]')\n",
        "                parsed_row.append(text)\n",
        "            except ValueError:\n",
        "                parsed_row.append(np.NaN)\n",
        "                none_count += 1\n",
        "\n",
        "        if (none_count < 4):\n",
        "            parsed_rows.append(parsed_row)\n",
        "\n",
        "    return pd.DataFrame(parsed_rows)\n",
        "\n",
        "def clean_data(df):\n",
        "    df = df.set_index(0) # Set the index to the first column: 'Period Ending'.\n",
        "    df = df.transpose() # Transpose the DataFrame, so that our header contains the account names\n",
        "\n",
        "    # Rename the \"Breakdown\" column to \"Date\"\n",
        "    cols = list(df.columns)\n",
        "    cols[0] = 'Date'\n",
        "    df = df.set_axis(cols, axis='columns', inplace=False)\n",
        "\n",
        "    numeric_columns = list(df.columns)[1::] # Take all columns, except the first (which is the 'Date' column)\n",
        "\n",
        "    for column_index in range(1, len(df.columns)): # Take all columns, except the first (which is the 'Date' column)\n",
        "        df.iloc[:,column_index] = df.iloc[:,column_index].str.replace(',', '') # Remove the thousands separator\n",
        "        df.iloc[:,column_index] = df.iloc[:,column_index].astype(np.float64) # Convert the column to float64\n",
        "\n",
        "    return df\n",
        "\n",
        "def scrape_table(url):\n",
        "    # Fetch the page that we're going to parse\n",
        "    page = get_page(url);\n",
        "\n",
        "    # Parse the page with LXML, so that we can start doing some XPATH queries\n",
        "    # to extract the data that we want\n",
        "    tree = html.fromstring(page.content)\n",
        "\n",
        "    # Fetch all div elements which have class 'D(tbr)'\n",
        "    table_rows = tree.xpath(\"//div[contains(@class, 'D(tbr)')]\")\n",
        "\n",
        "    # Ensure that some table rows are found; if none are found, then it's possible\n",
        "    # that Yahoo Finance has changed their page layout, or have detected\n",
        "    # that you're scraping the page.\n",
        "    assert len(table_rows) > 0\n",
        "\n",
        "    df = parse_rows(table_rows)\n",
        "    df = clean_data(df)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b20f6b3-c57f-4660-875c-16531ec30109",
      "metadata": {
        "id": "1b20f6b3-c57f-4660-875c-16531ec30109"
      },
      "outputs": [],
      "source": [
        "df_income=scrape_table('https://finance.yahoo.com/quote/' + symbol + '/financials?p=' + symbol)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c54de524-0671-422b-9c12-bfa2072ba35f",
      "metadata": {
        "id": "c54de524-0671-422b-9c12-bfa2072ba35f"
      },
      "outputs": [],
      "source": [
        "df_income"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a6e7e09-a9e6-4829-ae81-4722ba93463d",
      "metadata": {
        "id": "3a6e7e09-a9e6-4829-ae81-4722ba93463d"
      },
      "outputs": [],
      "source": [
        "df_income.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6fc43a0-cee0-4ac6-8f40-6b9867b759ca",
      "metadata": {
        "id": "f6fc43a0-cee0-4ac6-8f40-6b9867b759ca"
      },
      "outputs": [],
      "source": [
        "BS_analysis = df# copy columns of dataframe\n",
        "BS_analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fd06cc1-d30d-47b6-be5b-aab5b101b8e6",
      "metadata": {
        "id": "2fd06cc1-d30d-47b6-be5b-aab5b101b8e6"
      },
      "source": [
        "## Working Capital Per Dollar of Sales = Working Capital ÷ Total Sales\n",
        "Total Sales is from Income Statement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a049373-f2c1-4472-927b-c0b330119777",
      "metadata": {
        "id": "8a049373-f2c1-4472-927b-c0b330119777"
      },
      "outputs": [],
      "source": [
        "current_assets = BS_analysis['Total Assets']\n",
        "current_liabilities = BS_analysis['Total Liabilities Net Minority Interest']\n",
        "working_capital = current_assets - current_liabilities\n",
        "working_capital\n",
        "total_sales = df_income['Total Revenue']\n",
        "working_capital_per_dollar_of_sales = working_capital / total_sales\n",
        "BS_analysis['Working Capital per Dollar of Sales'] = working_capital # copy columns of dataframe\n",
        "BS_analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af5be76b-346a-47be-af10-a16f68263f1b",
      "metadata": {
        "id": "af5be76b-346a-47be-af10-a16f68263f1b"
      },
      "source": [
        "## Current Ratio = Current Assets ÷ Current Liabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "565ba6a9-5e85-461c-bb18-19cc86db2875",
      "metadata": {
        "id": "565ba6a9-5e85-461c-bb18-19cc86db2875"
      },
      "outputs": [],
      "source": [
        "current_ratio = current_assets / current_liabilities\n",
        "BS_analysis['Current Ratio'] = current_ratio\n",
        "BS_analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e63bcaf-703c-4082-8d78-1704599b1dc7",
      "metadata": {
        "id": "6e63bcaf-703c-4082-8d78-1704599b1dc7"
      },
      "source": [
        "## debt-to-equity ratio = total liabilities ÷ shareholders' equity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b466d7f7-c9e0-4c26-998f-5bd1f4307cbb",
      "metadata": {
        "id": "b466d7f7-c9e0-4c26-998f-5bd1f4307cbb"
      },
      "outputs": [],
      "source": [
        "total_liabilities = df['Total Liabilities Net Minority Interest']\n",
        "shareholders_equity = df['Common Stock Equity']\n",
        "debt2equity_ratio = total_liabilities / shareholders_equity\n",
        "BS_analysis['Debt to Equity Ratio'] = debt2equity_ratio\n",
        "BS_analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a5a9637-eb5f-40b7-b26d-0365e0bfe727",
      "metadata": {
        "id": "3a5a9637-eb5f-40b7-b26d-0365e0bfe727"
      },
      "source": [
        "## Receivable Turnover = Net Credit Sales ÷ Average Net Receivables for the Period\n",
        "Net Credit Sales is from Income Statement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22cc30e2-b0fc-4828-b8f3-87ae6fc71e0e",
      "metadata": {
        "id": "22cc30e2-b0fc-4828-b8f3-87ae6fc71e0e"
      },
      "outputs": [],
      "source": [
        "net_credit_sales = df_income['Net Income from Continuing Operation Net Minority Interest']\n",
        "average_net_receivables_for_the_period = df['Tangible Book Value']\n",
        "receivable_turnover = net_credit_sales / average_net_receivables_for_the_period\n",
        "BS_analysis['Receivable Turnover'] = receivable_turnover\n",
        "BS_analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8bd3c41-1de4-4b86-b681-76f561d2e1a4",
      "metadata": {
        "id": "a8bd3c41-1de4-4b86-b681-76f561d2e1a4"
      },
      "source": [
        "## You can calculate any financial ratios with formulae\n",
        "\n",
        "Thanks for looking into the Notebook:)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbf8f221-3259-4214-a5fc-80fe29568ea7",
      "metadata": {
        "id": "bbf8f221-3259-4214-a5fc-80fe29568ea7"
      },
      "outputs": [],
      "source": [
        "def ConvertTimeSeriesToReturns(pf_data):\n",
        "\n",
        "    log_returns = np.log(pf_data/pf_data.shift(1))\n",
        "    return log_returns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "353421de-47dc-4094-9474-ecf1f1017fd4",
      "metadata": {
        "id": "353421de-47dc-4094-9474-ecf1f1017fd4"
      },
      "outputs": [],
      "source": [
        "def ConvertTimeseriesToUSD(p):\n",
        "\n",
        "    print(\"Converting data to USD...\")\n",
        "    print(70*'=')\n",
        "\n",
        "    # new_names = []\n",
        "    # for i in stock_list:\n",
        "    #     sl = i.split('.',maxsplit = 1)\n",
        "    #     new_names.append(sl[0])\n",
        "    # for i in new_names:\n",
        "    #         if i != 'GC=F' and i != 'CL=F':\n",
        "    #             p[i] = pd.Series(p[i] / p['TRY=X'])\n",
        "    for i in p.columns :\n",
        "        p[i] = pd.Series(p[i] / p['TRY=X'])\n",
        "        # p = p[i].astype(float)/p[\"TRY=X\"].astype(float)\n",
        "\n",
        "    return p\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b062949e-bf12-494b-a7c6-11f13873f039",
      "metadata": {
        "id": "b062949e-bf12-494b-a7c6-11f13873f039"
      },
      "source": [
        "## MARKOV PROCESS FOR INDIVIDUAL STOCK RETURN ANALYSIS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e4115f7-51be-4c3f-8410-4c71a336e42b",
      "metadata": {
        "id": "9e4115f7-51be-4c3f-8410-4c71a336e42b"
      },
      "outputs": [],
      "source": [
        "\n",
        "stock = yf.download('EUPWR.IS',T0_START,T0_END)['Adj Close']\n",
        "usdtry = yf.download('TRY=X',T0_START,T0_END)['Adj Close']\n",
        "\n",
        "for i in np.arange(0,len(stock)):\n",
        "    stock[i] = stock[i]/usdtry[i]\n",
        "\n",
        "\n",
        "p = np.round(PredictNextStateProbability(stock.pct_change()),4)\n",
        "p\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "318a6fc2-b663-4fbd-b0d5-b50fea4995ad",
      "metadata": {
        "id": "318a6fc2-b663-4fbd-b0d5-b50fea4995ad"
      },
      "outputs": [],
      "source": [
        "# LIBRARIES WE USE IN THE NOTEBOOK\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy.random import rand, seed\n",
        "from scipy.stats import norm\n",
        "# seed random number generator\n",
        "seed(12345)\n",
        "\n",
        "\n",
        "TARGET_PURSE = 110\n",
        "INIT_PURSE = 100\n",
        "\n",
        "N_STATES = TARGET_PURSE + 1\n",
        "\n",
        "S = np.zeros((N_STATES, 1))\n",
        "P = np.zeros((N_STATES, N_STATES))\n",
        "\n",
        "P[0, 0] = 1.0\n",
        "P[N_STATES - 1, N_STATES - 1] = 1.0\n",
        "\n",
        "for ii in range(1, N_STATES - 1):\n",
        "    for jj in range(0, N_STATES):\n",
        "        if jj == ii - 1 :\n",
        "          P[ii, jj] = (1-p)\n",
        "        if jj == ii + 1 :\n",
        "          P[ii, jj] = p\n",
        "\n",
        "print(\"Transition matrix:\\n\", np.round(P,2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d72b2638-0db6-4a4c-8e8a-f5e7ea8971f8",
      "metadata": {
        "id": "d72b2638-0db6-4a4c-8e8a-f5e7ea8971f8"
      },
      "outputs": [],
      "source": [
        "N_HISTORIES = 10000  # number of histories or simulations\n",
        "LEN_HIST = 100  # Length of each simulation\n",
        "histories = np.zeros((N_HISTORIES, LEN_HIST))\n",
        "histories[:, 0] = INIT_PURSE * np.ones(N_HISTORIES)\n",
        "randarray = rand(N_HISTORIES, LEN_HIST)\n",
        "\n",
        "for i in range(0, N_HISTORIES):\n",
        "    for j in range(1, LEN_HIST):\n",
        "        histories[i, j] = (\n",
        "            histories[i, j - 1] + (randarray[i, j] >= 1-p) - (randarray[i, j] < 1-p)\n",
        "        )\n",
        "        if histories[i, j] == TARGET_PURSE or histories[i, j] < 1:\n",
        "            histories[i, j + 1 : LEN_HIST + 1] = histories[i, j]  # noQA E203\n",
        "            break\n",
        "\n",
        "target_num = np.sum(np.max(histories, axis=1) == TARGET_PURSE)\n",
        "\n",
        "end_gamble = np.zeros(N_HISTORIES)\n",
        "end_gamble_sum = 0\n",
        "\n",
        "for i in range(0, N_HISTORIES):\n",
        "    if np.max(histories[i, :]) == TARGET_PURSE:\n",
        "        where_gamble_ends_T = np.where((histories[i, :] == TARGET_PURSE))\n",
        "        end_gamble[i] = where_gamble_ends_T[0][0]\n",
        "        end_gamble_sum += 1\n",
        "    elif np.min(histories[i, :]) < 1:\n",
        "        where_gamble_ends_0 = np.where((histories[i, :] < 1))\n",
        "        end_gamble[i] = where_gamble_ends_0[0][0]\n",
        "        end_gamble_sum += 1\n",
        "    else:\n",
        "        end_gamble[i] = 0.0\n",
        "\n",
        "broke_num = np.sum(np.min(histories, axis=1) < 1)\n",
        "\n",
        "print(\n",
        "    \"Probability of getting the target:\",\n",
        "    target_num / N_HISTORIES,\n",
        "    \"\\nProbability of losing all the money:\",\n",
        "    broke_num / N_HISTORIES,\n",
        ")\n",
        "print(\n",
        "    \"Expected time until reaching a stopping result:\",\n",
        "    np.sum(end_gamble) / end_gamble_sum,\n",
        "    \" days.\\nTotal number of simulations:\",\n",
        "    end_gamble_sum,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95671ce5-8929-44f2-b6bd-b3857480f129",
      "metadata": {
        "id": "95671ce5-8929-44f2-b6bd-b3857480f129"
      },
      "outputs": [],
      "source": [
        "#input(\"Sonuna geldik\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8520e0d-672b-48aa-964e-433338f4c225",
      "metadata": {
        "id": "a8520e0d-672b-48aa-964e-433338f4c225"
      },
      "outputs": [],
      "source": [
        "def GetTransitionProbability(ticker, start, end):\n",
        "    stock = yf.download(ticker,start,end)['Adj Close']\n",
        "    usdtry = yf.download('TRY=X',start,end)['Adj Close']\n",
        "    for i in np.arange(0,len(stock)):\n",
        "        stock[i] = stock[i]/usdtry[i]\n",
        "    rets = stock.pct_change()\n",
        "    mean = 100*np.round(rets.mean(),4)\n",
        "    p = np.round(PredictNextStateProbability(rets),4)\n",
        "    return p,mean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5099e504-9c4d-452e-87a1-639acc8fecd2",
      "metadata": {
        "id": "5099e504-9c4d-452e-87a1-639acc8fecd2"
      },
      "outputs": [],
      "source": [
        "stock_list = ['THYAO.IS', 'EUPWR.IS', \"CANTE.IS\", \"QUAGR.IS\",  'KRDMD.IS']\n",
        "for tick in stock_list:\n",
        "    print(\"---------------------------------------------\")\n",
        "    p,m = GetTransitionProbability(tick, T0_START, T0_END);\n",
        "    print(f\"\\nticker={tick}, Tr.Prob.= {p}, MeanR= {m}% \")\n",
        "    print(\"---------------------------------------------\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b700a76-1bec-4423-ac0a-4518f0fc3867",
      "metadata": {
        "id": "9b700a76-1bec-4423-ac0a-4518f0fc3867"
      },
      "source": [
        "MARKOV REGIME CHANGE DETECTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fb772c9-ac0a-4082-973b-5de6d37d1cc3",
      "metadata": {
        "id": "2fb772c9-ac0a-4082-973b-5de6d37d1cc3"
      },
      "outputs": [],
      "source": [
        "!pip3 install statsmodels\n",
        "!pip3 install pmdarima\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "from pandas_datareader import data as pdr\n",
        "import yfinance as yf\n",
        "from scipy.stats import norm\n",
        "yf.pdr_override()\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import statsmodels.tsa\n",
        "from pmdarima.arima import auto_arima\n",
        "\n",
        "\n",
        "START = '2019-01-01'\n",
        "END = '2022-12-31'\n",
        "\n",
        "aapl = pdr.get_data_yahoo(\"AAPL\", start= START, end=END)\n",
        "btcusd = pdr.get_data_yahoo(\"BTC-USD\", start=START, end=END)\n",
        "tsla = pdr.get_data_yahoo(\"TSLA\", start=START, end=END)\n",
        "vix = pdr.get_data_yahoo(\"^VIX\", start=START, end=END)\n",
        "\n",
        "aapl_close = aapl['Adj Close']\n",
        "aapl_log_returns = aapl_close.pct_change().apply(lambda x: np.log(1+x))\n",
        "print(aapl_log_returns)\n",
        "\n",
        "btcusd_close = btcusd['Adj Close']\n",
        "btcusd_log_returns = btcusd_close.pct_change().apply(lambda x: np.log(1+x))\n",
        "print(btcusd_log_returns)\n",
        "\n",
        "tsla_close = tsla['Adj Close']\n",
        "tsla_log_returns = tsla_close.pct_change().apply(lambda x: np.log(1+x))\n",
        "print(tsla_log_returns)\n",
        "\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df[\"aapl\"] = aapl_log_returns\n",
        "df[\"btc\"] = btcusd_log_returns\n",
        "df[\"tsla\"] = tsla_log_returns\n",
        "df[\"vix\"] = vix['Adj Close']\n",
        "\n",
        "\n",
        "window = 10 # mean days for calculating volatility\n",
        "\n",
        "# defining volatility for each log returns data\n",
        "df[\"aapl.vlt\"] = df[\"aapl\"].rolling(window).std()*(252**0.5)\n",
        "df[\"btc.vlt\"] = df[\"btc\"].rolling(window).std()*(252**0.5)\n",
        "df[\"tsla.vlt\"] = df[\"tsla\"].rolling(window).std()*(252**0.5)\n",
        "df[\"vix.vlt\"] = df[\"vix\"]/100\n",
        "\n",
        "print(df)\n",
        "\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(aapl_close)\n",
        "plt.title(\"AAPL time series\")\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(df[\"aapl\"])\n",
        "plt.title(\"AAPL returns time series\")\n",
        "\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(df[\"aapl.vlt\"])\n",
        "\n",
        "plt.title(\"AAPL volatility time series\")\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(16, 11)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e08229d-360b-4b0e-880b-4265b4cba8ec",
      "metadata": {
        "id": "0e08229d-360b-4b0e-880b-4265b4cba8ec"
      },
      "outputs": [],
      "source": [
        "# Estimation of model with changes in volatility regimes\n",
        "\n",
        "# Estimation of model with changes in volatility regimes\n",
        "# Build function that performs the E step\n",
        "# Likelihood of an observation\n",
        "\n",
        "\n",
        "def likelihood(xi_prob, mu, sigma, y):\n",
        "    phi = norm.pdf((y - mu) / sigma)\n",
        "    y_like = np.dot(xi_prob, phi)\n",
        "\n",
        "    return y_like\n",
        "\n",
        "\n",
        "# Hamilton filtering\n",
        "def forward_alg(pi_hat0, N, T, P, mu, sigma, Y):\n",
        "    xi_prob_t = np.zeros((T, N))\n",
        "    xi_prob_t1 = np.zeros((T, N))\n",
        "\n",
        "    # Case t=1\n",
        "    y_like = likelihood(pi_hat0, mu, sigma, Y[0])\n",
        "    for ss in range(0, N):\n",
        "        phi = np.zeros((N))\n",
        "        for ss2 in range(0, N):\n",
        "            phi[ss2] = norm.pdf((Y[0] - mu[ss2]) / sigma[ss2])\n",
        "    xi_prob_t[0, :] = np.multiply(pi_hat0, phi) / y_like\n",
        "    for ss in range(0, N):\n",
        "        xi_prob_t1[0, ss] = np.dot(P[:, ss], xi_prob_t[0, :])\n",
        "\n",
        "    for tt in range(1, T):\n",
        "        y_like = likelihood(xi_prob_t1[tt - 1, :], mu, sigma, Y[tt])\n",
        "        for ss in range(0, N):\n",
        "            phi = np.zeros((N))\n",
        "            for ss2 in range(0, N):\n",
        "                phi[ss2] = norm.pdf((Y[tt] - mu[ss2]) / sigma[ss2])\n",
        "        xi_prob_t[tt, :] = np.multiply(xi_prob_t1[tt - 1, :], phi) / y_like\n",
        "        for ss in range(0, N):\n",
        "            xi_prob_t1[tt, ss] = np.dot(P[:, ss], xi_prob_t[tt, :])\n",
        "\n",
        "    return xi_prob_t, xi_prob_t1\n",
        "\n",
        "\n",
        "# Kim filtering\n",
        "def backward_alg(xi_prob_t, xi_prob_t1, N, T, P, mu, sigma, Y):\n",
        "    xi_prob_T = np.zeros((T, N))\n",
        "    xi_prob_T[T - 1, :] = xi_prob_t[T - 1, :]\n",
        "\n",
        "    for tt in range(T - 2, -1, -1):\n",
        "        xi_T_xi = np.divide(xi_prob_T[tt + 1, :], xi_prob_t1[tt, :])\n",
        "        for ss in range(0, N):\n",
        "            xi_prob_T[tt, ss] = xi_prob_t[tt, ss] * np.dot(P[ss, :], xi_T_xi)\n",
        "\n",
        "    return xi_prob_T  # , xi_prob_T1\n",
        "\n",
        "\n",
        "def M_step_func(xi_prob, P, N, T, Y):  #\n",
        "    mu_hat = np.zeros((N))\n",
        "    sigma_hat = np.zeros((N))\n",
        "    P_hat = np.zeros((N, N))\n",
        "    pi_hat = np.zeros((N))\n",
        "\n",
        "    for ss in range(0, N):\n",
        "        xi_y = np.dot(xi_prob[:, ss], Y)\n",
        "        mu_hat[ss] = xi_y / np.sum(xi_prob[:, ss])\n",
        "\n",
        "        xi_y_mu2 = np.dot(xi_prob[:, ss], (Y - mu_hat[ss]) ** 2)\n",
        "        sigma_hat[ss] = (xi_y_mu2 / np.sum(xi_prob[:, ss])) ** 0.5\n",
        "\n",
        "        for ss2 in range(0, N):\n",
        "            P_hat[ss, ss2] = np.sum(P[ss, ss2, 1:]) / np.sum(\n",
        "                P[ss, :, 1:]\n",
        "            )  # /np.sum(xi_prob[0:T-1,ss]) #np.sum(P[ss,:,1:T])\n",
        "            # print( np.sum(xi_prob[0:T-1,ss]), np.sum(P[ss,:,1:T]))\n",
        "\n",
        "        pi_hat[ss] = xi_prob[0, ss]\n",
        "\n",
        "    return mu_hat, sigma_hat, P_hat, pi_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "658ac1a2-6664-4258-9bd3-883fc7ff20d1",
      "metadata": {
        "id": "658ac1a2-6664-4258-9bd3-883fc7ff20d1"
      },
      "outputs": [],
      "source": [
        "## Read data for VIX\n",
        "print (vix)\n",
        "YDatapd = vix['Adj Close']\n",
        "\n",
        "YData = YDatapd.to_numpy()\n",
        "YData = np.log(YData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0bf84fc-b18e-4a80-869d-cf6915e40402",
      "metadata": {
        "id": "a0bf84fc-b18e-4a80-869d-cf6915e40402"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Initialize parameters\n",
        "T = len(YData)\n",
        "N = 3\n",
        "\n",
        "# SET INITIAL GUESSES\n",
        "\n",
        "mu_hat0 = [2.5, 3, 3.5] * np.ones((N))\n",
        "sigma_hat0 = [0.3, 0.4, 0.5] * np.ones((N))\n",
        "P_hat0 = np.zeros((N, N))\n",
        "\n",
        "P_hat0[0, 0] = 0.85\n",
        "P_hat0[0, 1] = (1 - P_hat0[0, 0])/2\n",
        "P_hat0[0, 2] = (1 - P_hat0[0, 0])/2\n",
        "\n",
        "P_hat0[1, 1] = 0.90\n",
        "P_hat0[1, 0] = (1 - P_hat0[1, 1])/2\n",
        "P_hat0[1, 2] = (1 - P_hat0[1, 1])/2\n",
        "\n",
        "P_hat0[2, 2] = 0.70\n",
        "P_hat0[2, 0] = (1 - P_hat0[2, 2])/2\n",
        "P_hat0[2, 1] = (1 - P_hat0[2, 2])/2\n",
        "\n",
        "\n",
        "\n",
        "pi_hat0 = [0.5, 0.25, 0.25] * np.ones((N))\n",
        "for t in range(1, 100):\n",
        "    pi_hat0 = np.dot(P_hat0.T, pi_hat0)\n",
        "\n",
        "# Determine maximum number of iterations until convergence and convergence tolerance\n",
        "itemax = 100\n",
        "itetol = 1e-2\n",
        "\n",
        "for ite in range(0, itemax):\n",
        "    #print(mu_hat0, sigma_hat0, P_hat0, pi_hat0)\n",
        "    print(f\"\\nmu_hat0 = {np.round(mu_hat0,4)}, \\nsigma_hat0 = {np.round(sigma_hat0,4)}, \\nP_hat0 = \\n{np.round(P_hat0,4)}, \\npi_hat0 = {np.round(pi_hat0,4)}\")\n",
        "\n",
        "    # E-step\n",
        "    xi_prob_t, xi_prob_t1 = forward_alg(\n",
        "        pi_hat0, N, T, P_hat0, mu_hat0, sigma_hat0, YData\n",
        "    )\n",
        "    xi_prob_T = backward_alg(\n",
        "        xi_prob_t, xi_prob_t1, N, T, P_hat0, mu_hat0, sigma_hat0, YData\n",
        "    )\n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "    plt.subplot(4, 1, 1)\n",
        "    plt.plot(YData)\n",
        "    plt.subplot(4, 1, 2)\n",
        "    plt.plot(xi_prob_T[:, 0])\n",
        "    plt.subplot(4, 1, 3)\n",
        "    plt.plot(xi_prob_T[:, 1])\n",
        "    plt.subplot(4, 1, 4)\n",
        "    plt.plot(xi_prob_T[:, 2])\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(16, 11)\n",
        "    plt.show()\n",
        "    print(\"\")\n",
        "\n",
        "    # Compute Pr(s_t+1 = j, s_t = i)\n",
        "    P_hat_T = np.zeros((N, N, T))\n",
        "    for tt in range(1, T):\n",
        "        for ss in range(0, N):\n",
        "            for ss2 in range(0, N):\n",
        "                P_hat_T[ss, ss2, tt] = (\n",
        "                    P_hat0[ss, ss2]\n",
        "                    * xi_prob_t[tt - 1, ss]\n",
        "                    * xi_prob_T[tt, ss2]\n",
        "                    / xi_prob_t1[tt - 1, ss2]\n",
        "                )\n",
        "    # M-step\n",
        "    mu_hat1, sigma_hat1, P_hat1, pi_hat1 = M_step_func(xi_prob_T, P_hat_T, N, T, YData)\n",
        "\n",
        "    diff = np.zeros((4))\n",
        "    diff[0] = np.sum(np.absolute(mu_hat1 - mu_hat0)) / (np.min(mu_hat0) + itetol * 1e-2)\n",
        "    diff[1] = np.sum(np.absolute(sigma_hat1 - sigma_hat0)) / (\n",
        "        np.min(sigma_hat0) + itetol * 1e-2\n",
        "    )\n",
        "    diff[2] = np.sum(np.absolute(np.subtract(P_hat1, P_hat0))) / (\n",
        "        np.min(P_hat0) + itetol * 1e-2\n",
        "    )\n",
        "    diff[3] = np.sum(np.absolute(pi_hat1 - pi_hat0)) / (np.min(pi_hat0) + itetol * 1e-2)\n",
        "\n",
        "    print(f\"ite={ite}, max(diff) = {np.max(diff)}\")\n",
        "\n",
        "    if np.max(diff) > itetol:\n",
        "        mu_hat0, sigma_hat0, P_hat0, pi_hat0 = mu_hat1, sigma_hat1, P_hat1, pi_hat1\n",
        "    else:\n",
        "        print(f\"\\nmu_hat1 = {np.round(mu_hat1,4)}, \\nsigma_hat1 = {np.round(sigma_hat1,4)}, \\nP_hat1 = \\n{np.round(P_hat1,4)}, \\npi_hat1 = {np.round(pi_hat1,4)}\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d47c5ce6-48eb-446e-82d0-d1254a666b0f",
      "metadata": {
        "id": "d47c5ce6-48eb-446e-82d0-d1254a666b0f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}