{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarkovMarkowitz/MarkovMarkowitz/blob/main/ON_Trading_Strategy_Functions_v7_Markov_Probabilities.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia1DEDPuVS4b",
        "outputId": "5a51f12a-8f5c-412b-daab-faf8b4c5b6ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyfolio in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (7.34.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (1.5.3)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (2022.7.1)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (1.2.2)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (0.12.2)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from pyfolio) (0.5.5)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.10/dist-packages (from empyrical>=0.5.0->pyfolio) (0.10.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (0.19.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=3.2.3->pyfolio) (4.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->pyfolio) (2.8.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.16.1->pyfolio) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.16.1->pyfolio) (3.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio) (0.8.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (4.9.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2.31.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=3.2.3->pyfolio) (0.2.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->pyfolio) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pyfolio\n",
        "!pip install datetime\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ih7-VamUZ4qc"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQK6fotMVYtJ"
      },
      "source": [
        "# Notebook Instructions\n",
        "\n",
        "1. If you are new to Jupyter notebooks, please go through this introductory manual <a href='https://quantra.quantinsti.com/quantra-notebook' target=\"_blank\">here</a>.\n",
        "1. Any changes made in this notebook would be lost after you close the browser window. **You can download the notebook to save your work on your PC.**\n",
        "1. Before running this notebook on your local PC:<br>\n",
        "i.  You need to set up a Python environment and the relevant packages on your local PC. To do so, go through the section on \"**Run Codes Locally on Your Machine**\" in the course.<br>\n",
        "ii. You need to **download the zip file available in the last unit** of this course. The zip file contains the data files and/or python modules that might be required to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9nKTtg-wv5c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas_datareader.data as web\n",
        "from datetime import datetime\n",
        "from pprint import pprint\n",
        "import pandas as pd\n",
        "\n",
        "import datetime\n",
        "import pyfolio as pyf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "current_date = datetime.datetime.now()\n",
        "\n",
        "delta = 1\n",
        "# day = current_date.day\n",
        "# month = current_date.month\n",
        "# year = current_date.year - delta\n",
        "day = 8\n",
        "month = 8\n",
        "year = 2022\n",
        "\n",
        "START = f'{year}-{month}-{day}'\n",
        "END = f'{year+delta}-{month}-{day}'\n",
        "\n",
        "TARGET_RETURN = 0.00\n",
        "VOLATILITY_FACTOR = 0.45\n",
        "R_WINDOW = 32\n",
        "REVERSED = True\n",
        "LEFT, RIGHT = datetime.date(year, month, day), datetime.date(year+delta, month, day)\n",
        "\n",
        "Ticker = \"EREGL\"    # EREGL, ASELS, KCHOL THYAO ak≈üam al sabah sata uygun\n",
        "TickerIS = Ticker + \".IS\"\n",
        "\n",
        "TR_Tickers = [\"EREGL\", \"CANTE\", \"GARAN\", \"KCHOL\", \"EUPWR\"]\n",
        "US_Tickers = [\"TSLA\", \"AAPL\", \"GOOGL\", \"BA\", \"V\"]\n",
        "DOW30 = [\"AXP\",\"AMGN\",\"AAPL\",\"BA\",\"CAT\",\"CSCO\",\"CVX\",\"GS\",\"HD\",\"HON\",\"IBM\",\"JNJ\",\"KO\",\"JPM\",\n",
        "         \"MCD\",\"MMM\",\"MRK\",\"MSFT\",\"NKE\",\"PG\",\"TRV\",\"UNH\",\"CRM\",\"VZ\",\"V\",\"WBA\",\"WMT\",\"DIS\",\"DOW\"]\n",
        "\n",
        "BIST30 = [\"AKBNK\",\"ALARK\",\"ARCLK\",\"ASELS\",\"BIMAS\",\"EKGYO\",\"ENKAI\",\"EREGL\",\"FROTO\",\"GARAN\",\n",
        "          \"GUBRF\",\"HEKTS\",\"ISCTR\",\"KOZAA\",\"KOZAL\",\"KRDMD\",\"ODAS\",\"PETKM\",\"PGSUS\",\"SAHOL\",\"SASA\",\n",
        "          \"SISE\",\"TAVHL\",\"TCELL\",\"THYAO\",\"TOASO\",\"TUPRS\",\"YKBNK\",\"EUPWR\"]\n",
        "\n",
        "BIST100 = [\"AKBNK\",\"ALARK\",\"ARCLK\",\"ASELS\",\"BIMAS\",\"EKGYO\",\"ENKAI\",\"EREGL\",\"FROTO\",\"GARAN\",\n",
        "          \"GUBRF\",\"HEKTS\",\"ISCTR\",\"KOZAA\",\"KOZAL\",\"KRDMD\",\"ODAS\",\"PETKM\",\"PGSUS\",\"SAHOL\",\"SASA\",\n",
        "          \"SISE\",\"TAVHL\",\"TCELL\",\"THYAO\",\"TOASO\",\"TUPRS\",\"YKBNK\",\n",
        "          \"AEFES\",\"AGHOL\",\"AHGAZ\",\"AKCNS\",\"AKFGY\",\"AKSA\",\"AKSEN\",\n",
        "           \"ALBRK\",\"ASUZU\",\"AYDEM\",\"BAGFS\",\"BERA\",\n",
        "           \"BRSAN\",\"BRYAT\",\"BUCIM\",\"CANTE\",\"CCOLA\",\"CEMTS\",\"CIMSA\",\n",
        "           \"DOAS\",\"DOHOL\",\"ECILC\",\"ECZYT\",\"EGEEN\",\"ENJSA\",\n",
        "           \"GENIL\",\"GESAN\",\"GLYHO\",\"GSDHO\",\"GWIND\",\"HALKB\",\"IPEKE\",\n",
        "           \"ISDMR\",\"ISGYO\",\"ISMEN\",\"IZMDC\",\"KARSN\",\"KMPUR\",\n",
        "           \"KONTR\",\"KONYA\",\"KORDS\",\"KZBGY\",\"MAVI\",\"OTKAR\",\"OYAKC\",\n",
        "           \"PENTA\",\"QUAGR\",\"SELEC\",\"SKBNK\",\"SMRTG\",\n",
        "           \"SNGYO\",\"SOKM\",\"TAVHL\",\"TKFEN\",\"TKNSA\",\"TOASO\",\"TSKB\",\n",
        "           \"TTKOM\",\"TTRAK\",\"TUKAS\",\"ULKER\",\"VAKBN\",\"VESBE\",\"ZOREN\",\n",
        "           \"EUPWR\"]\n",
        "\n",
        "\n",
        "sp_url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
        "\n",
        "sp500_constituents = pd.read_html(sp_url, header=0)[0]\n",
        "sp500_constituents = sp500_constituents[sp500_constituents.Symbol != \"BRK.B\"]\n",
        "sp500_constituents = sp500_constituents[sp500_constituents.Symbol != \"BF.B\"]\n",
        "\n",
        "sp500_constituents.Symbol\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mvd8f-g7Cmuz"
      },
      "outputs": [],
      "source": [
        "def ConvertToUSD(ticker, start, end, exchange):\n",
        "\n",
        "    adjclose = yf.download(ticker,start,end)['Adj Close']\n",
        "    close = yf.download(ticker,start,end)['Close']\n",
        "    open = yf.download(ticker,start,end)['Open']\n",
        "\n",
        "    adjusted_factor = adjclose / close\n",
        "    adjopen = adjusted_factor * open\n",
        "\n",
        "    usdtry = yf.download('TRY=X',start,end)['Adj Close']\n",
        "\n",
        "    if ( exchange != \"SP500\" or exchange != \"DOW30\"):\n",
        "      for i in np.arange(0,len(close)):\n",
        "          adjclose[i] = close[i]/usdtry[i]\n",
        "          adjopen[i] = open[i]/usdtry[i]\n",
        "\n",
        "    rets = adjclose.pct_change()\n",
        "\n",
        "    return adjclose, adjopen, rets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa8x3mz3VZuT"
      },
      "outputs": [],
      "source": [
        "def UpdateData(TickerIS, START, END, exchange):\n",
        "\n",
        "  # For data manupulations\n",
        "\n",
        "  # VF    LB    PEAK_CUM  CUM_LAST    REVERSED\n",
        "  # 0.25  45    6.11       4.29 OK    True\n",
        "  # 0.35  45    7.42       5.02 OK    True\n",
        "  # 0.40  45    7.64       5.17 OK    True\n",
        "  # 0.45  45    8.99       6.16 OK    True\n",
        "  # 0.45  45    1.22       1.05 OK    False\n",
        "  # 0.45  55    7.97       5.39 OK    True\n",
        "  # 0.45  40    9.35       6.31 OK    True\n",
        "  # 0.45  35    9.65       7.14 OK    True\n",
        "  # 0.45  33    9.78       7.24 OK    True  ***\n",
        "  # 0.45  32    10.02      7.42 OK    True  ****\n",
        "  # 0.45  30    9.16       6.78 OK    True\n",
        "  # 0.45  25    8.19       5.98 OK    True\n",
        "  # -   -       5.17       4.82 OK    True / original Gap up buy side.\n",
        "\n",
        "  # Read data from Yahoo finance\n",
        "\n",
        "  data = yf.download(TickerIS,START, END)\n",
        "  # Convert index into datetime format\n",
        "  data.index = pd.to_datetime(data.index,format=\"%d-%m-%Y\")\n",
        "  # Calculate adjustment factor\n",
        "\n",
        "  if ( exchange != \"SP500\" or exchange != \"DOW30\"):\n",
        "    # In Turkish exchange\n",
        "      data['Adj Close'], data['Adj Open'], data['rets'] = ConvertToUSD(TickerIS, START, END, \"BIST\")\n",
        "  else:\n",
        "    # In US exchange\n",
        "      data['Adj Close'], data['Adj Open'], data['rets'] = ConvertToUSD(TickerIS, START, END, \"DOW30\")\n",
        "\n",
        "  data['returns'] = (data['Adj Open'] - data['Adj Close'].shift(1)) / data['Adj Close'].shift(1)\n",
        "  data['std'] = data['returns'].rolling(R_WINDOW).std()\n",
        "  data['positions'] = np.nan\n",
        "  data['close']= data['Adj Close']\n",
        "  data[\"log_returns\"] = data['close'].pct_change().apply(lambda x: np.log(1+x))\n",
        "  data[\"rel\"]= data['Adj Close'] / data['Adj Close'][0]\n",
        "\n",
        "  # Long entry condition\n",
        "  if REVERSED:\n",
        "      long_entry = data['returns'] < VOLATILITY_FACTOR  * data['std']\n",
        "      short_entry = data['returns'] >= VOLATILITY_FACTOR  * data['std']\n",
        "  else:\n",
        "  # Short entry condition\n",
        "      long_entry = data['returns'] >= VOLATILITY_FACTOR  * data['std']\n",
        "      short_entry = data['returns'] < VOLATILITY_FACTOR  * data['std']\n",
        "\n",
        "  # Store 1 when long entry condition is true\n",
        "  data.loc[long_entry, 'positions'] = 1\n",
        "  data.loc[short_entry, 'positions'] = 0\n",
        "\n",
        "  data['positions'].fillna(method='ffill', inplace=True)\n",
        "  data['strategy_returns'] = ((data['Adj Close'] - data['Adj Open']) / data['Adj Open']) * data.positions\n",
        "  data['cumulative_strategy_returns'] = (data.strategy_returns+1).cumprod()\n",
        "  data['cumulative_normal_returns'] = (data.returns+1).cumprod()\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCppA4pzAUyu"
      },
      "outputs": [],
      "source": [
        "# #GAP UP-GAP DOWN STRATEGY\n",
        "\n",
        "# # Long entry condition\n",
        "# long_entry = data['Adj Open'] > data['Adj Close'].shift(1)\n",
        "\n",
        "# # Short entry condition\n",
        "# short_entry = data['Adj Open'] < data['Adj Close'].shift(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEBR-ALlVuDa"
      },
      "outputs": [],
      "source": [
        "# IMPROVED STRATEGY\n",
        "def Strategy(data):\n",
        "  global VOLATILITY_FACTOR\n",
        "  # Long entry condition\n",
        "  if REVERSED:\n",
        "    long_entry = data['returns'] < VOLATILITY_FACTOR  * data['std']\n",
        "    short_entry = data['returns'] >= VOLATILITY_FACTOR  * data['std']\n",
        "  else:\n",
        "  # Short entry condition\n",
        "    long_entry = data['returns'] >= VOLATILITY_FACTOR  * data['std']\n",
        "    short_entry = data['returns'] < VOLATILITY_FACTOR  * data['std']\n",
        "  # Store 1 when long entry condition is true\n",
        "  data.loc[long_entry, 'positions'] = 1\n",
        "\n",
        "  # Store -1 when short entry condition is true\n",
        "  # data.loc[short_entry, 'positions'] = -1\n",
        "\n",
        "  # Store 0 when wait condition is true\n",
        "  data.loc[short_entry, 'positions'] = 0\n",
        "\n",
        "  data['positions'].fillna(method='ffill', inplace=True)\n",
        "  return data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7Xb_DDb3DMk"
      },
      "outputs": [],
      "source": [
        "# IMPROVED STRATEGY\n",
        "def Volatility_Strategy_USD_TR(data):\n",
        "  global VOLATILITY_FACTOR\n",
        "  # Long entry condition\n",
        "  if REVERSED:\n",
        "    long_entry = data['returns'] < VOLATILITY_FACTOR  * data['std']\n",
        "    short_entry = data['returns'] >= VOLATILITY_FACTOR  * data['std']\n",
        "  else:\n",
        "  # Short entry condition\n",
        "    long_entry = data['returns'] >= VOLATILITY_FACTOR  * data['std']\n",
        "    short_entry = data['returns'] < VOLATILITY_FACTOR  * data['std']\n",
        "  # Store 1 when long entry condition is true\n",
        "\n",
        "  data.loc[long_entry, 'positions'] = 1\n",
        "\n",
        "  # Store -1 when short entry condition is true\n",
        "  data.loc[short_entry, 'positions'] = -1\n",
        "\n",
        "  # Store 0 when wait condition is true\n",
        "  data.loc[short_entry, 'positions'] = 0\n",
        "\n",
        "  data['positions'].fillna(method='ffill', inplace=True)\n",
        "\n",
        "\n",
        "  return data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "At1lib6fAOJT"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Drop NaN values\n",
        "#data = data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEasbkyqVxJf"
      },
      "outputs": [],
      "source": [
        "def CalculateStrReturns(data):\n",
        "  data['strategy_returns'] = ((data['Adj Close'] - data['Adj Open']) / data['Adj Open']) * data.positions\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Duv_zZfAdTl1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14EFET83XE-L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnTjVQdZcINa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLPhtXvAV3Hb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3ryp4bZbjdg"
      },
      "outputs": [],
      "source": [
        "def PlotUSDTROpenClosePerformance(Ticker,data):\n",
        "  print(f\"Plotting Open-Close Performance for {Ticker}\")\n",
        "  # Plot cumulative returns\n",
        "  global LEFT, RIGHT\n",
        "  import datetime\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(16, 22)\n",
        "\n",
        "  # ----------------------------------------------------------------------------------\n",
        "  plt.subplot(4, 1, 1)\n",
        "  plt.xlim(LEFT, RIGHT)\n",
        "  plt.plot(data['close'])\n",
        "  plt.grid(True)\n",
        "  plt.xticks(fontsize=12)\n",
        "  plt.yticks(fontsize=12)\n",
        "  plt.title(f\"{Ticker} USD price\", fontsize=12)\n",
        "  #plt.xlabel('Date', fontsize=12)\n",
        "  plt.ylabel('Price USD', fontsize=12)\n",
        "\n",
        "   # ----------------------------------------------------------------------------------\n",
        "  plt.subplot(4, 1, 2)\n",
        "  plt.xlim(LEFT, RIGHT)\n",
        "  plt.plot(data['cumulative_normal_returns'])\n",
        "  plt.grid(True)\n",
        "  plt.xticks(fontsize=12)\n",
        "  plt.yticks(fontsize=12)\n",
        "  plt.title(f\"{Ticker} data['cumulative_normal_returns'] \", fontsize=12)\n",
        "  #plt.xlabel('Date', fontsize=12)\n",
        "  plt.ylabel('Open-Close Trade Returns', fontsize=12)\n",
        "\n",
        "\n",
        "  # ----------------------------------------------------------------------------------\n",
        "  plt.subplot(4, 1, 3)\n",
        "  plt.xlim(LEFT, RIGHT)\n",
        "  plt.plot(data['cumulative_strategy_returns'])\n",
        "  plt.grid(True)\n",
        "  plt.xticks(fontsize=12)\n",
        "  plt.yticks(fontsize=12)\n",
        "  plt.title(f\"{Ticker} data['cumulative_strategy_returns'] \", fontsize=12)\n",
        "  #plt.xlabel('Date', fontsize=12)\n",
        "  plt.ylabel('Volatility Strategy Returns', fontsize=12)\n",
        "\n",
        " #----------------------------------------------------------------------------------\n",
        "  # plt.subplot(4, 1, 3)\n",
        "  # plt.xlim(LEFT, RIGHT)\n",
        "  # plt.plot(data['close'])\n",
        "  # plt.grid(True)\n",
        "  # plt.xticks(fontsize=12)\n",
        "  # plt.yticks(fontsize=12)\n",
        "  # plt.title(f\"{Ticker} TL price\", fontsize=12)\n",
        "  # #plt.xlabel('Date', fontsize=12)\n",
        "  # plt.ylabel('Price TL', fontsize=12)\n",
        "\n",
        "  # #----------------------------------------------------------------------------------\n",
        "  # plt.subplot(4, 1, 4)\n",
        "  # plt.xlim(LEFT, RIGHT)\n",
        "  # plt.plot(data['cumulative_normal_returns'])\n",
        "  # plt.grid(True)\n",
        "  # plt.xticks(fontsize=12)\n",
        "  # plt.yticks(fontsize=12)\n",
        "  # plt.title(f\"{Ticker} TL Open-Close Strategy\", fontsize=12)\n",
        "  # #plt.xlabel('Date', fontsize=12)\n",
        "  # plt.ylabel('Open-Close Strategy TL Returns', fontsize=12)\n",
        "\n",
        "  #----------------------------------------------------------------------------------\n",
        "  plt.subplot(4, 1, 4)\n",
        "  plt.xlim(LEFT, RIGHT)\n",
        "  plt.title(f\"{Ticker} {R_WINDOW}-day rolling volatility\")\n",
        "  plt.xlabel('Date', fontsize=14)\n",
        "  plt.ylabel(f'{Ticker} volatility', fontsize=14)\n",
        "  plt.grid()\n",
        "  plt.xticks(fontsize=12)\n",
        "\n",
        "  plt.plot(data['std']*252**0.5)\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp0cjuVFDs29"
      },
      "outputs": [],
      "source": [
        "def ShowDataTable(data):\n",
        "  global year, day, month\n",
        "  return(data.loc[f'{year}-{month}-{day}':f'{year+delta}-{month}-{day}'].dropna())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tp6gqXvZGsft"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def CreateTearSheetForData(data):\n",
        "  # if we buy and hold performance would be:\n",
        "  print(\"\\nIf we buy and hold performance would be:\")\n",
        "  print(\"\\n======================================\")\n",
        "  pyf.create_simple_tear_sheet(data['rets'].dropna())\n",
        "\n",
        "  # if we apply open-close strategy, performance would be:\n",
        "  print(\"\\nIf we apply open-close strategy, performance would be:\")\n",
        "  print(\"\\n====================================================\")\n",
        "  pyf.create_simple_tear_sheet(data['returns'].dropna())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKbDGMn0Fang"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LA3_sTWK1Kc"
      },
      "outputs": [],
      "source": [
        "def EvaluateFeasibility(data):\n",
        "  Max_Cum_Norm_Ret = np.max(data.cumulative_normal_returns)\n",
        "  Max_Cum_Str_Ret = np.max(data.cumulative_strategy_returns)\n",
        "\n",
        "  Last_Cum_Norm_Ret = data.cumulative_normal_returns[-1]\n",
        "  Last_Cum_Str_Ret = data.cumulative_strategy_returns[-1]\n",
        "\n",
        "  Latest_Rel = data['rel'][-1]\n",
        "  Latest_Cum_Norm_Ret = data.cumulative_normal_returns[-1]\n",
        "  feasible = Latest_Cum_Norm_Ret / Latest_Rel\n",
        "  return feasible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPkVe-OmiC0S"
      },
      "outputs": [],
      "source": [
        "def EvaluateFeasibility_TR(data):\n",
        "  Max_Cum_Norm_Ret = np.max(data.cumulative_normal_returns)\n",
        "  Max_Cum_Str_Ret = np.max(data.cumulative_strategy_returns)\n",
        "\n",
        "  Last_Cum_Norm_Ret = data.cumulative_normal_returns[-1]\n",
        "  Last_Cum_Str_Ret = data.cumulative_strategy_returns[-1]\n",
        "\n",
        "  Latest_Rel = data['rel'][-1]\n",
        "  Latest_Cum_Norm_Ret = data.cumulative_normal_returns[-1]\n",
        "  feasible = Latest_Cum_Norm_Ret / Latest_Rel\n",
        "  return Latest_Cum_Norm_Ret, Latest_Rel,feasible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXiemDK5iEDa"
      },
      "outputs": [],
      "source": [
        "def EvaluateFeasibility_USD(data):\n",
        "  Max_Cum_Norm_Ret = np.max(data['cumulative_normal_returns'])\n",
        "  Max_Cum_Str_Ret = np.max(data['cumulative_strategy_returns'])\n",
        "\n",
        "  Last_Cum_Norm_Ret = data['cumulative_normal_returns'][-1]\n",
        "  Last_Cum_Str_Ret = data['cumulative_strategy_returns'][-1]\n",
        "\n",
        "  Latest_Rel = data['rel'][-1]\n",
        "  Latest_Cum_Norm_Ret = data['cumulative_normal_returns'][-1]\n",
        "  feasible = Latest_Cum_Norm_Ret / Latest_Rel\n",
        "  return Latest_Cum_Norm_Ret, Latest_Rel,feasible\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZaWhd1Td5-R"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL3t551xVZFO"
      },
      "outputs": [],
      "source": [
        "def PredictNextState(datareturns, Rtarget):\n",
        "    state_bins = [-np.inf, Rtarget, np.inf]\n",
        "    datastate = pd.cut(datareturns, bins=state_bins)\n",
        "    transition_matrix = pd.crosstab(datastate, datastate.shift(-1), normalize='index')\n",
        "    #print(transition_matrix)\n",
        "    current_state = datastate.iloc[-1]\n",
        "    #print(f'Current state: {current_state}')\n",
        "    next_state = np.random.choice(transition_matrix.columns, p=transition_matrix.loc[current_state].values)\n",
        "    #print(f'Predicted next state: {next_state}')\n",
        "    # Print the probabilities of all states\n",
        "    state_probabilities = datastate.value_counts(sort=True, normalize=True)\n",
        "    #print(\"State probabilities:\")\n",
        "    #print(state_probabilities)\n",
        "    return next_state, np.round(transition_matrix[1][1],3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BewmdeM6dug"
      },
      "outputs": [],
      "source": [
        "def ShowTRMarket(Tickers, target_return):\n",
        "\n",
        "  my_dict = {'Ticker':[], 'Open-Close':[],'Close':[],'Eff':[], 'PWin_OC':[], 'PWin':[]};\n",
        "\n",
        "  for ticker in Tickers:\n",
        "    ticker = ticker + \".IS\"\n",
        "    print(f\"Downloading {ticker}...\")\n",
        "    d = UpdateData(ticker, START, END, \"BIST\");\n",
        "    #d = Volatility_Strategy_USD_TR(d)\n",
        "    opc,clo,fb = EvaluateFeasibility_TR(d);\n",
        "\n",
        "    print(\"\\n====================================================\")\n",
        "    print(f\"Next State Probabilities for {ticker} Buy-Hold\")\n",
        "    print(\"\\n====================================================\")\n",
        "    ns0, tm0 = PredictNextState(d['rets'], target_return)\n",
        "\n",
        "    print(\"\\n====================================================\")\n",
        "    print(f\"Next State Probabilities for {ticker} Open-Close\")\n",
        "    print(\"\\n====================================================\")\n",
        "    ns1, tm1 = PredictNextState(d['returns'], target_return)\n",
        "\n",
        "    my_dict['Ticker'].append(ticker)\n",
        "    my_dict['Eff'].append(fb)\n",
        "    my_dict['Open-Close'].append(opc)\n",
        "    my_dict['Close'].append(clo)\n",
        "    my_dict['PWin_OC'].append(tm1)\n",
        "    my_dict['PWin'].append(tm0)\n",
        "\n",
        "  df = pd.DataFrame(my_dict)\n",
        "  df.sort_values(by=['PWin_OC'], ascending=False, inplace=True)\n",
        "  print(df)\n",
        "  return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmNRV92Lh1Is"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4WCv-pokU9W"
      },
      "outputs": [],
      "source": [
        "def ShowUSMarket(Tickers,target_return):\n",
        "\n",
        "  my_dict = {'Ticker':[], 'Open-Close':[],'Close':[],'Eff':[], 'PWin_OC':[], 'PWin':[]};\n",
        "\n",
        "  for ticker in Tickers:\n",
        "    print(f\"Downloading {ticker}...\")\n",
        "    d = UpdateData(ticker, START, END, \"DOW30\");\n",
        "    opc,clo,fb = EvaluateFeasibility_USD(d);\n",
        "\n",
        "    print(\"\\n====================================================\")\n",
        "    print(f\"Next State Probabilities for {ticker} Buy-Hold\")\n",
        "    print(\"\\n====================================================\")\n",
        "    ns0, tm0 = PredictNextState(d['rets'], target_return)\n",
        "\n",
        "    print(\"\\n====================================================\")\n",
        "    print(f\"Next State Probabilities for {ticker} Open-Close\")\n",
        "    print(\"\\n====================================================\")\n",
        "    ns1, tm1 = PredictNextState(d['rets'], target_return)\n",
        "\n",
        "    my_dict['Ticker'].append(ticker)\n",
        "    my_dict['Eff'].append(fb)\n",
        "    my_dict['Open-Close'].append(opc)\n",
        "    my_dict['Close'].append(clo)\n",
        "    my_dict['PWin_OC'].append(tm1)\n",
        "    my_dict['PWin'].append(tm0)\n",
        "\n",
        "  df = pd.DataFrame(my_dict)\n",
        "  df.sort_values(by=['Pwin_OC'], ascending=False, inplace=True)\n",
        "  print(df)\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KtJd14QaZV4"
      },
      "outputs": [],
      "source": [
        "def ShowTickerStats(ticker, exchange):\n",
        "\n",
        "  print(\"\\n====================================================\")\n",
        "  print(f\"\\nUpdating data for {ticker}\")\n",
        "  print(\"\\n====================================================\")\n",
        "  d = UpdateData(ticker, START, END, exchange)\n",
        "\n",
        "  print(\"\\n====================================================\")\n",
        "  print(f\"\\nPlotting for {ticker}\")\n",
        "  print(\"\\n====================================================\")\n",
        "  #PlotUSDTROpenClosePerformance(ticker, d)\n",
        "\n",
        "  print(\"\\n====================================================\")\n",
        "  print(f\"Creating Tear Sheet for {ticker}\")\n",
        "  print(\"\\n====================================================\")\n",
        "  #CreateTearSheetForData(d)\n",
        "\n",
        "\n",
        "\n",
        "  return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmjUsNdUN19x"
      },
      "outputs": [],
      "source": [
        "def EmpyrialPortfolioPerformance():\n",
        "  !pip install Scikit-learn\n",
        "  !pip install empyrial\n",
        "\n",
        "  from empyrial import empyrial, Engine\n",
        "\n",
        "  pf2 = Engine(\n",
        "                    start_date= START, #start date for the backtesting\n",
        "                    portfolio = [\"ODAS.IS\", \"ALARK.IS\", \"KOZAA.IS\", \"ENKAI.IS\",\"KRDMD.IS\", \"ISCTR.IS\", \"PETKM.IS\", \"TAVHL.IS\", \"EREGL.IS\"],\n",
        "                    optimizer = \"MEANVAR\", # defines Mean-Variance as the optimizer\n",
        "                    max_vol = 40, #maximize the return for this level of volatility (25%)\n",
        "                    benchmark = [\"TRY=X\"], #NIFTY50 is set by default\n",
        "                    #rebalance = \"1Y\" #rebalance every year\n",
        "                    #risk_manager = {\"Take Profit\" : 1} #Stop the investment when the profit becomes superior to 25%\n",
        "  )\n",
        "  empyrial(pf2)\n",
        "  empyrial.orderbook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLcpiYgtafJ9"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "\n",
        "  target_return = 0\n",
        "  bist_df = ShowTRMarket(BIST100, target_return)\n",
        "  # for ticker in bist_df['Ticker']:\n",
        "  #   print(\"\\n====================================================\")\n",
        "  #   print(f\"\\nShowing Ticker Stats for {ticker} : \")\n",
        "  #   print(\"\\n====================================================\")\n",
        "  #   ShowTickerStats( ticker,\"BIST\")\n",
        "\n",
        "  # # dow_df = ShowUSMarket(DOW30)\n",
        "  # # for ticker in dow_df['Ticker']:\n",
        "\n",
        "  # # sp500_df = ShowUSMarket(sp500_constituents.Symbol)\n",
        "  # # for ticker in sp500_df['Ticker']:\n",
        "  # #    ShowTickerStats( ticker,\"SP500\")\n",
        "\n",
        "  # #EmpyrialPortfolioPerformance()\n",
        "  print(f\"\\nHere is our most probable winner list (for TR = {target_return}) :\")\n",
        "  print(\"\\n====================================================\")\n",
        "\n",
        "  pd.set_option('display.max_columns', None)\n",
        "  bist_df = bist_df.reset_index(drop=True)\n",
        "  print(bist_df)\n",
        "\n",
        "  # from google.colab import data_table\n",
        "  # print(data_table.DataTable(bist_df, include_index=False, num_rows_per_page=10))\n",
        "\n",
        "  cnt_PWin = bist_df[(bist_df['PWin'] > 0.5)].count()\n",
        "  cnt_PWin_OC = bist_df[(bist_df['PWin_OC'] > 0.5)].count()\n",
        "  print(\"\\n====================================================\")\n",
        "  print(f\"\\nOut of {bist_df['PWin'].count()}, there are {cnt_PWin} assets have Pwin > 0.5\")\n",
        "  print(f\"\\nOut of {bist_df['PWin_OC'].count()}, there are {cnt_PWin_OC} assets have PWin_OC > 0.5\")\n",
        "  return(bist_df)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i5jQPaQGYjZm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMo1i6HX4ZWoCWl+OzhrOd/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}